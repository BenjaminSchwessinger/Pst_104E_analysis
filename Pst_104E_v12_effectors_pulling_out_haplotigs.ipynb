{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at getting all the effector candidates from the Pst_104E_genome haplotigs as defined as the following.\n",
    "EffectorP prediction done by Jana Sperschneider\n",
    "Gene expression cluster analysis done by Jana Sperschneider picking cluster 11, 13, 14, and 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define your input folders updated for haplotigs\n",
    "CLUSTER_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/gene_expression/Pst104_h_SecretomeClustering'\n",
    "EFFECTORP_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/Secretomes/EffectorP'\n",
    "GFF_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "PROTEIN_ANNO_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/pa_26062017'\n",
    "OUT_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome = 'Pst_104E_v12_'\n",
    "h_effector_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define what you want to take\n",
    "clusters = [ 11, 13, 14, 15]\n",
    "clusters_files = [os.path.join(CLUSTER_FOLDER, x) for x in os.listdir(CLUSTER_FOLDER)\\\n",
    "                 if x.startswith('Cluster') and x.endswith('_DEs.fasta') and\\\n",
    "                  any(str(y) in x for y in clusters) ] #fixed to check if any of the clusters are\n",
    "                                    #in the file header\n",
    "effectorp_files = [os.path.join(EFFECTORP_FOLDER, x) for x in os.listdir(EFFECTORP_FOLDER)\\\n",
    "                  if x.endswith('effectors.fasta') and x.startswith(genome)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the sequence names into a list from the fasta headers \n",
    "for file in clusters_files:\n",
    "    fh = open(file, 'r')\n",
    "    for seq in SeqIO.parse(fh, 'fasta'):\n",
    "        if 'hcontig' in seq.id:\n",
    "            h_effector_list.append(seq.id)\n",
    "    fh.close()\n",
    "\n",
    "for file in effectorp_files:\n",
    "    fh = open(file, 'r')\n",
    "    for seq in SeqIO.parse(fh, 'fasta'):\n",
    "        if 'hcontig' in seq.id:\n",
    "            h_effector_list.append(seq.id)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_effector_file = os.path.join(OUT_FOLDER, genome + 'h_effector.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out the sets of effector candidates\n",
    "fh = open(h_effector_file, 'w')\n",
    "for ec in set(h_effector_list):\n",
    "    print(ec, file=fh)\n",
    "fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subset the gff files as well and write those out\n",
    "h_gff_file = [os.path.join(GFF_FOLDER, x) for x in os.listdir(GFF_FOLDER)\\\n",
    "                 if x.startswith(genome+'h_ctg') and x.endswith('anno.gff3') ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.listdir(GFF_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get repeat gff files\n",
    "h_repeat_gff_fn  = [os.path.join(GFF_FOLDER, x) for x in os.listdir(GFF_FOLDER)\\\n",
    "                 if x.startswith(genome+'h_ctg') and x.endswith('REPET.gff') ][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command line in /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/TE_analysis the superfamily gff files were sorted as followed and copied over into the lists folder\n",
    "sort Pst_104E_v12_h_ctg.REPET.superfamily.gff -k1,1n -k4,4n > Pst_104E_v12_h_ctg.REPET.sorted.superfamily.gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get repeat gff files\n",
    "h_repeat_superfamily_gff_fn  = [os.path.join(OUT_FOLDER, x) for x in os.listdir(OUT_FOLDER)\\\n",
    "                 if x.startswith(genome+'h_ctg') and x.endswith('REPET.sorted.superfamily.gff') ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gff header \n",
    "gff_header = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now subset the gff files for effectors only\n",
    "h_gff_df = pd.read_csv(h_gff_file, header = None, sep='\\t', names= gff_header)\n",
    "h_gff_df['ID'] = h_gff_df.attributes.str.extract(r'ID=([^;]*);', expand=False)\n",
    "h_gff_df.sort_values(by=['seqid', 'start'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now sort REPET gff and write out again\n",
    "h_repeat_gff_df = pd.read_csv(h_repeat_gff_fn, header=None, sep='\\t', names=gff_header, comment='#')\n",
    "h_repeat_gff_fn = os.path.join(OUT_FOLDER,h_repeat_gff_fn.split('/')[-1] )\n",
    "h_repeat_gff_df.sort_values(by=['seqid', 'start']).to_csv(h_repeat_gff_fn, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now write out dataframes for h_gff\n",
    "\n",
    "#bed 6 file\n",
    "h_effector_bed_fn = h_effector_file.replace('.list', '.gene.bed')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_effector_bed_fn, header=None, index=None, sep='\\t')\n",
    "    \n",
    "h_effector_gff_fn = h_effector_file.replace('.list', '.gene.gff3')    \n",
    "h_gff_df[(h_gff_df.type == 'gene') & (h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))].\\\n",
    "    loc[:,gff_header].to_csv(h_effector_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "\n",
    "#bed 6 file no effectors\n",
    "h_noeffector_bed_fn = h_effector_file.replace('.list', 'h_noeffector.gene.bed')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (~h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_noeffector_bed_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "#no effector gff and list\n",
    "h_noeffector_gff_fn = h_effector_file.replace('h_effector.list', 'h_noeffector.gene.gff3')    \n",
    "h_gff_df[(h_gff_df.type == 'gene') & (~h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))].\\\n",
    "    loc[:,gff_header].to_csv(h_noeffector_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "file_name = h_effector_file.replace('h_effector.list', 'h_noeffector.list')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (~h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get BUSCO list and write out stuff\n",
    "h_busco_file = [os.path.join(PROTEIN_ANNO_FOLDER, x) for x in os.listdir(PROTEIN_ANNO_FOLDER) if x.startswith(genome+'h_ctg') and 'busco' in x][0]\n",
    "h_busco_list = pd.read_csv(h_busco_file, header=None, sep='\\t')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out BUSCO for hcontigs\n",
    "file_name = h_effector_file.replace('effector.list', 'busco.list')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (h_gff_df.ID.str.replace('TU', 'model').isin(h_busco_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')\n",
    "h_busco_gff_fn = h_effector_file.replace('effector.list', 'busco.gene.gff3')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (h_gff_df.ID.str.replace('TU', 'model').isin(h_busco_list))].\\\n",
    "    loc[:,gff_header].to_csv(h_busco_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "h_busco_bed_fn = h_effector_file.replace('effector.list', 'busco.gene.bed')\n",
    "h_gff_df[(h_gff_df.type == 'gene') & (h_gff_df.ID.str.replace('TU', 'model').isin(h_busco_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_busco_bed_fn, header=None, index=None, sep='\\t')\n",
    "    \n",
    "h_nobusco_bed_fn = h_effector_file.replace('effector.list', 'no_busco.gene.bed')    \n",
    "h_gff_df[(h_gff_df.type == 'gene') & (~h_gff_df.ID.str.replace('TU', 'model').isin(h_busco_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_nobusco_bed_fn, header=None, index=None, sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out no busco no effector bed files\n",
    "h_noeffector_nobusco_bed_fn = h_effector_file.replace('effector.list', 'no_busco_no_effector.gene.bed')    \n",
    "h_gff_df[(h_gff_df.type == 'gene') & (~h_gff_df.ID.str.replace('TU', 'model').isin(h_busco_list))\\\n",
    "         &(~h_gff_df.ID.str.replace('TU', 'model').isin(h_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_noeffector_nobusco_bed_fn, header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write all genes\n",
    "h_gene_gff_fn = h_effector_file.replace('effector.list', 'all.gene.gff3')\n",
    "h_gff_df[(h_gff_df.type == 'gene') ].\\\n",
    "    loc[:,gff_header].to_csv(h_gene_gff_fn, header=None, index=None, sep='\\t')\n",
    "#write bed 6\n",
    "h_gene_bed_fn = h_effector_file.replace('effector.list', 'all.gene.bed')\n",
    "h_gff_df[(h_gff_df.type == 'gene') ].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(h_gene_bed_fn, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed it up to here waiting to get the cluster genes for effector annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {p_effector_bed_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances\n",
    "p_effector_bed = BedTool(p_effector_gff_fn)\n",
    "p_noeffector_bed = BedTool(p_noeffector_gff_fn)\n",
    "p_busco_bed = BedTool(p_busco_gff_fn)\n",
    "p_repeats_bed = BedTool(p_repeat_superfamily_gff_fn)\n",
    "\n",
    "p_closest_rep_to_eff = p_effector_bed.closest(p_repeats_bed, d=True)\n",
    "\n",
    "p_closest_rep_to_eff_df = p_closest_rep_to_eff.to_dataframe()\n",
    "\n",
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily', 'tmpsuperfamily')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bed closest header\n",
    "bed_repeat_closest_header = [x +'_gene' for x in gff_header] + [x +'_repeat' for x in gff_header] + ['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_effector_bed.closest(p_repeats_bed,d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_effector_bed.closest(p_repeats_bed, d=True, t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_noeffector_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_effector_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_busco_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_REPET[(tmp_REPET.distance > 400)&(tmp_REPET.attributes == 'ClassII:?:?')].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_effector_bed.closest(p_repeats_bed,d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_effector_bed.closest(p_repeats_bed, d=True, t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density')\n",
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density', color='r')\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density', color='g')\n",
    "plt.semilogx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density')\n",
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density', color='r')\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density', color='g')\n",
    "plt.semilogx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily', 'tmpsuperfamily')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_br_closest_df = p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_br_closest_pt = p_br_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_br_closest_pt['superfamily_%'] = p_br_closest_pt.count_nonzero / p_br_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_br_closest_pt.columns] \n",
    "new_columns = [x+'_busco' for x in p_br_closest_pt.columns]\n",
    "p_br_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_er_closest_df = p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_er_closest_pt = p_er_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_er_closest_pt['superfamily_%'] = p_er_closest_pt.count_nonzero / p_er_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_er_closest_pt.columns] \n",
    "new_columns = [x+'_effector' for x in p_er_closest_pt.columns]\n",
    "p_er_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_ner_closest_df = p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_ner_closest_pt = p_ner_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_ner_closest_pt['superfamily_%'] = p_ner_closest_pt['count_nonzero'] / p_ner_closest_pt['count_nonzero'].sum() *100\n",
    "old_columns =[x for x in p_ner_closest_pt.columns] \n",
    "new_columns = [x+'_noeffector' for x in p_ner_closest_pt.columns]\n",
    "p_ner_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "repeat_distance_df = pd.concat([p_ner_closest_pt.iloc[:,1:], p_br_closest_pt.iloc[:,1:], p_er_closest_pt.iloc[:,1:]], axis=1)\n",
    "\n",
    "repeat_distance_df[repeat_distance_df['superfamily_%_effector'] >1].sort_values('superfamily_%_effector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summary not allowing for overlaps of closest TEs not allowing for overlaps\n",
    "p_br_closest_df = p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_br_closest_pt = p_br_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_br_closest_pt['superfamily_%'] = p_br_closest_pt.count_nonzero / p_br_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_br_closest_pt.columns] \n",
    "new_columns = [x+'_busco' for x in p_br_closest_pt.columns]\n",
    "p_br_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_er_closest_df = p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_er_closest_pt = p_er_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_er_closest_pt['superfamily_%'] = p_er_closest_pt.count_nonzero / p_er_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_er_closest_pt.columns] \n",
    "new_columns = [x+'_effector' for x in p_er_closest_pt.columns]\n",
    "p_er_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_ner_closest_df = p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_ner_closest_pt = p_ner_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_ner_closest_pt['superfamily_%'] = p_ner_closest_pt['count_nonzero'] / p_ner_closest_pt['count_nonzero'].sum() *100\n",
    "old_columns =[x for x in p_ner_closest_pt.columns] \n",
    "new_columns = [x+'_noeffector' for x in p_ner_closest_pt.columns]\n",
    "p_ner_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "repeat_distance_df = pd.concat([p_ner_closest_pt.iloc[:,1:], p_br_closest_pt.iloc[:,1:], p_er_closest_pt.iloc[:,1:]], axis=1)\n",
    "\n",
    "repeat_distance_df[repeat_distance_df['superfamily_%_effector'] >1].sort_values('superfamily_%_effector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some sub_sets for randommization to get equal sized groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the size of the subset here\n",
    "sub_set = len(p_busco_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed = BedTool(p_effector_bed_fn)\n",
    "p_allgene_bed = BedTool(p_gene_bed_fn)\n",
    "p_busco_bed = BedTool(p_busco_bed_fn)\n",
    "p_allall_rand_sub = p_allgene_bed.random_subset(sub_set)\n",
    "p_effector_bed_rand_sub = p_effector_bed.random_subset(sub_set)\n",
    "p_busco_bed_rand_sub = p_busco_bed.random_subset(sub_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances with nearest gene effectors vs effectors\n",
    "p_eself = p_effector_bed_rand_sub.closest(p_effector_bed_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_eself = p_eself[p_eself > -1]\n",
    "p_eself.name = 'Effectors'\n",
    "p_eall = p_effector_bed_rand_sub.closest(p_allall_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_eall= p_eall[p_eall > -1]\n",
    "print(p_eself.describe())\n",
    "p_eself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances with nearest gene all vs all subsampled\n",
    "p_allall = p_allall_rand_sub.closest(p_allall_rand_sub, d=True, N=True).to_dataframe().iloc[:,12]\n",
    "p_allall = p_allall[p_allall > -1]\n",
    "p_allall.name = 'All_genes'\n",
    "print(p_allall.describe())\n",
    "p_allall.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now with buscos\n",
    "p_bself = p_busco_bed_rand_sub.closest(p_busco_bed_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_bself = p_bself[p_bself > -1]\n",
    "p_bself.name = 'BUSCO'\n",
    "print(p_bself.describe())\n",
    "p_bself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#non_effectors\n",
    "p_noeffector_bed= BedTool(p_noeffector_bed_fn)\n",
    "p_noeffector_rand_sub = p_noeffector_bed.random_subset(sub_set)\n",
    "p_neself = p_noeffector_rand_sub.closest(p_noeffector_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_neself = p_neself[p_neself > -1]\n",
    "p_neself.name = 'No_effectors'\n",
    "print(p_neself.describe())\n",
    "p_neself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself[p_bself < 10000], bins=20, rug = True, color='g',label='BUSCO')\n",
    "sns.distplot(p_eself[p_eself < 10000], bins=20, rug = True, color='red',label = 'effector')\n",
    "sns.distplot(p_neself[p_neself <10000], bins=20, rug=True, color='yellow', label ='not_effectors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself[p_bself < 200000], bins=20, color='g' ,label='BUSCO')\n",
    "sns.distplot(p_eself[p_eself < 200000], bins=20,  color='red',label = 'effector')\n",
    "sns.distplot(p_neself[p_neself <200000], bins=20,  color='yellow', label ='not_effectors', axlabel='Distance to closest neighbour [bp]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself, bins=20,color='g',  label='BUSCO')\n",
    "sns.distplot(p_eself, bins=20,  color='red',label = 'effector')\n",
    "sns.distplot(p_allall, bins=20,  color='b',label = 'all')\n",
    "sns.distplot(p_neself, bins=20,  color='yellow', label ='not_effectors', axlabel='Distance to closest neighbour [bp]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now make a nearest neightbour dataframe\n",
    "nn_df = pd.concat([p_allall, p_bself, p_eself], names=['All_genes', 'BUSCO', 'effectors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=nn_df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOW FILTER BY QUANTIELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low = 0\n",
    "high = 0.8\n",
    "quant_df = nn_df.quantile([low,high])\n",
    "\n",
    "qfilt_nn_df = nn_df.apply(lambda x: x[(x > quant_df.loc[low, x.name]) & (x  < quant_df.loc[high, x.name])], axis=0)\n",
    "\n",
    "sns.violinplot(data=qfilt_nn_df , palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now filter on IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iqr_df_low = nn_df.apply(lambda x: x.quantile(0.25) - 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "iqr_df_low.name ='low'\n",
    "iqr_df_high = nn_df.apply(lambda x: x.quantile(0.75) + 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "iqr_df_high.name = 'high'\n",
    "\n",
    "iqr_df = pd.concat([iqr_df_low, iqr_df_high], axis=1).T\n",
    "\n",
    "iqr_nn_df = nn_df.apply(lambda x: x[(x > iqr_df.loc['low', x.name]) & (x  < iqr_df.loc['high', x.name])], axis=0)\n",
    "plt.title('Violine plot of nearest neighbour in the same category')\n",
    "sns.violinplot(data=iqr_nn_df  , palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_bself[p_bself < 20000].plot(kind='density')\n",
    "p_eself[p_eself < 20000].plot(kind='density', color='g')\n",
    "p_neself[p_neself < 20000].plot(kind='density', color='r')\n",
    "p_eall[p_eall < 20000].plot(kind='density', color='y')\n",
    "#plt.semilogx()\n",
    "print(len(p_bself[p_bself < 20000]), len(p_eself[p_eself < 20000]), len(p_neself[p_neself < 20000]), len(p_eall[p_eall < 20000]))\n",
    "plt.xlim(0, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_eall[p_eall < 20000].plot(kind='hist', bins=20, normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_eself[p_eself < 20000].plot(kind='hist', bins=20, normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_bself[p_bself < 20000].plot(kind='hist', bins=20,normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_neself[p_neself < 20000].plot(kind='hist',bins=20,normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there seems to be no clear link between effector candidates and closest neighbour in terms of TEs in general. They all have the same distance in general.\n",
    "Maybe Gypsy and ClassII:?:? should be looked at more carefully. Those are depleted and enriched in busco and effector genes. In general there seems to be a trend towards ClassII elements compared to ClassI in effector candidates.\n",
    "This changes when for allowing for overlaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that effectors are closer together than noneffector genes. Buscos also seem to cluster a bit. Let's see if we can visualize the location of genes on certain contigs vs repeats and such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start with getting effectors per contig divided by length divded by # of overall genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "effector_bdf = pd.read_csv(p_effector_bed_fn, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effectors_per_contig  = effector_bdf.groupby(0).count()[1]\n",
    "p_effectors_per_contig.name = 'effectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_all_genes_per_contig = pd.read_csv(p_gene_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_all_genes_per_contig.name = 'all_genes'\n",
    "p_noeffectors_per_contig = pd.read_csv(p_noeffector_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_noeffectors_per_contig.name = 'no_effectors'\n",
    "p_busco_per_contig = pd.read_csv(p_busco_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_busco_per_contig.name = 'buscos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_contig_length = pd.read_csv(os.path.join(GFF_FOLDER, 'Pst_104E_v12_p_ctg.genome_file'), header = None,\\\n",
    "                          names=['contig' , 'length'], sep='\\t').sort_values('contig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_contig_length.index = p_contig_length.contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_contig_length = p_contig_length.loc[:, 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig = pd.concat([p_contig_length,p_all_genes_per_contig,p_noeffectors_per_contig,p_busco_per_contig,  p_effectors_per_contig, ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig.effectors.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chisquare for genes per contig vs bases per contig\n",
    "chisquare(gene_dis_per_contig.length.values/gene_dis_per_contig.length.sum()\\\n",
    "          , gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chisquare(gene_dis_per_contig.buscos.values/gene_dis_per_contig.buscos.sum()\\\n",
    "          , gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig['%busco'] = gene_dis_per_contig.buscos.values/gene_dis_per_contig.buscos.sum() *100\n",
    "gene_dis_per_contig['%effector'] = gene_dis_per_contig.effectors.values/gene_dis_per_contig.effectors.sum() *100\n",
    "gene_dis_per_contig['%all_genes'] = gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum() *100\n",
    "gene_dis_per_contig['%no_effector'] = gene_dis_per_contig.no_effectors.values/gene_dis_per_contig.no_effectors.sum() *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chisquare(gene_dis_per_contig['%effector'], f_exp = gene_dis_per_contig['%all_genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig.loc[:,['%effector', '%all_genes','%no_effector' ,'%busco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%effector'] > gene_dis_per_contig['%busco'])].loc[:,['effectors', '%effector', '%all_genes']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#effectors per contig > than expected\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes']) > 1.2].loc[:,['effectors', '%effector', 'all_genes','%all_genes']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%effector'] > gene_dis_per_contig['%busco'])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.2) & (gene_dis_per_contig['%busco'] > 0.5 )\\\n",
    "                    ].loc[:,['buscos', '%busco', '%all_genes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.2) \\\n",
    "                    ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.1) & \\\n",
    "                   (gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes'] < 0.9) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.0000001) & \\\n",
    "                   (gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes'] < 0.9999) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enriched for effectors relative to busco and all genes. Seems to be the case that their might be contigs\n",
    "#with less BUSCOs and more effectors\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%effector'] < 1) & \\\n",
    "                    (gene_dis_per_contig['%all_genes'] / gene_dis_per_contig['%effector'] < 1) ].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get closest features genes vs. TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily.gff', 'tmpsuperfamily.bed')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,['seqid', 'start', 'end', 'attributes', 'score', 'strand']].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df = p_effector_bed.closest( [p_repeats_bed.fn,p_allgene_bed.fn] , mdb='all', d=True, N=True).to_dataframe()\n",
    "\n",
    "tmp_df.rename(columns={10: 'ID'}, inplace=True)\n",
    "\n",
    "print('Per of effectors having genes as closest feature %f2' % (tmp_df[tmp_df.ID.str.contains('evm')][0].count()/len(p_effector_bed)*100))\n",
    "\n",
    "print('Per of effectors having TE as closest %f2' % (tmp_df[~tmp_df.ID.str.contains('evm')][0].count()/len(p_effector_bed)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df = p_allgene_bed.closest( [p_repeats_bed.fn,p_allgene_bed.fn] , mdb='all', d=True, N=True).to_dataframe()\n",
    "\n",
    "tmp_df.rename(columns={10: 'ID'}, inplace=True)\n",
    "\n",
    "print('Per of genes having genes as closest feature %f2' % (tmp_df[tmp_df.ID.str.contains('evm')][0].count()/len(p_allgene_bed)*100))\n",
    "\n",
    "print('Per of genes having TE as closest %f2' % (tmp_df[~tmp_df.ID.str.contains('evm')][0].count()/len(p_allgene_bed)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 5 and 3 prime distances of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now get the 3 prime distante to genes using the D='a' and iu flag in bedtools\n",
    "g_to_g_3 = p_allgene_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "\n",
    "\n",
    "g_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#now get the 5 prime distante to genes using the D='a' and id flag in bedtools\n",
    "g_to_g_5 = p_allgene_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "g_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "g_to_g_merged = g_to_g_3.merge(g_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account. Filter out everythign that has a 5' distance of -1 meaning nothing\n",
    "#and is at the begining of the contig .1 and at the 3' end drop everything that has a negative distance meaning no 3' neighbour\n",
    "\n",
    "g_to_g_merged = g_to_g_merged[ (g_to_g_merged['5_target'] !='.') &(g_to_g_merged['3_target'] !='.') ]\n",
    "\n",
    "\n",
    "g_to_g_merged['5_distance'] = abs(g_to_g_merged['5_distance'])\n",
    "g_to_g_merged['5_distance_log10'] = np.log10(g_to_g_merged['5_distance'])\n",
    "g_to_g_merged['3_distance_log10'] = np.log10(g_to_g_merged['3_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\")\n",
    "\n",
    "\n",
    "\n",
    "#do the same for effectors\n",
    "#now for effectors \n",
    "#getting 5' and 3' distance\n",
    "e_to_g_3 = p_effector_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "e_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "e_to_g_5 = p_effector_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "e_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#merging them\n",
    "e_to_g_merged = e_to_g_3.merge(g_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges\n",
    "e_to_g_merged = e_to_g_merged[((e_to_g_merged['5_target'] != '.') & ((e_to_g_merged['3_target'] != '.'))) ]\n",
    "e_to_g_merged['5_distance'] = abs(e_to_g_merged['5_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\")\n",
    "\n",
    "\n",
    "#now for busco\n",
    "b_to_g_3 = p_busco_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "b_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "b_to_g_5 = p_busco_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "b_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "b_to_g_merged = b_to_g_3.merge(b_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges see above for details\n",
    "b_to_g_merged = b_to_g_merged[((b_to_g_merged['5_target'] !='.') & (b_to_g_merged['3_target'] !='.')) ]\n",
    "b_to_g_merged['5_distance'] = abs(b_to_g_merged['5_distance'])\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged, kind=\"kde\")\n",
    "\n",
    "#now start plotting stuff\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\", color='r', xlim=10000, ylim=10000)\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\", xlim=10000, ylim=10000)\n",
    "\n",
    "\n",
    "#subset everything by fixed numbers maybe to IQR or such in future\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged[(e_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (e_to_g_merged['3_distance'] < 10000)], kind=\"hex\", color='r',xlim=[0,10000], ylim=[0,10000],\\\n",
    "             marginal_kws=dict(bins=30))\n",
    "\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged[(b_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (b_to_g_merged['3_distance'] < 10000)], kind=\"hex\",color='g', xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged[(g_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (g_to_g_merged['3_distance'] < 10000)], kind=\"hex\", xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the distance to the closest gene of the same group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the 3 prime distante to genes using the D='a' and iu flag in bedtools\n",
    "p_allall_rand_sub = p_allgene_bed.random_subset(sub_set)\n",
    "p_effector_bed_rand_sub = p_effector_bed.random_subset(sub_set)\n",
    "p_busco_bed_rand_sub = p_busco_bed.random_subset(sub_set)\n",
    "\n",
    "all_all_rand_3 = p_allall_rand_sub.closest( p_allall_rand_sub ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "\n",
    "\n",
    "all_all_rand_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#now get the 5 prime distante to genes using the D='a' and id flag in bedtools\n",
    "all_all_rand_5 = p_allall_rand_sub.closest( p_allall_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "all_all_rand_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "all_all_rand_merged = all_all_rand_3.merge(all_all_rand_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account. Filter out everythign that has a 5' distance of -1 meaning nothing\n",
    "#and is at the begining of the contig .1 <- the .1 was no appropriate here as the random subsampling can lead\n",
    "#to alternative first gene models selected on the respective contig\n",
    "#extended the initial df of closest to include also queyr and target. Now filtering on no target ='.' possible\n",
    "\n",
    "all_all_rand_merged = all_all_rand_merged[((all_all_rand_merged['5_target'] != '.')&(all_all_rand_merged['3_target'] != '.')  ) ]\n",
    "\n",
    "\n",
    "\n",
    "all_all_rand_merged['5_distance'] = abs(all_all_rand_merged['5_distance'])\n",
    "all_all_rand_merged['5_distance_log10'] = np.log10(all_all_rand_merged['5_distance'])\n",
    "all_all_rand_merged['3_distance_log10'] = np.log10(all_all_rand_merged['3_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=all_all_rand_merged, kind=\"kde\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#do the same for effectors\n",
    "#now for effectors \n",
    "#getting 5' and 3' distance\n",
    "e_to_e_sub_3 = p_effector_bed_rand_sub.closest( p_effector_bed_rand_sub ,  N=True, iu=True, D='a' ).to_dataframe()\\\n",
    "    .iloc[:,[0, 3, 9,12]]\n",
    "e_to_e_sub_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "e_to_e_sub_5 = p_effector_bed_rand_sub.closest( p_effector_bed_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe()\\\n",
    "    .iloc[:,[0, 3, 9,12]]\n",
    "e_to_e_sub_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#merging them\n",
    "e_to_e_sub_merged = e_to_e_sub_3.merge(e_to_e_sub_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges\n",
    "e_to_e_sub_merged = e_to_e_sub_merged [((e_to_e_sub_merged ['5_target'] != '.') & (e_to_e_sub_merged ['3_target'] != '.') )  ]\n",
    "e_to_e_sub_merged ['5_distance'] = abs(e_to_e_sub_merged ['5_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_e_sub_merged , kind=\"kde\", color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#now for busco\n",
    "p_busco_bed_rand_sub_3 = p_busco_bed_rand_sub.closest( p_busco_bed_rand_sub.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "p_busco_bed_rand_sub_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "p_busco_bed_rand_sub_5 = p_busco_bed_rand_sub.closest( p_busco_bed_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "p_busco_bed_rand_sub_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "p_busco_bed_rand_sub_merged = p_busco_bed_rand_sub_3.merge(p_busco_bed_rand_sub_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges see above for details\n",
    "p_busco_bed_rand_sub_merged = p_busco_bed_rand_sub_merged[((p_busco_bed_rand_sub_merged['5_target'] != '.') & (p_busco_bed_rand_sub_merged['5_target'] != '.') )]\n",
    "p_busco_bed_rand_sub_merged['5_distance'] = abs(p_busco_bed_rand_sub_merged['5_distance'])\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=p_busco_bed_rand_sub_merged, kind=\"kde\" ,color = 'green')\n",
    "\n",
    "#now start plotting stuff\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\", color='r', xlim=10000, ylim=10000)\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\", xlim=10000, ylim=10000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some more plotting for when subsetting the dataframe to exclude outliers\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=p_busco_bed_rand_sub_merged[(p_busco_bed_rand_sub_merged['5_distance'] < 20000)&\\\n",
    "                                                                              (p_busco_bed_rand_sub_merged['3_distance'] < 20000)],\\\n",
    "              kind=\"kde\" ,color = 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some more plotting for when subsetting the dataframe to exclude outliers\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_e_sub_merged[(e_to_e_sub_merged['5_distance'] < 20000)&\\\n",
    "                                                                              (e_to_e_sub_merged['3_distance'] < 20000)],\\\n",
    "              kind=\"kde\" ,color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking more into the distance distribution between effectors use the index for this purpose and groupby or filteirng by \n",
    "#contig\n",
    "#getting 5' and 3' distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting 5' and 3' distance\n",
    "e_to_e_sub_distance = e_to_e_sub_3.merge(e_to_e_sub_5, on = ['query','contig'])\n",
    "\n",
    "#convert negative -1 from bedtools closest to nan and make values absolute\n",
    "tmp_index = e_to_e_sub_distance[e_to_e_sub_distance['5_target'] == '.'].index.tolist()\n",
    "e_to_e_sub_distance.loc[tmp_index, '5_distance'] = np.nan\n",
    "e_to_e_sub_distance['5_distance'] = abs(e_to_e_sub_distance['5_distance'])\n",
    "#convert -1 from bedtools closest to nan in 3_distance\n",
    "tmp_index = e_to_e_sub_distance[e_to_e_sub_distance['3_target'] == '.'].index.tolist()\n",
    "e_to_e_sub_distance.loc[tmp_index, '3_distance'] = np.nan\n",
    "\n",
    "#now subset the dataframe for a fixed distance \n",
    "max_distance = 15000\n",
    "#subset the df and get the index\n",
    "e_to_e_less_d_df = e_to_e_sub_distance[(e_to_e_sub_distance['3_distance'] <max_distance) | (e_to_e_sub_distance['5_distance'] <max_distance) ]\n",
    "e_to_e_less_d_df_index = e_to_e_less_d_df.index.values\n",
    "\n",
    "\n",
    "#introduce new column 'linked' and make this 1 were the genes are linked (e.g. less than max distance apart)\n",
    "e_to_e_sub_distance['linked'] =0\n",
    "e_to_e_sub_distance.loc[e_to_e_less_d_df_index, 'linked']  = 1\n",
    "#get a new columns linkage_group that is 0 for now\n",
    "e_to_e_sub_distance['linkage_group'] = 0\n",
    "\n",
    "\n",
    "#now loop over the contigs and connect the consecutive linked effectors (e.g. linked == 1) with a cumsum \n",
    "for contig in e_to_e_sub_distance['contig'].unique():\n",
    "    tmp_df = e_to_e_sub_distance[e_to_e_sub_distance.contig == contig]\n",
    "    #check were the index difference is not one and add it up\n",
    "    tmp_linkage_groups = (tmp_df[tmp_df.linked == 1].linked != tmp_df[tmp_df.linked == 1].linked.index.to_series().diff().eq(1)).cumsum() \n",
    "    e_to_e_sub_distance.loc[tmp_df[tmp_df.linked == 1].index, 'linkage_group'] =  tmp_linkage_groups\n",
    "    #print(contig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now fill in the nan values in the linkage_group \n",
    "e_to_e_sub_distance.fillna(0,inplace=True)\n",
    "\n",
    "#the count of each linkage group per contig is the number of genes within this linkage group\n",
    "lg_grouped = e_to_e_sub_distance.groupby(by=['contig', 'linkage_group']).linked.count()\n",
    "\n",
    "#sum up the zeros these are the number of unlinked genes/effectors\n",
    "number_unlinked_effectors = lg_grouped.unstack()[0].sum()\n",
    "\n",
    "#the columns correspond to the name of the linkage group and the values to the number of genes contained in each\n",
    "tmp_non_zero_df = lg_grouped.unstack().iloc[:,1:]\n",
    "\n",
    "#count the number of each linkage group size for each abitrary linkage group and sum it up \n",
    "tmp_freq_count = tmp_non_zero_df.apply(pd.value_counts).sum(axis=1)\n",
    "\n",
    "#this gives the frequency of each size of linkage group\n",
    "tmp_freq_count = pd.Series([number_unlinked_effectors], index=[1.00]).append(tmp_freq_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now let's do the same for all genes\n",
    "all_all_rand_distance = all_all_rand_3.merge(all_all_rand_5, on=['query', 'contig'])\n",
    "\n",
    "#convert negative -1 from bedtools closest to nan and make values absolute\n",
    "tmp_index = all_all_rand_distance[all_all_rand_distance['5_target'] == '.'].index.tolist()\n",
    "all_all_rand_distance.loc[tmp_index, '5_distance'] = np.nan\n",
    "all_all_rand_distance['5_distance'] = abs(all_all_rand_distance['5_distance'])\n",
    "#convert -1 from bedtools closest to nan in 3_distance\n",
    "tmp_index = all_all_rand_distance[all_all_rand_distance['3_target'] == '.'].index.tolist()\n",
    "all_all_rand_distance.loc[tmp_index, '3_distance'] = np.nan\n",
    "\n",
    "#now subset the dataframe for a fixed distance \n",
    "#max_distance = 10000\n",
    "#subset the df and get the index\n",
    "all_all_rand_less_d_df = all_all_rand_distance[(all_all_rand_distance['3_distance'] <max_distance) | \\\n",
    "                                               (all_all_rand_distance['5_distance'] <max_distance) ]\n",
    "all_all_rand_less_d_df_index = all_all_rand_less_d_df.index.values\n",
    "\n",
    "\n",
    "#introduce new column linked and make this 1 were the genes are linked (e.g. less than max distance apart)\n",
    "all_all_rand_distance['linked'] =0\n",
    "all_all_rand_distance.loc[all_all_rand_less_d_df_index, 'linked']  = 1\n",
    "all_all_rand_distance['linkage_group'] = 0\n",
    "\n",
    "\n",
    "\n",
    "for contig in all_all_rand_distance['contig'].unique():\n",
    "    tmp_df = all_all_rand_distance[all_all_rand_distance.contig == contig]\n",
    "    tmp_df['lg'] = 0\n",
    "    #check were the index difference is not one and add it up\n",
    "    tmp_linkage_groups = (tmp_df[tmp_df.linked == 1].linked != tmp_df[tmp_df.linked == 1].linked.index.to_series().diff().eq(1)).cumsum() \n",
    "    all_all_rand_distance.loc[tmp_df[tmp_df.linked == 1].index, 'linkage_group'] =  tmp_linkage_groups\n",
    "    #print(contig)\n",
    "all_all_rand_distance.fillna(0,inplace=True)\n",
    "\n",
    "all_lg_grouped = all_all_rand_distance.groupby(by=['contig', 'linkage_group']).linked.count()\n",
    "\n",
    "all_number_unlinked_effectors = all_lg_grouped.unstack()[0].sum()\n",
    "\n",
    "all_tmp_non_zero_df = all_lg_grouped.unstack().iloc[:,1:]\n",
    "\n",
    "all_tmp_freq_count = all_tmp_non_zero_df.apply(pd.value_counts).sum(axis=1)\n",
    "\n",
    "all_tmp_freq_count = pd.Series([all_number_unlinked_effectors], index=[1.00]).append(all_tmp_freq_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting 5' and 3' distance\n",
    "busco_sub_distance = p_busco_bed_rand_sub_3.merge(p_busco_bed_rand_sub_5, on = ['query','contig'])\n",
    "\n",
    "#convert negative -1 from bedtools closest to nan and make values absolute\n",
    "tmp_index_busco = busco_sub_distance[busco_sub_distance['5_target'] == '.'].index.tolist()\n",
    "busco_sub_distance.loc[tmp_index_busco, '5_distance'] = np.nan\n",
    "busco_sub_distance['5_distance'] = abs(busco_sub_distance['5_distance'])\n",
    "#convert -1 from bedtools closest to nan in 3_distance\n",
    "tmp_index_busco = busco_sub_distance[busco_sub_distance['3_target'] == '.'].index.tolist()\n",
    "busco_sub_distance.loc[tmp_index_busco, '3_distance'] = np.nan\n",
    "\n",
    "#subset the df and get the index\n",
    "busco_less_d_df = busco_sub_distance[(busco_sub_distance['3_distance'] <max_distance) | (busco_sub_distance['5_distance'] <max_distance) ]\n",
    "busco_less_d_df_index = busco_less_d_df.index.values\n",
    "\n",
    "\n",
    "#introduce new column 'linked' and make this 1 were the genes are linked (e.g. less than max distance apart)\n",
    "busco_sub_distance['linked'] =0\n",
    "busco_sub_distance.loc[busco_less_d_df_index, 'linked']  = 1\n",
    "#get a new columns linkage_group that is 0 for now\n",
    "busco_sub_distance['linkage_group'] = 0\n",
    "\n",
    "\n",
    "#now loop over the contigs and connect the consecutive linked effectors (e.g. linked == 1) with a cumsum \n",
    "for contig in busco_sub_distance['contig'].unique():\n",
    "    tmp_df = busco_sub_distance[busco_sub_distance.contig == contig]\n",
    "    #check were the index difference is not one and add it up\n",
    "    tmp_linkage_groups = (tmp_df[tmp_df.linked == 1].linked != tmp_df[tmp_df.linked == 1].linked.index.to_series().diff().eq(1)).cumsum() \n",
    "    busco_sub_distance.loc[tmp_df[tmp_df.linked == 1].index, 'linkage_group'] =  tmp_linkage_groups\n",
    "    \n",
    "#now fill in the nan values in the linkage_group \n",
    "busco_sub_distance.fillna(0,inplace=True)\n",
    "\n",
    "#the count of each linkage group per contig is the number of genes within this linkage group\n",
    "busco_lg_grouped = busco_sub_distance.groupby(by=['contig', 'linkage_group']).linked.count()\n",
    "\n",
    "#sum up the zeros these are the number of unlinked genes/effectors\n",
    "number_unlinked_buscos = busco_lg_grouped.unstack()[0].sum()\n",
    "\n",
    "#the columns correspond to the name of the linkage group and the values to the number of genes contained in each\n",
    "tmp_non_zero_df_busco = busco_lg_grouped.unstack().iloc[:,1:]\n",
    "\n",
    "#count the number of each linkage group size for each abitrary linkage group and sum it up \n",
    "tmp_freq_count_busco = tmp_non_zero_df_busco.apply(pd.value_counts).sum(axis=1)\n",
    "\n",
    "#this gives the frequency of each size of linkage group\n",
    "tmp_freq_count_busco = pd.Series([number_unlinked_buscos], index=[1.00]).append(tmp_freq_count_busco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a dataframe collecting all the frequencies\n",
    "_df = pd.DataFrame([all_tmp_freq_count, tmp_freq_count, tmp_freq_count_busco]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df.rename(columns= {0:'all_genes', 1:'effectors', 2:'buscos'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df['effector_count'] = _df.index.values * _df.effectors\n",
    "_df['gene_count'] = _df.index.values * _df.all_genes\n",
    "_df['busco_count'] = _df.index.values * _df.buscos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df.loc[:,['effector_count', 'gene_count', 'busco_count']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df['group_size'] = _df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df['effector_cumsum']= ['effector_count'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df['gene_cumsum']= _df.sort_values(by='group_size', ascending=False)['gene_count'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df['busco_cumsum']= _df.sort_values(by='group_size', ascending=False)['busco_count'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df.sort_values(by='group_size', ascending=False).loc[:, ['effector_cumsum', 'gene_cumsum', 'busco_cumsum']].plot(colors=['r', 'b', 'g']\\\n",
    "                                                                                                                 )\n",
    "plt.title('Number of genes in cluster with max nearest neigbhour distance = 24kpb')\n",
    "plt.xlabel('cluster size')\n",
    "plt.xlim(21,0)\n",
    "plt.plot(( 0,17), ( 722,722), 'k-',label='Gene N50')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=_df.group_size.sort_values(ascending=False), y=_df.sort_values(by='group_size',\\\n",
    "                                                    ascending=False).loc[:, ['effector_cumsum']], color='r', label='effector_cumsum')\n",
    "plt.scatter(x=_df.group_size.sort_values(ascending=False), y=_df.sort_values(by='group_size',\\\n",
    "                                                    ascending=False).loc[:, ['gene_cumsum']], color='b', label = 'gene_cumsum')\n",
    "plt.scatter(x=_df.group_size.sort_values(ascending=False), y=_df.sort_values(by='group_size',\\\n",
    "                                                    ascending=False).loc[:, ['busco_cumsum']], color='g', label = 'busco_cumsum')\n",
    "plt.xlim(21,0)\n",
    "plt.legend(loc=4)\n",
    "plt.title('Number of genes in cluster with max nearest neigbhour distance = %i' % max_distance)\n",
    "plt.xlabel('cluster size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df.sort_values(by='group_size', ascending=False).loc[:, ['effector_cumsum', 'gene_cumsum', 'busco_cumsum']].plot(colors=['r', 'b', 'g']\\\n",
    "                                                                                                                 )\n",
    "plt.title('Number of genes in cluster with max nearest neigbhour distance = 24kpb')\n",
    "plt.xlabel('cluster size')\n",
    "plt.xlim(21,0)\n",
    "plt.plot(( 0,17), ( 722,722), 'k-',label='Gene N50')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look for the only cloned Avr homologe from Pgt\n",
    "e_to_e_sub_distance[e_to_e_sub_distance['query'] == 'evm.TU.pcontig_013.278']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_to_e_sub_distance[(e_to_e_sub_distance.contig == 'pcontig_013') & (e_to_e_sub_distance.linkage_group == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at the different distance dataframes to explore them further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_all_rand_merged[((all_all_rand_merged['5_distance'])< 10000)|((all_all_rand_merged['3_distance'])< 10000)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed_rand_sub_merged[((p_busco_bed_rand_sub_merged['5_distance'])< 20000)|((p_busco_bed_rand_sub_merged['3_distance'])< 20000)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_to_e_sub_merged[(e_to_e_sub_merged['3_distance'] < 150000)|(e_to_e_sub_merged['5_distance'] < 150000)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_to_e_sub_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_to_e_sub_5['abs_5_distance'] = abs(e_to_e_sub_5['5_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_to_e_sub_5.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#subset everything by fixed numbers maybe to IQR or such in future\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged[(e_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (e_to_g_merged['3_distance'] < 10000)], kind=\"hex\", color='r',xlim=[0,10000], ylim=[0,10000],\\\n",
    "             marginal_kws=dict(bins=30))\n",
    "\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged[(b_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (b_to_g_merged['3_distance'] < 10000)], kind=\"hex\",color='g', xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged[(g_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (g_to_g_merged['3_distance'] < 10000)], kind=\"hex\", xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at allele analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_QC_fn = os.path.join('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/alleles'\\\n",
    "                           , 'Pst_104E_v12_p_ctg.h_contig_overlap.Qcov80.PctID70.alleles')\n",
    "\n",
    "allele_blast_df_fn = os.path.join('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis' ,'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis')\n",
    "\n",
    "alleles_df = pd.read_csv(allele_QC_fn, header=None, sep = '\\t', names=['p_protein', 'h_protein'])\n",
    "alleles_df['match'] = alleles_df.p_protein + alleles_df.h_protein\n",
    "\n",
    "allele_blast_df = pd.read_csv(allele_blast_df_fn, sep='\\t')\n",
    "allele_blast_df['match'] = allele_blast_df.Query + allele_blast_df.Target\n",
    "\n",
    "allele_blast_df = allele_blast_df[(allele_blast_df.match.isin(alleles_df.match))]\n",
    "\n",
    "len(allele_blast_df)\n",
    "\n",
    "allele_blast_df.head()\n",
    "\n",
    "allele_blast_df[(allele_blast_df.Query.isin(p_effector_list))]['PctID'].mean()\n",
    "\n",
    "allele_blast_df[~(allele_blast_df.Query.isin(p_effector_list))]['PctID'].mean()\n",
    "\n",
    "print(len(allele_blast_df[(allele_blast_df.Query.isin(p_effector_list))])/len(p_effector_list))\n",
    "\n",
    "print(len(allele_blast_df)/len(p_allgene_bed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
