{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at looked at the allele analysis output a bit more interms of what are the alleles. What is missing? What is the GO term enrichment in those if any? How much are effectors?....\n",
    "The input is based on the following ideas:\n",
    "\n",
    "\n",
    "the idea is to label alleles, non_allelic 'orthologs' singeltons, and single nuclear genes.\n",
    "* alleles are bast on proteinortho -synteny flag\n",
    "* non_allelic 'orthologs' are genes that cluster on the protein level but are not allelic\n",
    "* singeltons are genes without ‘ortholog’ in the other haplotype\n",
    "* single haplotype genes are genes that have no gene to genome blast hit e_value = 1e-2 and are not in a homozygous region.\n",
    "\n",
    "Final analysis is based on Pst_104E_v12_missing_allele_QC_v03.ipynb and Pst_104E_v12_defining_alleles_v03.ipynb in folder \n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01 and alleles_proteinortho_graph516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import SeqUtils\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwh_set = []\n",
    "def pwh_filter (q_contig, pwh_set=pwh_set):\n",
    "    '''Checks if contig belongs to the primary with haplotig set.'''\n",
    "    if q_contig in pwh_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_primary_contig (q_contig):\n",
    "    '''Quick function that checks if query is on primary contig or not'''\n",
    "    if q_contig.startswith('hcontig'):\n",
    "        return False\n",
    "    elif q_contig.startswith('pcontig'):\n",
    "        return True\n",
    "    else:\n",
    "        print('Contig annotation needs to start with hcontig or pcontig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "BLAST_RESULT_PATH = os.path.join(BASE_AA_PATH,'allele_analysis' )\n",
    "ALLELE_PATH =os.path.join(BASE_AA_PATH ,'allele_analysis/alleles_proteinortho_graph516')\n",
    "ALLELE_QC_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis', \\\n",
    "                              'no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "LIST_PATH = os.path.join(BASE_AA_PATH, 'enrichment_analysis', 'lists')\n",
    "POST_ALLELE_PATH = os.path.join(BASE_AA_PATH, 'post_allele_analysis')\n",
    "OUT_PATH = os.path.join(POST_ALLELE_PATH, 'proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "if not os.path.exists(POST_ALLELE_PATH):\n",
    "    os.mkdir(POST_ALLELE_PATH)\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n",
    "ph_gene_fasta = os.path.join(BASE_A_PATH , 'Pst_104E_v12_ph_ctg.anno.gene.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the alleles in as they are not filtered by QCov and PctID but simply taken straight from the \n",
    "# proteinortho\n",
    "allele_header = ['p_gene', 'h_gene']\n",
    "a_overlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_overlap_df['Linkage'] = 'h_contig_overlap'\n",
    "a_no_roverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_roverlap_df['Linkage'] = 'no_r_overlap'\n",
    "a_no_soverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_soverlap_df['Linkage'] = 'no_s_overlap'\n",
    "allele_df = pd.concat([a_overlap_df, a_no_roverlap_df, a_no_soverlap_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy over allele files to OUTPATH\n",
    "os.chdir(ALLELE_PATH)\n",
    "!cp Pst_104E_v12_p_ctg.h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles {OUT_PATH}/. \n",
    "!cat Pst_104E_v12_p_ctg.h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles > {OUT_PATH}/Pst_104E_v12_p_ctg.all.alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#get the blast dataframe and the QC dataframe\n",
    "allele_blast_df = pd.read_csv(os.path.join(BLAST_RESULT_PATH, 'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis'), sep='\\t')\n",
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')\n",
    "allele_QC_df = allele_QC_df[~((allele_QC_df.Query.isin(allele_df.p_gene))|(allele_QC_df.Query.isin(allele_df.h_gene)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check if all the numbers of genes add up\n",
    "len(allele_df.p_gene.unique())+ len(allele_df.h_gene.unique())+len(allele_QC_df.Query.unique()) == 30249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now write out all no_allele_orthologs\n",
    "no_allele_orthologs_fn = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.no_alleles_orthologs')\n",
    "no_allele_orthologs = allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique()\n",
    "tmp_fh = open(no_allele_orthologs_fn, 'w')\n",
    "for _id in allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique():\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out singeltons\n",
    "singeltons_fh = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.singletons')\n",
    "singeltons = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.ph_p_homo_region != True)][\"Query\"].unique()\n",
    "tmp_fh = open(singeltons_fh , 'w')\n",
    "for _id in singeltons:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out single nuclear genes\n",
    "shg_df = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.gene_on_genome_blast_hit != True)\\\n",
    "            &(allele_QC_df.ph_p_homo_region != True)].copy()\n",
    "shg_fh = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.single_haplotype_genes')\n",
    "shg = shg_df.Query.unique()\n",
    "tmp_fh = open(shg_fh, 'w')\n",
    "for _id in shg:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in some types of genes\n",
    "gene_group_list = ['BUSCOS', 'EFFECTORS', 'HAUSTORIA', 'EFFECTORP']\n",
    "p_gene_dict = {}\n",
    "h_gene_dict = {}\n",
    "p_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_cluster_8.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_cluster_15.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "#now get pwh and pwoh\n",
    "pwh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwh.txt')\\\n",
    "                                , header=None)[0].tolist()\n",
    "pwoh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwoh.txt')\\\n",
    "                                , header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwh contigs\n",
      "1523\n"
     ]
    }
   ],
   "source": [
    "#cause we are a bit lazy an like notebooks here we go looking for stuff\n",
    "os.chdir(BASE_A_PATH)\n",
    "print(\"Effectors on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"Effectors on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwh contigs\n",
      "1395\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on hcontigs\n",
      "1293 /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists/Pst_104E_v12_h_busco.gene.gff3\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on hcontigs\")\n",
    "!wc -l {LIST_PATH}/Pst_104E_v12_h_busco.gene.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "def orphan_analysis(_orphan_list):\n",
    "    orphan_effectors = 0\n",
    "    orphan_effectors_h = 0\n",
    "    orphan_effectors_pwh = 0\n",
    "    orphan_effectors_pwoh =0\n",
    "    orphan_busco = 0\n",
    "    orphan_busco_h = 0\n",
    "    orphan_busco_pwh = 0\n",
    "    orphan_busco_pwoh = 0\n",
    "    for x in _orphan_list:\n",
    "        if x in p_gene_dict['BUSCOS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_busco_pwh += 1\n",
    "            else:\n",
    "                orphan_busco_pwoh += 1\n",
    "        if x in h_gene_dict['BUSCOS']:\n",
    "            orphan_busco_h += 1\n",
    "        #now same for effectors    \n",
    "        if x in p_gene_dict['EFFECTORS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_effectors_pwh += 1\n",
    "            else:\n",
    "                orphan_effectors_pwoh += 1\n",
    "            \n",
    "        if x in h_gene_dict['EFFECTORS']:\n",
    "            orphan_effectors_h += 1      \n",
    "    orphan_effectors = orphan_effectors_h + orphan_effectors_pwh + orphan_effectors_pwoh\n",
    "    orphan_busco = orphan_busco_h +  orphan_busco_pwh +  orphan_busco_pwoh\n",
    "    print('Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "          %(len(_orphan_list), orphan_busco, orphan_effectors))\n",
    "    print('On haplotigs. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %(len([x for x in _orphan_list if 'hcontig' in x]), orphan_busco_h, orphan_effectors_h))\n",
    "    print('On pwh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list].count(True), orphan_busco_pwh, orphan_effectors_pwh))\n",
    "    print('On pwoh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list if 'pcontig' in x].count(False), orphan_busco_pwoh, orphan_effectors_pwoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes without clear allele:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7912"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of genes without clear allele:\")\n",
    "len(allele_QC_df[allele_QC_df.ph_p_homo_region != True]['Query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1506 orphan genes we have 125 orphan buscos and 120 orphan effectors.\n",
      "On haplotigs. Out of 160 orphan genes we have 6 orphan buscos and 5 orphan effectors.\n",
      "On pwh. Out of 1149 orphan genes we have 93 orphan buscos and 98 orphan effectors.\n",
      "On pwoh. Out of 197 orphan genes we have 26 orphan buscos and 17 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "orphan_analysis(shg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 7029 orphan genes we have 234 orphan buscos and 453 orphan effectors.\n",
      "On haplotigs. Out of 2931 orphan genes we have 57 orphan buscos and 153 orphan effectors.\n",
      "On pwh. Out of 3700 orphan genes we have 147 orphan buscos and 270 orphan effectors.\n",
      "On pwoh. Out of 398 orphan genes we have 30 orphan buscos and 30 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "orphan_analysis(singeltons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#set the coverage limits\n",
    "QCov_limit = 80\n",
    "PctID_limit = 70\n",
    "#now get all the ids for which we have hits above the cut off and are singletons\n",
    "tmp_df = allele_QC_df[allele_QC_df.Target != 'False'] #filter out no hits\n",
    "tmp_df[['QCov', 'PctID']] = tmp_df[['QCov', 'PctID']].apply(pd.to_numeric) #make numeric\n",
    "#get ids of stuff above the cut off\n",
    "tmp_df_ids = tmp_df[(tmp_df.QCov >= QCov_limit) & (tmp_df.PctID >= PctID_limit)]['Query'].unique()\n",
    "#filter those out and everything that is not a singleton\n",
    "tmp_df = allele_QC_df[~((allele_QC_df.Query.isin(tmp_df_ids)) | (allele_QC_df.singeltons == False))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3191 orphan genes we have 180 orphan buscos and 207 orphan effectors.\n",
      "On haplotigs. Out of 942 orphan genes we have 26 orphan buscos and 34 orphan effectors.\n",
      "On pwh. Out of 1998 orphan genes we have 126 orphan buscos and 152 orphan effectors.\n",
      "On pwoh. Out of 251 orphan genes we have 28 orphan buscos and 21 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3991 orphan genes we have 190 orphan buscos and 303 orphan effectors.\n",
      "On haplotigs. Out of 1335 orphan genes we have 31 orphan buscos and 83 orphan effectors.\n",
      "On pwh. Out of 2393 orphan genes we have 131 orphan buscos and 198 orphan effectors.\n",
      "On pwoh. Out of 263 orphan genes we have 28 orphan buscos and 22 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter =  (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 534 orphan genes we have 62 orphan buscos and 44 orphan effectors.\n",
      "On haplotigs. Out of 0 orphan genes we have 0 orphan buscos and 0 orphan effectors.\n",
      "On pwh. Out of 474 orphan genes we have 57 orphan buscos and 43 orphan effectors.\n",
      "On pwoh. Out of 60 orphan genes we have 5 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 550 orphan genes we have 62 orphan buscos and 45 orphan effectors.\n",
      "On haplotigs. Out of 0 orphan genes we have 0 orphan buscos and 0 orphan effectors.\n",
      "On pwh. Out of 488 orphan genes we have 57 orphan buscos and 44 orphan effectors.\n",
      "On pwoh. Out of 62 orphan genes we have 5 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.ph_p_homo_region == True) \n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.homozygous_coverage' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 816 orphan genes we have 10 orphan buscos and 97 orphan effectors.\n",
      "On haplotigs. Out of 393 orphan genes we have 5 orphan buscos and 49 orphan effectors.\n",
      "On pwh. Out of 409 orphan genes we have 5 orphan buscos and 47 orphan effectors.\n",
      "On pwoh. Out of 14 orphan genes we have 0 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.exonerate_hits' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4541"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_df.Query.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 809 orphan genes we have 10 orphan buscos and 96 orphan effectors.\n",
      "On haplotigs. Out of 393 orphan genes we have 5 orphan buscos and 49 orphan effectors.\n",
      "On pwh. Out of 404 orphan genes we have 5 orphan buscos and 46 orphan effectors.\n",
      "On pwoh. Out of 12 orphan genes we have 0 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 2739 orphan genes we have 62 orphan buscos and 240 orphan effectors.\n",
      "On haplotigs. Out of 1448 orphan genes we have 33 orphan buscos and 126 orphan effectors.\n",
      "On pwh. Out of 1212 orphan genes we have 27 orphan buscos and 105 orphan effectors.\n",
      "On pwoh. Out of 79 orphan genes we have 2 orphan buscos and 9 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#do filtering of the whole dataframe with QCov and PctID\n",
    "#now make new filter for the following\n",
    "out_filter = (allele_QC_df.exn_asso_contig == True) | (allele_QC_df.exn_no_asso_contig == True) \n",
    "queries_out_filtered = allele_QC_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some features of the orphan genes such as:\n",
    "* gene/protein length\n",
    "* gc content\n",
    "* numbers of exons\n",
    "* distance to TEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349.0830013280212"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now look at single haplotype genes\n",
    "shg_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.5913485685585"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_blast_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8498250071590965, pvalue=1.2357044232530989e-06)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ranksums(shg_df.drop_duplicates('Query')['QLgth'],allele_blast_df.drop_duplicates('Query')['QLgth'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the len per gene in the list plus the len\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(len(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(len(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GC_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the GC content per gene in the list plus the GC content\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(SeqUtils.GC(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(SeqUtils.GC(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_gene_fasta(gene_list, gg_fasta):\n",
    "    '''Returns the fasta of gene in list as SeqIO object '''\n",
    "    genes_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            genes_fasta.append(x)\n",
    "    return genes_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_contig_fasta(contig_list, gg_fasta):\n",
    "    '''Returns the fasta of contig in list as SeqIO object '''\n",
    "    contig_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id in contig_list:\n",
    "            contig_fasta.append(x)\n",
    "    return contig_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "shg_GC, genome_GC = GC_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.936932047 45.7863006323\n"
     ]
    }
   ],
   "source": [
    "#gc content per gene\n",
    "print(np.mean(shg_GC), np.mean(genome_GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=1.7879649018298396, pvalue=0.073781670619541995)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "stats.ranksums(shg_GC, genome_GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gene length\n",
    "shg_len, genome_len = len_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334.79282869 1538.62967371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8395122876180281, pvalue=1.3015814430474663e-06)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "print(np.mean(shg_len), np.mean(genome_len))\n",
    "stats.ranksums(shg_len, genome_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gene fastas and save those\n",
    "shg_fasta = return_gene_fasta(shg, ph_gene_fasta)\n",
    "shg_fn = os.path.join(OUT_PATH, \"Pst_104E_ph_ctg.single_haplotype_genes.fasta\")\n",
    "with open(shg_fn, 'w') as fh:\n",
    "    SeqIO.write(shg_fasta, fh, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pick a couple of the non_respective_haplotype alignements and get sequencing data for those to make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_respective_alleles_fn = os.path.join(ALLELE_PATH, 'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles')\n",
    "contig_fa_fn = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.fa')\n",
    "gene_fa_fn = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.anno.gene.fa')\n",
    "OUT_PATH_NO_RES = os.path.join(OUT_PATH, 'no_respect_fasta')\n",
    "if not os.path.exists(OUT_PATH_NO_RES):\n",
    "    os.mkdir(OUT_PATH_NO_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_respective_alleles_df = pd.read_csv(no_respective_alleles_fn, sep='\\t', header=None, names=['pgene', 'hgene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#get the contig genes are on\n",
    "no_respective_alleles_df['pcontig'] = no_respective_alleles_df.pgene.str.extract(r'(p[^.]*)')\n",
    "no_respective_alleles_df['hcontig'] = no_respective_alleles_df.hgene.str.extract(r'(h[^.]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for filtering on most hit contigs. First by a group by function\n",
    "no_ra_linkage_count_df = no_respective_alleles_df.groupby(['pcontig','hcontig'])['pgene'].count()\n",
    "no_ra_linkage_count_max = no_respective_alleles_df.groupby(['pcontig','hcontig'])['pgene']\\\n",
    "            .count().max(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ra_linkage_count_df = no_ra_linkage_count_df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_contig_list = []\n",
    "most_linked_hcontig = []\n",
    "number_of_hits = []\n",
    "for _index, row in no_ra_linkage_count_df.iterrows():\n",
    "    if row.max() > 2:\n",
    "        p_contig_list.append(_index)\n",
    "        most_linked_hcontig.append(row[row==no_ra_linkage_count_max[_index]].index.tolist()[0])\n",
    "        number_of_hits.append(row[row==no_ra_linkage_count_max[_index]].max())\n",
    "        #print('primary contig %s and %s overlaps %i' %\\\n",
    "              #(_index, row[row==no_ra_linkage_count_max[_index]].index.tolist()[0],row[row==no_ra_linkage_count_max[_index]].max() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df = pd.concat([pd.Series(p_contig_list)\\\n",
    "                            , pd.Series(most_linked_hcontig), pd.Series(number_of_hits)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df.rename(columns={0:'pcontig', 1:'hcontig', 2:'number_of_overlaps'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now loop over the best hit dataframe to get all the fasta sequences of the repective alleles\n",
    "\n",
    "for _index, row in most_linked_non_ra_alleles_df.iterrows():\n",
    "    tmp_p_contig = row['pcontig']\n",
    "    tmp_h_contig = row['hcontig']\n",
    "    h_genes = no_respective_alleles_df[(no_respective_alleles_df.pcontig==tmp_p_contig)&\\\n",
    "                                      (no_respective_alleles_df.hcontig==tmp_h_contig)]\\\n",
    "                                        ['hgene'].unique()\n",
    "    p_genes = no_respective_alleles_df[(no_respective_alleles_df.pcontig==tmp_p_contig)&\\\n",
    "                                      (no_respective_alleles_df.hcontig==tmp_h_contig)]\\\n",
    "                                        ['pgene'].unique()\n",
    "    #get the h_gene and p_gene sequenes\n",
    "    h_gene_seq = return_gene_fasta(h_genes, gene_fa_fn)\n",
    "    p_gene_seq = return_gene_fasta(p_genes, gene_fa_fn)\n",
    "    fh = open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_gene.fa' %tmp_p_contig), 'w')\n",
    "    SeqIO.write(p_gene_seq+h_gene_seq, fh, 'fasta')\n",
    "    fh.close()\n",
    "    #get the contig sequences\n",
    "    p_contig_seq = return_contig_fasta([tmp_p_contig], contig_fa_fn)\n",
    "    h_contig_seq = return_contig_fasta([tmp_h_contig], contig_fa_fn)\n",
    "    fh = open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_contig.fa' %tmp_p_contig), 'w')\n",
    "    SeqIO.write(p_contig_seq+h_contig_seq, fh, 'fasta')\n",
    "    fh.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcontig</th>\n",
       "      <th>hcontig</th>\n",
       "      <th>number_of_overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pcontig_042</td>\n",
       "      <td>hcontig_000_054</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pcontig_086</td>\n",
       "      <td>hcontig_225_001</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pcontig_040</td>\n",
       "      <td>hcontig_032_001</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pcontig_087</td>\n",
       "      <td>hcontig_072_099</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pcontig_032</td>\n",
       "      <td>hcontig_030_011</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pcontig_091</td>\n",
       "      <td>hcontig_044_023</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pcontig_029</td>\n",
       "      <td>hcontig_012_028</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pcontig_104</td>\n",
       "      <td>hcontig_016_024</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pcontig_170</td>\n",
       "      <td>hcontig_072_009</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pcontig_021</td>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pcontig_013</td>\n",
       "      <td>hcontig_000_054</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pcontig_173</td>\n",
       "      <td>hcontig_034_113</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pcontig_009</td>\n",
       "      <td>hcontig_057_003</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pcontig_200</td>\n",
       "      <td>hcontig_020_132</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pcontig_007</td>\n",
       "      <td>hcontig_018_022</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pcontig_225</td>\n",
       "      <td>hcontig_002_028</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pcontig_003</td>\n",
       "      <td>hcontig_005_021</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pcontig_014</td>\n",
       "      <td>hcontig_027_006</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pcontig_058</td>\n",
       "      <td>hcontig_005_021</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pcontig_079</td>\n",
       "      <td>hcontig_048_122</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pcontig_186</td>\n",
       "      <td>hcontig_009_029</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcontig_001</td>\n",
       "      <td>hcontig_042_009</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pcontig_025</td>\n",
       "      <td>hcontig_095_133</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pcontig_008</td>\n",
       "      <td>hcontig_001_054</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pcontig_248</td>\n",
       "      <td>hcontig_129_001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pcontig_031</td>\n",
       "      <td>hcontig_166_001</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pcontig_100</td>\n",
       "      <td>hcontig_189_001</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pcontig_023</td>\n",
       "      <td>hcontig_031_159</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pcontig_012</td>\n",
       "      <td>hcontig_028_011</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pcontig_174</td>\n",
       "      <td>hcontig_088_002</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pcontig_046</td>\n",
       "      <td>hcontig_039_005</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pcontig_233</td>\n",
       "      <td>hcontig_066_107</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pcontig_037</td>\n",
       "      <td>hcontig_086_003</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pcontig_005</td>\n",
       "      <td>hcontig_004_020</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pcontig_045</td>\n",
       "      <td>hcontig_027_102</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pcontig_010</td>\n",
       "      <td>hcontig_019_085</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pcontig_103</td>\n",
       "      <td>hcontig_031_007</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pcontig          hcontig  number_of_overlaps\n",
       "18  pcontig_042  hcontig_000_054                 3.0\n",
       "23  pcontig_086  hcontig_225_001                 3.0\n",
       "17  pcontig_040  hcontig_032_001                 3.0\n",
       "24  pcontig_087  hcontig_072_099                 3.0\n",
       "15  pcontig_032  hcontig_030_011                 3.0\n",
       "25  pcontig_091  hcontig_044_023                 3.0\n",
       "13  pcontig_029  hcontig_012_028                 3.0\n",
       "28  pcontig_104  hcontig_016_024                 3.0\n",
       "29  pcontig_170  hcontig_072_009                 3.0\n",
       "10  pcontig_021  hcontig_000_003                 3.0\n",
       "8   pcontig_013  hcontig_000_054                 3.0\n",
       "30  pcontig_173  hcontig_034_113                 3.0\n",
       "5   pcontig_009  hcontig_057_003                 3.0\n",
       "33  pcontig_200  hcontig_020_132                 3.0\n",
       "3   pcontig_007  hcontig_018_022                 3.0\n",
       "34  pcontig_225  hcontig_002_028                 3.0\n",
       "1   pcontig_003  hcontig_005_021                 3.0\n",
       "9   pcontig_014  hcontig_027_006                 3.0\n",
       "21  pcontig_058  hcontig_005_021                 3.0\n",
       "22  pcontig_079  hcontig_048_122                 4.0\n",
       "32  pcontig_186  hcontig_009_029                 4.0\n",
       "0   pcontig_001  hcontig_042_009                 4.0\n",
       "12  pcontig_025  hcontig_095_133                 4.0\n",
       "4   pcontig_008  hcontig_001_054                 4.0\n",
       "36  pcontig_248  hcontig_129_001                 4.0\n",
       "14  pcontig_031  hcontig_166_001                 5.0\n",
       "26  pcontig_100  hcontig_189_001                 5.0\n",
       "11  pcontig_023  hcontig_031_159                 5.0\n",
       "7   pcontig_012  hcontig_028_011                 5.0\n",
       "31  pcontig_174  hcontig_088_002                 5.0\n",
       "20  pcontig_046  hcontig_039_005                 5.0\n",
       "35  pcontig_233  hcontig_066_107                 6.0\n",
       "16  pcontig_037  hcontig_086_003                 6.0\n",
       "2   pcontig_005  hcontig_004_020                 6.0\n",
       "19  pcontig_045  hcontig_027_102                10.0\n",
       "6   pcontig_010  hcontig_019_085                11.0\n",
       "27  pcontig_103  hcontig_031_007                26.0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_linked_non_ra_alleles_df.sort_values('number_of_overlaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcontig_greater_2000.txt\t    Pst_104E_v12_p_ctg.fa\r\n",
      "hcontig_smaller_2000.txt\t    Pst_104E_v12_p_ctg.fa.fai\r\n",
      "pcontig_greater_2000.txt\t    Pst_104E_v12_p_ctg.genome_file\r\n",
      "pcontig_smaller_2000.txt\t    Pst_104E_v12_p_ctg.REPET.gff\r\n",
      "Pst_104E_v12_h_ctg.anno.CDS.fa\t    Pst_104E_v12_ph_ctg.anno.CDS.fa\r\n",
      "Pst_104E_v12_h_ctg.anno.CDS.gff3    Pst_104E_v12_ph_ctg.anno.CDS.gff3\r\n",
      "Pst_104E_v12_h_ctg.anno.gene.fa     Pst_104E_v12_ph_ctg.anno.gene.fa\r\n",
      "Pst_104E_v12_h_ctg.anno.gff3\t    Pst_104E_v12_ph_ctg.anno.gff3\r\n",
      "Pst_104E_v12_h_ctg.anno.protein.fa  Pst_104E_v12_ph_ctg.anno.protein.fa\r\n",
      "Pst_104E_v12_h_ctg.fa\t\t    Pst_104E_v12_ph_ctg.fa\r\n",
      "Pst_104E_v12_h_ctg.fa.fai\t    Pst_104E_v12_ph_ctg.fa.fai\r\n",
      "Pst_104E_v12_h_ctg.genome_file\t    Pst_104E_v12_ph_ctg.REPET.gff\r\n",
      "Pst_104E_v12_h_ctg.REPET.gff\t    Pst_104E_v12_pwh_ctg.anno.gff3\r\n",
      "Pst_104E_v12_p_ctg.anno.CDS.fa\t    Pst_104E_v12_pwh.txt\r\n",
      "Pst_104E_v12_p_ctg.anno.CDS.gff3    Pst_104E_v12_pwoh_ctg.anno.gff3\r\n",
      "Pst_104E_v12_p_ctg.anno.gene.fa     Pst_104E_v12_pwoh.txt\r\n",
      "Pst_104E_v12_p_ctg.anno.gff3\t    README.txt\r\n",
      "Pst_104E_v12_p_ctg.anno.protein.fa\r\n"
     ]
    }
   ],
   "source": [
    "!ls {BASE_A_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.QCov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QP_filter = (allele_QC_df.QCov >= QCov_limit) & (allele_QC_df.PctID >= PctID_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now a bit more specific for each haplotyp\n",
    "os.chdir(ALLELE_QC_PATH)\n",
    "allele_blast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
