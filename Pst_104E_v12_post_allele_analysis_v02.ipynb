{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at looked at the allele analysis output a bit more interms of what are the alleles. What is missing? What is the GO term enrichment in those if any? How much are effectors?....\n",
    "The input is based on the following ideas:\n",
    "\n",
    "\n",
    "the idea is to label alleles, singeltons, and single nuclear genes.\n",
    "* alleles are bast on proteinortho -synteny flag\n",
    "* singeltons are genes without ‘ortholog’ in the other haplotype\n",
    "* single nuclear genes are genes that have no gene to genome blast hit e_value = 1e-2 and are not in a homozygous region.\n",
    "\n",
    "Final analysis is based on Pst_104E_v12_missing_allele_QC_v03.ipynb and Pst_104E_v12_defining_alleles_v03.ipynb in folder \n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01 and alleles_proteinortho_graph516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwh_set = []\n",
    "def pwh_filter (q_contig, pwh_set=pwh_set):\n",
    "    '''Checks if contig belongs to the primary with haplotig set.'''\n",
    "    if q_contig in pwh_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_primary_contig (q_contig):\n",
    "    '''Quick function that checks if query is on primary contig or not'''\n",
    "    if q_contig.startswith('hcontig'):\n",
    "        return False\n",
    "    elif q_contig.startswith('pcontig'):\n",
    "        return True\n",
    "    else:\n",
    "        print('Contig annotation needs to start with hcontig or pcontig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "BLAST_RESULT_PATH = os.path.join(BASE_AA_PATH,'allele_analysis' )\n",
    "ALLELE_PATH =os.path.join(BASE_AA_PATH ,'allele_analysis/alleles_proteinortho_graph516')\n",
    "ALLELE_QC_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis', \\\n",
    "                              'no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "LIST_PATH = os.path.join(BASE_AA_PATH, 'enrichment_analysis', 'lists')\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'post_allele_analysis')\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some input files an make allele dataframe\n",
    "allele_header = ['p_gene', 'h_gene']\n",
    "a_overlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_overlap_df['Linkage'] = 'h_contig_overlap'\n",
    "a_no_roverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_roverlap_df['Linkage'] = 'no_r_overlap'\n",
    "a_no_soverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_soverlap_df['Linkage'] = 'no_s_overlap'\n",
    "allele_df = pd.concat([a_overlap_df, a_no_roverlap_df, a_no_soverlap_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some input files and get no allele dataframe\n",
    "#no allele dataframe will be updated based on gene blast hits\n",
    "no_allele_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_postQC.txt')\\\n",
    "                          ,header=None, names=['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#get the blast dataframe and the QC dataframe\n",
    "allele_blast_df = pd.read_csv(os.path.join(BLAST_RESULT_PATH, 'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis'), sep='\\t')\n",
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in some types of genes\n",
    "gene_group_list = ['BUSCOS', 'EFFECTORS', 'HAUSTORIA', 'EFFECTORP']\n",
    "p_gene_dict = {}\n",
    "h_gene_dict = {}\n",
    "p_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_cluster_8.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_cluster_15.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "#now get pwh and pwoh\n",
    "pwh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwh.txt')\\\n",
    "                                , header=None)[0].tolist()\n",
    "pwoh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwoh.txt')\\\n",
    "                                , header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwh contigs\n",
      "1523\n"
     ]
    }
   ],
   "source": [
    "#cause we are a bit lazy an like notebooks here we go looking for stuff\n",
    "os.chdir(BASE_A_PATH)\n",
    "print(\"Effectors on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"Effectors on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwh contigs\n",
      "1395\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on hcontigs\n",
      "1293 /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists/Pst_104E_v12_h_busco.gene.gff3\r\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on hcontigs\")\n",
    "!wc -l {LIST_PATH}/Pst_104E_v12_h_busco.gene.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "def orphan_analysis(_orphan_list):\n",
    "    orphan_effectors = 0\n",
    "    orphan_effectors_h = 0\n",
    "    orphan_effectors_pwh = 0\n",
    "    orphan_effectors_pwoh =0\n",
    "    orphan_busco = 0\n",
    "    orphan_busco_h = 0\n",
    "    orphan_busco_pwh = 0\n",
    "    orphan_busco_pwoh = 0\n",
    "    for x in _orphan_list:\n",
    "        if x in p_gene_dict['BUSCOS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_busco_pwh += 1\n",
    "            else:\n",
    "                orphan_busco_pwoh += 1\n",
    "        if x in h_gene_dict['BUSCOS']:\n",
    "            orphan_busco_h += 1\n",
    "        #now same for effectors    \n",
    "        if x in p_gene_dict['EFFECTORS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_effectors_pwh += 1\n",
    "            else:\n",
    "                orphan_effectors_pwoh += 1\n",
    "            \n",
    "        if x in h_gene_dict['EFFECTORS']:\n",
    "            orphan_effectors_h += 1      \n",
    "    orphan_effectors = orphan_effectors_h + orphan_effectors_pwh + orphan_effectors_pwoh\n",
    "    orphan_busco = orphan_busco_h +  orphan_busco_pwh +  orphan_busco_pwoh\n",
    "    print('Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "          %(len(_orphan_list), orphan_busco, orphan_effectors))\n",
    "    print('On haplotigs. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %(len([x for x in _orphan_list if 'hcontig' in x]), orphan_busco_h, orphan_effectors_h))\n",
    "    print('On pwh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list].count(True), orphan_busco_pwh, orphan_effectors_pwh))\n",
    "    print('On pwoh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list if 'pcontig' in x].count(False), orphan_busco_pwoh, orphan_effectors_pwoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 894 orphan genes we have 83 orphan buscos and 30 orphan effectors.\n",
      "On haplotigs. Out of 169 orphan genes we have 4 orphan buscos and 4 orphan effectors.\n",
      "On pwh. Out of 640 orphan genes we have 65 orphan buscos and 25 orphan effectors.\n",
      "On pwoh. Out of 85 orphan genes we have 14 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "orphan_analysis(no_allele_df.gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_allele_df['contig'] = no_allele_df.gene.str.extract(r'([hp][^.]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_allele_df['pwh'] = no_allele_df.contig.apply(lambda x: pwh_filter(x, pwh_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_allele_df['pcontig'] = no_allele_df.contig.apply(lambda x: on_primary_contig(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no alleles on pwoh\n",
    "(no_allele_df.pwh == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((no_allele_df.pwh == False) & (no_allele_df.pcontig == True)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((no_allele_df.pwh == False) & (no_allele_df.pcontig == False)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do some more filtering and see what is happening\n",
    "allele_QC_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the coverage limits\n",
    "QCov_limit = 70\n",
    "PctID_limit = 80\n",
    "#now get all the ids for which we have hits above the cut off\n",
    "tmp_df = allele_QC_df[allele_QC_df.Target != 'False'] #filter out no hits\n",
    "tmp_df[['QCov', 'PctID']] = tmp_df[['QCov', 'PctID']].apply(pd.to_numeric) #make numeric\n",
    "#get ids of stuff above the cut off\n",
    "tmp_df_ids = tmp_df[(tmp_df.QCov >= QCov_limit) & (tmp_df.PctID >= PctID_limit)]['Query'].unique()\n",
    "#filter those out\n",
    "tmp_df = tmp_df[~tmp_df.Query.isin(tmp_df_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate.txt' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.orphan.PctID%i_QCov%i.no_exonerate.list' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.orphan.PctID%i_QCov%i.no_exonerate.list' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter =  (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.txt' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.orphan.PctID%i_QCov%i.list' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.orphan.PctID%i_QCov%i.list' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.ph_p_homo_region == True) \n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.homozygous_coverage.txt' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.exonerate_hits.txt' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_df.Query.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do filtering of the whole dataframe with QCov and PctID\n",
    "#now make new filter for the following\n",
    "out_filter = (allele_QC_df.exn_asso_contig == True) | (allele_QC_df.exn_no_asso_contig == True) \n",
    "queries_out_filtered = allele_QC_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some features of the orphan genes such as:\n",
    "* gene/protein length\n",
    "* gc content\n",
    "* numbers of exons\n",
    "* distance to TEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter =  (tmp_df.ph_p_homo_region != True)\n",
    "filtered_tmp_df = tmp_df[out_filter]\n",
    "filtered_tmp_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_blast_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots()\n",
    "sns.boxplot(y=filtered_tmp_df.drop_duplicates('Query')['QLgth'])\n",
    "sns.boxplot(y=allele_blast_df.drop_duplicates('Query')['QLgth'])\n",
    "plt.ylim(0, 5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(allele_blast_df.drop_duplicates('Query')['QLgth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ranksums(filtered_tmp_df.drop_duplicates('Query')['QLgth'],allele_blast_df.drop_duplicates('Query')['QLgth'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get http://geneontology.org/ontology/go-basic.obo\n",
    "from goatools.base import download_go_basic_obo\n",
    "obo_fname = download_go_basic_obo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move on to do some enrichment analysis for GO terms needs to be done \n",
    "Looking at the command line this seems all a bit silly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.QCov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QP_filter = (allele_QC_df.QCov >= QCov_limit) & (allele_QC_df.PctID >= PctID_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now a bit more specific for each haplotyp\n",
    "os.chdir(ALLELE_QC_PATH)\n",
    "allele_blast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
