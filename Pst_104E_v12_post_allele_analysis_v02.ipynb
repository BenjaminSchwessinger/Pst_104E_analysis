{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at looked at the allele analysis output a bit more interms of what are the alleles. What is missing? What is the GO term enrichment in those if any? How much are effectors?....\n",
    "The input is based on the following ideas:\n",
    "\n",
    "\n",
    "the idea is to label alleles, non_allelic 'orthologs' singeltons, and single nuclear genes.\n",
    "* alleles are bast on proteinortho -synteny flag\n",
    "* non_allelic 'orthologs' are genes that cluster on the protein level but are not allelic\n",
    "* singeltons are genes without ‘ortholog’ in the other haplotype\n",
    "* single haplotype genes are genes that have no gene to genome blast hit e_value = 1e-2 and are not in a homozygous region.\n",
    "\n",
    "Final analysis is based on Pst_104E_v12_missing_allele_QC_v03.ipynb and Pst_104E_v12_defining_alleles_v03.ipynb in folder \n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01 and alleles_proteinortho_graph516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import SeqUtils\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwh_set = []\n",
    "def pwh_filter (q_contig, pwh_set=pwh_set):\n",
    "    '''Checks if contig belongs to the primary with haplotig set.'''\n",
    "    if q_contig in pwh_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_primary_contig (q_contig):\n",
    "    '''Quick function that checks if query is on primary contig or not'''\n",
    "    if q_contig.startswith('hcontig'):\n",
    "        return False\n",
    "    elif q_contig.startswith('pcontig'):\n",
    "        return True\n",
    "    else:\n",
    "        print('Contig annotation needs to start with hcontig or pcontig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "BLAST_RESULT_PATH = os.path.join(BASE_AA_PATH,'allele_analysis' )\n",
    "ALLELE_PATH =os.path.join(BASE_AA_PATH ,'allele_analysis/alleles_proteinortho_graph516')\n",
    "ALLELE_QC_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis', \\\n",
    "                              'no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "LIST_PATH = os.path.join(BASE_AA_PATH, 'enrichment_analysis', 'lists')\n",
    "POST_ALLELE_PATH = os.path.join(BASE_AA_PATH, 'post_allele_analysis')\n",
    "OUT_PATH = os.path.join(POST_ALLELE_PATH, 'proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "if not os.path.exists(POST_ALLELE_PATH):\n",
    "    os.mkdir(POST_ALLELE_PATH)\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n",
    "ph_gene_fasta = os.path.join(BASE_A_PATH , 'Pst_104E_v12_ph_ctg.anno.gene.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the alleles in as they are not filtered by QCov and PctID but simply taken straight from the \n",
    "# proteinortho\n",
    "allele_header = ['p_gene', 'h_gene']\n",
    "a_overlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_overlap_df['Linkage'] = 'h_contig_overlap'\n",
    "a_no_roverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_roverlap_df['Linkage'] = 'no_r_overlap'\n",
    "a_no_soverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_soverlap_df['Linkage'] = 'no_s_overlap'\n",
    "allele_df = pd.concat([a_overlap_df, a_no_roverlap_df, a_no_soverlap_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy over allele files to OUTPATH\n",
    "os.chdir(ALLELE_PATH)\n",
    "!cp Pst_104E_v12_p_ctg.h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles {OUT_PATH}/. \n",
    "!cat Pst_104E_v12_p_ctg.h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles > {OUT_PATH}/Pst_104E_v12_p_ctg.all.alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#get the blast dataframe and the QC dataframe\n",
    "allele_blast_df = pd.read_csv(os.path.join(BLAST_RESULT_PATH, 'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis'), sep='\\t')\n",
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')\n",
    "allele_QC_df = allele_QC_df[~((allele_QC_df.Query.isin(allele_df.p_gene))|(allele_QC_df.Query.isin(allele_df.h_gene)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check if all the numbers of genes add up\n",
    "len(allele_df.p_gene.unique())+ len(allele_df.h_gene.unique())+len(allele_QC_df.Query.unique()) == 30249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now write out all no_allele_orthologs\n",
    "no_allele_orthologs_fn = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.no_alleles_orthologs')\n",
    "no_allele_orthologs = allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique()\n",
    "tmp_fh = open(no_allele_orthologs_fn, 'w')\n",
    "for _id in allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique():\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out singeltons\n",
    "singeltons_fh = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.singletons')\n",
    "singeltons = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.ph_p_homo_region != True)][\"Query\"].unique()\n",
    "tmp_fh = open(singeltons_fh , 'w')\n",
    "for _id in singeltons:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out single nuclear genes\n",
    "shg_df = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.gene_on_genome_blast_hit != True)\\\n",
    "            &(allele_QC_df.ph_p_homo_region != True)].copy()\n",
    "shg_fh = os.path.join(OUT_PATH, 'Pst_104E_ph_ctg.single_haplotype_genes')\n",
    "shg = shg_df.Query.unique()\n",
    "tmp_fh = open(shg_fh, 'w')\n",
    "for _id in shg:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in some types of genes\n",
    "gene_group_list = ['BUSCOS', 'EFFECTORS', 'HAUSTORIA', 'EFFECTORP']\n",
    "p_gene_dict = {}\n",
    "h_gene_dict = {}\n",
    "p_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_cluster_8.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_cluster_15.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "#now get pwh and pwoh\n",
    "pwh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwh.txt')\\\n",
    "                                , header=None)[0].tolist()\n",
    "pwoh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwoh.txt')\\\n",
    "                                , header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwh contigs\n",
      "1523\n"
     ]
    }
   ],
   "source": [
    "#cause we are a bit lazy an like notebooks here we go looking for stuff\n",
    "os.chdir(BASE_A_PATH)\n",
    "print(\"Effectors on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"Effectors on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwh contigs\n",
      "1395\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on hcontigs\n",
      "1293 /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists/Pst_104E_v12_h_busco.gene.gff3\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on hcontigs\")\n",
    "!wc -l {LIST_PATH}/Pst_104E_v12_h_busco.gene.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "def orphan_analysis(_orphan_list):\n",
    "    orphan_effectors = 0\n",
    "    orphan_effectors_h = 0\n",
    "    orphan_effectors_pwh = 0\n",
    "    orphan_effectors_pwoh =0\n",
    "    orphan_busco = 0\n",
    "    orphan_busco_h = 0\n",
    "    orphan_busco_pwh = 0\n",
    "    orphan_busco_pwoh = 0\n",
    "    for x in _orphan_list:\n",
    "        if x in p_gene_dict['BUSCOS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_busco_pwh += 1\n",
    "            else:\n",
    "                orphan_busco_pwoh += 1\n",
    "        if x in h_gene_dict['BUSCOS']:\n",
    "            orphan_busco_h += 1\n",
    "        #now same for effectors    \n",
    "        if x in p_gene_dict['EFFECTORS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_effectors_pwh += 1\n",
    "            else:\n",
    "                orphan_effectors_pwoh += 1\n",
    "            \n",
    "        if x in h_gene_dict['EFFECTORS']:\n",
    "            orphan_effectors_h += 1      \n",
    "    orphan_effectors = orphan_effectors_h + orphan_effectors_pwh + orphan_effectors_pwoh\n",
    "    orphan_busco = orphan_busco_h +  orphan_busco_pwh +  orphan_busco_pwoh\n",
    "    print('Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "          %(len(_orphan_list), orphan_busco, orphan_effectors))\n",
    "    print('On haplotigs. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %(len([x for x in _orphan_list if 'hcontig' in x]), orphan_busco_h, orphan_effectors_h))\n",
    "    print('On pwh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list].count(True), orphan_busco_pwh, orphan_effectors_pwh))\n",
    "    print('On pwoh. Out of %i orphan genes we have %i orphan buscos and %i orphan effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list if 'pcontig' in x].count(False), orphan_busco_pwoh, orphan_effectors_pwoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes without clear allele:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7912"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of genes without clear allele:\")\n",
    "len(allele_QC_df[allele_QC_df.ph_p_homo_region != True]['Query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1506 orphan genes we have 125 orphan buscos and 120 orphan effectors.\n",
      "On haplotigs. Out of 160 orphan genes we have 6 orphan buscos and 5 orphan effectors.\n",
      "On pwh. Out of 1149 orphan genes we have 93 orphan buscos and 98 orphan effectors.\n",
      "On pwoh. Out of 197 orphan genes we have 26 orphan buscos and 17 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "orphan_analysis(shg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 7029 orphan genes we have 234 orphan buscos and 453 orphan effectors.\n",
      "On haplotigs. Out of 2931 orphan genes we have 57 orphan buscos and 153 orphan effectors.\n",
      "On pwh. Out of 3700 orphan genes we have 147 orphan buscos and 270 orphan effectors.\n",
      "On pwoh. Out of 398 orphan genes we have 30 orphan buscos and 30 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "orphan_analysis(singeltons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#set the coverage limits\n",
    "QCov_limit = 80\n",
    "PctID_limit = 70\n",
    "#now get all the ids for which we have hits above the cut off and are singletons\n",
    "tmp_df = allele_QC_df[allele_QC_df.Target != 'False'] #filter out no hits\n",
    "tmp_df[['QCov', 'PctID']] = tmp_df[['QCov', 'PctID']].apply(pd.to_numeric) #make numeric\n",
    "#get ids of stuff above the cut off\n",
    "tmp_df_ids = tmp_df[(tmp_df.QCov >= QCov_limit) & (tmp_df.PctID >= PctID_limit)]['Query'].unique()\n",
    "#filter those out and everything that is not a singleton\n",
    "tmp_df = allele_QC_df[~((allele_QC_df.Query.isin(tmp_df_ids)) | (allele_QC_df.singeltons == False))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3191 orphan genes we have 180 orphan buscos and 207 orphan effectors.\n",
      "On haplotigs. Out of 942 orphan genes we have 26 orphan buscos and 34 orphan effectors.\n",
      "On pwh. Out of 1998 orphan genes we have 126 orphan buscos and 152 orphan effectors.\n",
      "On pwoh. Out of 251 orphan genes we have 28 orphan buscos and 21 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3991 orphan genes we have 190 orphan buscos and 303 orphan effectors.\n",
      "On haplotigs. Out of 1335 orphan genes we have 31 orphan buscos and 83 orphan effectors.\n",
      "On pwh. Out of 2393 orphan genes we have 131 orphan buscos and 198 orphan effectors.\n",
      "On pwoh. Out of 263 orphan genes we have 28 orphan buscos and 22 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter =  (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 534 orphan genes we have 62 orphan buscos and 44 orphan effectors.\n",
      "On haplotigs. Out of 0 orphan genes we have 0 orphan buscos and 0 orphan effectors.\n",
      "On pwh. Out of 474 orphan genes we have 57 orphan buscos and 43 orphan effectors.\n",
      "On pwoh. Out of 60 orphan genes we have 5 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 550 orphan genes we have 62 orphan buscos and 45 orphan effectors.\n",
      "On haplotigs. Out of 0 orphan genes we have 0 orphan buscos and 0 orphan effectors.\n",
      "On pwh. Out of 488 orphan genes we have 57 orphan buscos and 44 orphan effectors.\n",
      "On pwoh. Out of 62 orphan genes we have 5 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.ph_p_homo_region == True) \n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.homozygous_coverage' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 816 orphan genes we have 10 orphan buscos and 97 orphan effectors.\n",
      "On haplotigs. Out of 393 orphan genes we have 5 orphan buscos and 49 orphan effectors.\n",
      "On pwh. Out of 409 orphan genes we have 5 orphan buscos and 47 orphan effectors.\n",
      "On pwoh. Out of 14 orphan genes we have 0 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.exonerate_hits' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4541"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_df.Query.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 809 orphan genes we have 10 orphan buscos and 96 orphan effectors.\n",
      "On haplotigs. Out of 393 orphan genes we have 5 orphan buscos and 49 orphan effectors.\n",
      "On pwh. Out of 404 orphan genes we have 5 orphan buscos and 46 orphan effectors.\n",
      "On pwoh. Out of 12 orphan genes we have 0 orphan buscos and 1 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 2739 orphan genes we have 62 orphan buscos and 240 orphan effectors.\n",
      "On haplotigs. Out of 1448 orphan genes we have 33 orphan buscos and 126 orphan effectors.\n",
      "On pwh. Out of 1212 orphan genes we have 27 orphan buscos and 105 orphan effectors.\n",
      "On pwoh. Out of 79 orphan genes we have 2 orphan buscos and 9 orphan effectors.\n"
     ]
    }
   ],
   "source": [
    "#do filtering of the whole dataframe with QCov and PctID\n",
    "#now make new filter for the following\n",
    "out_filter = (allele_QC_df.exn_asso_contig == True) | (allele_QC_df.exn_no_asso_contig == True) \n",
    "queries_out_filtered = allele_QC_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some features of the orphan genes such as:\n",
    "* gene/protein length\n",
    "* gc content\n",
    "* numbers of exons\n",
    "* distance to TEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349.0830013280212"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now look at single haplotype genes\n",
    "shg_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.5913485685585"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_blast_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8498250071590965, pvalue=1.2357044232530989e-06)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ranksums(shg_df.drop_duplicates('Query')['QLgth'],allele_blast_df.drop_duplicates('Query')['QLgth'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the len per gene in the list plus the len\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(len(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(len(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GC_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the GC content per gene in the list plus the GC content\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(SeqUtils.GC(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(SeqUtils.GC(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_gene_fasta(gene_list, gg_fasta):\n",
    "    '''Returns the fasta of gene in list as SeqIO object '''\n",
    "    genes_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            genes_fasta.append(x)\n",
    "    return genes_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "shg_GC, genome_GC = GC_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.936932047 45.7863006323\n"
     ]
    }
   ],
   "source": [
    "#gc content per gene\n",
    "print(np.mean(shg_GC), np.mean(genome_GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=1.7879649018298396, pvalue=0.073781670619541995)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "stats.ranksums(shg_GC, genome_GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gene length\n",
    "shg_len, genome_len = len_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334.79282869 1538.62967371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8395122876180281, pvalue=1.3015814430474663e-06)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "print(np.mean(shg_len), np.mean(genome_len))\n",
    "stats.ranksums(shg_len, genome_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gene fastas and save those\n",
    "shg_fasta = return_gene_fasta(shg, ph_gene_fasta)\n",
    "shg_fn = os.path.join(OUT_PATH, \"Pst_104E_ph_ctg.single_haplotype_genes.fasta\")\n",
    "with open(shg_fn, 'w') as fh:\n",
    "    SeqIO.write(shg_fasta, fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots()\n",
    "sns.boxplot(y=filtered_tmp_df.drop_duplicates('Query')['QLgth'])\n",
    "sns.boxplot(y=allele_blast_df.drop_duplicates('Query')['QLgth'])\n",
    "plt.ylim(0, 5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(allele_blast_df.drop_duplicates('Query')['QLgth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ranksums(filtered_tmp_df.drop_duplicates('Query')['QLgth'],allele_blast_df.drop_duplicates('Query')['QLgth'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move on to do some enrichment analysis for GO terms needs to be done \n",
    "Looking at the command line this seems all a bit silly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.QCov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QP_filter = (allele_QC_df.QCov >= QCov_limit) & (allele_QC_df.PctID >= PctID_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now a bit more specific for each haplotyp\n",
    "os.chdir(ALLELE_QC_PATH)\n",
    "allele_blast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
