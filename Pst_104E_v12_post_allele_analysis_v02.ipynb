{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at looked at the allele analysis output a bit more interms of what are the alleles. What is missing? What is the GO term enrichment in those if any? How much are effectors?....\n",
    "The input is based on the following ideas:\n",
    "\n",
    "\n",
    "the idea is to label alleles, non_allelic 'orthologs' singeltons, and single nuclear genes.\n",
    "* alleles are bast on proteinortho -synteny flag\n",
    "* non_allelic 'orthologs' are genes that cluster on the protein level but are not allelic\n",
    "* singeltons are genes without ‘ortholog’ in the other haplotype\n",
    "* single haplotype genes are genes that have no gene to genome blast hit e_value = 1e-2 and are not in a homozygous region.\n",
    "\n",
    "Final analysis is based on Pst_104E_v12_missing_allele_QC_v03.ipynb and Pst_104E_v12_defining_alleles_v03.ipynb in folder \n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01 and alleles_proteinortho_graph516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import SeqUtils\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "import distance\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwh_set = []\n",
    "def pwh_filter (q_contig, pwh_set=pwh_set):\n",
    "    '''Checks if contig belongs to the primary with haplotig set.'''\n",
    "    if q_contig in pwh_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_primary_contig (q_contig):\n",
    "    '''Quick function that checks if query is on primary contig or not'''\n",
    "    if q_contig.startswith('hcontig'):\n",
    "        return False\n",
    "    elif q_contig.startswith('pcontig'):\n",
    "        return True\n",
    "    else:\n",
    "        print('Contig annotation needs to start with hcontig or pcontig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "BLAST_RESULT_PATH = os.path.join(BASE_AA_PATH,'allele_analysis' )\n",
    "ALLELE_PATH =os.path.join(BASE_AA_PATH ,'allele_analysis/alleles_proteinortho_graph516')\n",
    "ALLELE_QC_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis', \\\n",
    "                              'no_alleles_proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "LIST_PATH = os.path.join(BASE_AA_PATH, 'enrichment_analysis', 'lists')\n",
    "POST_ALLELE_PATH = os.path.join(BASE_AA_PATH, 'post_allele_analysis')\n",
    "OUT_PATH = os.path.join(POST_ALLELE_PATH, 'proteinortho_graph516_QC_Qcov80_PctID70_evalue01')\n",
    "if not os.path.exists(POST_ALLELE_PATH):\n",
    "    os.mkdir(POST_ALLELE_PATH)\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n",
    "ph_gene_fasta = os.path.join(BASE_A_PATH , 'Pst_104E_v12_ph_ctg.anno.gene.fa')\n",
    "ph_cds_fasta = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.anno.CDS.fa')\n",
    "ph_protein_fasta = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.anno.protein.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the alleles in as they are not filtered by QCov and PctID but simply taken straight from the \n",
    "# proteinortho\n",
    "allele_header = ['p_gene', 'h_gene']\n",
    "a_overlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_overlap_df['Linkage'] = 'h_contig_overlap'\n",
    "a_no_roverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_roverlap_df['Linkage'] = 'no_r_overlap'\n",
    "a_no_soverlap_df = pd.read_csv(os.path.join(ALLELE_PATH, \\\n",
    "                    'Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles'), sep='\\t', header = None,\\\n",
    "                           names=allele_header)\n",
    "a_no_soverlap_df['Linkage'] = 'no_s_overlap'\n",
    "allele_df = pd.concat([a_overlap_df, a_no_roverlap_df, a_no_soverlap_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy over allele files to OUTPATH\n",
    "os.chdir(ALLELE_PATH)\n",
    "!cp Pst_104E_v12_p_ctg.h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles {OUT_PATH}/.\n",
    "!cp Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles {OUT_PATH}/. \n",
    "!cat Pst_104E_v12_p_ctg.h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles Pst_104E_v12_p_ctg.no_specific_h_contig_overlap.alleles > {OUT_PATH}/Pst_104E_v12_p_ctg.all.alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#get the blast dataframe and the QC dataframe\n",
    "allele_blast_df = pd.read_csv(os.path.join(BLAST_RESULT_PATH, 'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis'), sep='\\t')\n",
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#now filter out all the genes that already have alleles based on the protein ortho results\n",
    "#this does not care about the 'abirary' cut offs for coverage and PctID\n",
    "allele_QC_df = pd.read_csv(os.path.join(ALLELE_QC_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_QC.Qcov80.PctID70.df'), sep='\\t')\n",
    "allele_QC_df = allele_QC_df[~((allele_QC_df.Query.isin(allele_df.p_gene))|(allele_QC_df.Query.isin(allele_df.h_gene)))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check if all the numbers of genes add up\n",
    "len(allele_df.p_gene.unique())+ len(allele_df.h_gene.unique())+len(allele_QC_df.Query.unique()) == 30249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now write out all no_allele_orthologs\n",
    "no_allele_orthologs_fn = os.path.join(OUT_PATH, 'Pst_104E_v12_ph_ctg.no_alleles_orthologs')\n",
    "no_allele_orthologs = allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique()\n",
    "tmp_fh = open(no_allele_orthologs_fn, 'w')\n",
    "for _id in allele_QC_df[allele_QC_df.singeltons == False][\"Query\"].unique():\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out singeltons\n",
    "singeltons_fh = os.path.join(OUT_PATH, 'Pst_104E_v12_ph_ctg.singletons')\n",
    "singeltons = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.ph_p_homo_region != True)][\"Query\"].unique()\n",
    "tmp_fh = open(singeltons_fh , 'w')\n",
    "for _id in singeltons:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out loose singeltons. This includes all the genes that are singletons also those that \n",
    "#are unphased\n",
    "loose_singeltons_fh = os.path.join(OUT_PATH, 'Pst_104E_v12_ph_ctg.loose_singletons')\n",
    "loose_singeltons = allele_QC_df[(allele_QC_df.singeltons == True) ][\"Query\"].unique()\n",
    "tmp_fh = open(loose_singeltons_fh , 'w')\n",
    "for _id in loose_singeltons:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out single nuclear genes defined as having no genome blast, being not in homozygous regions,\n",
    "#and being singeltons\n",
    "shg_df = allele_QC_df[(allele_QC_df.singeltons == True) & (allele_QC_df.gene_on_genome_blast_hit != True)\\\n",
    "            &(allele_QC_df.ph_p_homo_region != True)].copy()\n",
    "shg_fh = os.path.join(OUT_PATH, 'Pst_104E_v12_ph_ctg.single_haplotype_genes')\n",
    "shg = shg_df.Query.unique()\n",
    "tmp_fh = open(shg_fh, 'w')\n",
    "for _id in shg:\n",
    "    print(_id, file=tmp_fh)\n",
    "tmp_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in some types of genes\n",
    "gene_group_list = ['BUSCOS', 'EFFECTORS', 'HAUSTORIA', 'EFFECTORP']\n",
    "p_gene_dict = {}\n",
    "h_gene_dict = {}\n",
    "p_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_cluster_8.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "p_gene_dict['SIGNALP3'] = pd.read_csv(os.path.join(LIST_PATH, '..', 'pa_26062017',\\\n",
    "                            'Pst_104E_v12_p_ctg.SignalP3.tablist'), header=None, sep='\\t')[0].tolist()\n",
    "\n",
    "h_gene_dict['BUSCOS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_busco.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORS'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effector.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['HAUSTORIA'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_cluster_15.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['EFFECTORP'] = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_effectorp.list')\\\n",
    "                                    , header=None)[0].tolist()\n",
    "h_gene_dict['SIGNALP3'] = pd.read_csv(os.path.join(LIST_PATH, '..', 'pa_26062017',\\\n",
    "                            'Pst_104E_v12_h_ctg.SignalP3.tablist'), header=None, sep='\\t')[0].tolist()\n",
    "\n",
    "#now get pwh and pwoh\n",
    "pwh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwh.txt')\\\n",
    "                                , header=None)[0].tolist()\n",
    "pwoh_list = pd.read_csv(os.path.join(BASE_A_PATH, 'Pst_104E_v12_pwoh.txt')\\\n",
    "                                , header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwh contigs\n",
      "1523\n"
     ]
    }
   ],
   "source": [
    "#cause we are a bit lazy an like notebooks here we go looking for stuff\n",
    "os.chdir(BASE_A_PATH)\n",
    "print(\"Effectors on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectors on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"Effectors on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_effector.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwoh contigs\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwoh contigs\")\n",
    "!cat Pst_104E_v12_pwoh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on pwh contigs\n",
      "1395\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on pwh contigs\")\n",
    "!cat Pst_104E_v12_pwh.txt | xargs -I X grep -w 'X' {LIST_PATH}/Pst_104E_v12_p_busco.gene.gff3 | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSCOS on hcontigs\n",
      "1293 /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists/Pst_104E_v12_h_busco.gene.gff3\n"
     ]
    }
   ],
   "source": [
    "print(\"BUSCOS on hcontigs\")\n",
    "!wc -l {LIST_PATH}/Pst_104E_v12_h_busco.gene.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "def orphan_analysis(_orphan_list):\n",
    "    \"\"\"\n",
    "    This is a function that prints out the numbers of total genes and how many of those are\n",
    "    buscos or effectors. The same for haplotigs, primary contigs with haplotigs, and \n",
    "    primary contigs without haplotigs.\n",
    "    \"\"\"\n",
    "    orphan_effectors = 0\n",
    "    orphan_effectors_h = 0\n",
    "    orphan_effectors_pwh = 0\n",
    "    orphan_effectors_pwoh =0\n",
    "    orphan_busco = 0\n",
    "    orphan_busco_h = 0\n",
    "    orphan_busco_pwh = 0\n",
    "    orphan_busco_pwoh = 0\n",
    "    for x in _orphan_list:\n",
    "        if x in p_gene_dict['BUSCOS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_busco_pwh += 1\n",
    "            else:\n",
    "                orphan_busco_pwoh += 1\n",
    "        if x in h_gene_dict['BUSCOS']:\n",
    "            orphan_busco_h += 1\n",
    "        #now same for effectors    \n",
    "        if x in p_gene_dict['EFFECTORS']:\n",
    "            contig = re.search(r'[hp][^.]*',x).group()\n",
    "            if pwh_filter(contig, pwh_list) == True:\n",
    "                orphan_effectors_pwh += 1\n",
    "            else:\n",
    "                orphan_effectors_pwoh += 1\n",
    "            \n",
    "        if x in h_gene_dict['EFFECTORS']:\n",
    "            orphan_effectors_h += 1      \n",
    "    orphan_effectors = orphan_effectors_h + orphan_effectors_pwh + orphan_effectors_pwoh\n",
    "    orphan_busco = orphan_busco_h +  orphan_busco_pwh +  orphan_busco_pwoh\n",
    "    print('Out of %i genes we have %i buscos and %i effectors.'\\\n",
    "          %(len(_orphan_list), orphan_busco, orphan_effectors))\n",
    "    print('On haplotigs. Out of %i genes we have %i buscos and %i effectors.'\\\n",
    "         %(len([x for x in _orphan_list if 'hcontig' in x]), orphan_busco_h, orphan_effectors_h))\n",
    "    print('On pwh. Out of %i genes we have %i buscos and %i effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list].count(True), orphan_busco_pwh, orphan_effectors_pwh))\n",
    "    print('On pwoh. Out of %i genes we have %i buscos and %i effectors.'\\\n",
    "         %([pwh_filter(re.search(r'[hp][^.]*',x).group(), pwh_list) for x in _orphan_list if 'pcontig' in x].count(False), orphan_busco_pwoh, orphan_effectors_pwoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery',\n",
       "       'StopQuery', 'StartTarget', 'StopTarget', 'e-value', 'BitScore',\n",
       "       'QLgth', 'QCov', 'q_contig', 't_contig', 'q_contig == t_contig',\n",
       "       'primary_contig', 'pwh_contig', 'gene_on_genome_blast_hit',\n",
       "       'exn_asso_contig', 'exn_no_asso_contig', 'ph_p_homo_region',\n",
       "       'singeltons', 'Pst_E104_v1_ph_ctg.freebayes_SNP',\n",
       "       'Pst_E104_v1_ph_ctg.freebayes_SNP_#',\n",
       "       'Pst_E104_v1_ph_ctg.freebayes_SNP_%', 'overlap_p_on_h_mapping'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_QC_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes without clear allele:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7029"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of genes without clear allele:\")\n",
    "len(singeltons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For single haplotype genes:\n",
      "Out of 1506 genes we have 125 buscos and 120 effectors.\n",
      "On haplotigs. Out of 160 genes we have 6 buscos and 5 effectors.\n",
      "On pwh. Out of 1149 genes we have 93 buscos and 98 effectors.\n",
      "On pwoh. Out of 197 genes we have 26 buscos and 17 effectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"For single haplotype genes:\")\n",
    "orphan_analysis(shg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For singletons:\n",
      "Out of 7029 genes we have 234 buscos and 453 effectors.\n",
      "On haplotigs. Out of 2931 genes we have 57 buscos and 153 effectors.\n",
      "On pwh. Out of 3700 genes we have 147 buscos and 270 effectors.\n",
      "On pwoh. Out of 398 genes we have 30 buscos and 30 effectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"For singletons:\")\n",
    "orphan_analysis(singeltons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For loose singletons:\n",
      "Out of 7692 genes we have 297 buscos and 502 effectors.\n",
      "On haplotigs. Out of 2931 genes we have 57 buscos and 153 effectors.\n",
      "On pwh. Out of 4289 genes we have 205 buscos and 318 effectors.\n",
      "On pwoh. Out of 472 genes we have 35 buscos and 31 effectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"For loose singletons:\")\n",
    "orphan_analysis(loose_singeltons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#set the coverage limits\n",
    "QCov_limit = 80\n",
    "PctID_limit = 70\n",
    "#now get all the ids for which we have hits above the cut off and are singletons\n",
    "tmp_df = allele_QC_df[allele_QC_df.Target != 'False'] #filter out no hits\n",
    "tmp_df[['QCov', 'PctID']] = tmp_df[['QCov', 'PctID']].apply(pd.to_numeric) #make numeric\n",
    "#get ids of stuff above the cut off\n",
    "tmp_df_ids = tmp_df[(tmp_df.QCov >= QCov_limit) & (tmp_df.PctID >= PctID_limit)]['Query'].unique()\n",
    "#filter those out and everything that is not a singleton\n",
    "tmp_df = allele_QC_df[~((allele_QC_df.Query.isin(tmp_df_ids)) | (allele_QC_df.singeltons == False))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below is about singeltons that don't have a significant protein blast hit with considering the QCov and PctID limit set above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3191 genes we have 180 buscos and 207 effectors.\n",
      "On haplotigs. Out of 942 genes we have 26 buscos and 34 effectors.\n",
      "On pwh. Out of 1998 genes we have 126 buscos and 152 effectors.\n",
      "On pwoh. Out of 251 genes we have 28 buscos and 21 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_exonerate' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singletons that have are phased but have no good blast hit above the threshold\n",
      "Out of 3991 genes we have 190 buscos and 303 effectors.\n",
      "On haplotigs. Out of 1335 genes we have 31 buscos and 83 effectors.\n",
      "On pwh. Out of 2393 genes we have 131 buscos and 198 effectors.\n",
      "On pwoh. Out of 263 genes we have 28 buscos and 22 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now filter dataframe on different other issues\n",
    "out_filter =  (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "print('Singletons that have are phased but have no good blast hit above the threshold')\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_p = 'Pst_104E_v12_p_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn_short_h = 'Pst_104E_v12_h_ctg.no_alleles_postQC.PctID%i_QCov%i.no_homo' % (PctID_limit, QCov_limit)\n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fn_list_h = os.path.join(LIST_PATH, fn_short_h)\n",
    "fn_list_p = os.path.join(LIST_PATH, fn_short_p)\n",
    "fh_list_p = open(fn_list_p, 'w')\n",
    "fh_list_h = open(fn_list_h, 'w')\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    if 'pcontig' in gene:\n",
    "        print(gene, file=fh_list_p)\n",
    "    if 'hcontig' in gene:\n",
    "        print(gene, file=fh_list_h)\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n",
    "fh_list_p.close()\n",
    "fh_list_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For unphased singletons that have no exonerate alignments:\n",
      "Out of 534 genes we have 62 buscos and 44 effectors.\n",
      "On haplotigs. Out of 0 genes we have 0 buscos and 0 effectors.\n",
      "On pwh. Out of 474 genes we have 57 buscos and 43 effectors.\n",
      "On pwoh. Out of 60 genes we have 5 buscos and 1 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig != True) & (tmp_df.exn_no_asso_contig != True) & \\\n",
    "            (tmp_df.ph_p_homo_region == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "print(\"For unphased singletons that have no exonerate alignments:\")\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For unphased singletons:\n",
      "Out of 550 genes we have 62 buscos and 45 effectors.\n",
      "On haplotigs. Out of 0 genes we have 0 buscos and 0 effectors.\n",
      "On pwh. Out of 488 genes we have 57 buscos and 44 effectors.\n",
      "On pwoh. Out of 62 genes we have 5 buscos and 1 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.ph_p_homo_region == True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "print(\"For unphased singletons:\")\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 550 genes we have 62 buscos and 45 effectors.\n",
      "On haplotigs. Out of 0 genes we have 0 buscos and 0 effectors.\n",
      "On pwh. Out of 488 genes we have 57 buscos and 44 effectors.\n",
      "On pwoh. Out of 62 genes we have 5 buscos and 1 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.ph_p_homo_region == True) \n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.homozygous_coverage' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singletons with exonerate alignment\n",
      "Out of 816 genes we have 10 buscos and 97 effectors.\n",
      "On haplotigs. Out of 393 genes we have 5 buscos and 49 effectors.\n",
      "On pwh. Out of 409 genes we have 5 buscos and 47 effectors.\n",
      "On pwoh. Out of 14 genes we have 0 buscos and 1 effectors.\n",
      "I guess this means that BUSCOs might get annotated a bit better than other genes including effectors.\n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True) \n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "print(\"Singletons with exonerate alignment\") \n",
    "orphan_analysis(queries_out_filtered)\n",
    "print(\"I guess this means that BUSCOs might get annotated a bit better than other genes\\\n",
    " including effectors.\")\n",
    "#now print this out again into the ALLELE_QC folder\n",
    "fn_short = 'Pst_104E_v12_ph_ctg.no_alleles_postQC.exonerate_hits' \n",
    "fn = os.path.join(ALLELE_QC_PATH, fn_short)\n",
    "fh = open(fn, 'w')\n",
    "for gene in queries_out_filtered:\n",
    "    print(gene, file=fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 809 genes we have 10 buscos and 96 effectors.\n",
      "On haplotigs. Out of 393 genes we have 5 buscos and 49 effectors.\n",
      "On pwh. Out of 404 genes we have 5 buscos and 46 effectors.\n",
      "On pwoh. Out of 12 genes we have 0 buscos and 1 effectors.\n"
     ]
    }
   ],
   "source": [
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "#now make new filter for the following\n",
    "out_filter = (tmp_df.exn_asso_contig == True) | (tmp_df.exn_no_asso_contig == True) & \\\n",
    "            (tmp_df.ph_p_homo_region != True)\n",
    "queries_out_filtered = tmp_df[out_filter]['Query'].unique()\n",
    "#now see if there is an enrichment in GO terms associated with alleles\n",
    "orphan_analysis(queries_out_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all singletons without filtering for Cov or PctID that have an exonerate alignment:\n",
      "Out of 2531 genes we have 56 buscos and 230 effectors.\n",
      "On haplotigs. Out of 1381 genes we have 32 buscos and 123 effectors.\n",
      "On pwh. Out of 1097 genes we have 24 buscos and 102 effectors.\n",
      "On pwoh. Out of 53 genes we have 0 buscos and 5 effectors.\n",
      "Again we \n"
     ]
    }
   ],
   "source": [
    "#now make new filter for the following\n",
    "out_filter = (allele_QC_df.exn_asso_contig == True) | (allele_QC_df.exn_no_asso_contig == True)\\\n",
    "    & (allele_QC_df.singeltons == True)\n",
    "queries_out_filtered = allele_QC_df[out_filter]['Query'].unique()\n",
    "print(\"For all singletons without filtering for Cov or PctID that have an exonerate alignment:\")\n",
    "orphan_analysis(queries_out_filtered)\n",
    "print('Again we ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some features of the orphan genes such as:\n",
    "* gene/protein length\n",
    "* gc content\n",
    "* numbers of exons\n",
    "* distance to TEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349.0830013280212"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now look at single haplotype genes\n",
    "shg_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.5913485685585"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_blast_df.drop_duplicates('Query')['QLgth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8498250071590965, pvalue=1.2357044232530989e-06)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ranksums(shg_df.drop_duplicates('Query')['QLgth'],allele_blast_df.drop_duplicates('Query')['QLgth'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the len per gene in the list plus the len\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(len(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(len(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GC_per_gene(gene_list, gg_fasta):\n",
    "    '''Returns the GC content per gene in the list plus the GC content\n",
    "    for all genes in the genome from using gg_fasta genome gene fasta.'''\n",
    "    GC_list_genes = []\n",
    "    GC_list_genome = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        GC_list_genome.append(SeqUtils.GC(x.seq))\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            GC_list_genes.append(SeqUtils.GC(x.seq))\n",
    "    return GC_list_genes, GC_list_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_gene_fasta_paml(gene_list, gg_fasta):\n",
    "    '''Returns the fasta of gene in list as SeqIO object '''\n",
    "    genes_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            x.id = x.id.replace('TU', 'model')\n",
    "            genes_fasta.append(x)\n",
    "    return genes_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_gene_fasta(gene_list, gg_fasta):\n",
    "    '''Returns the fasta of gene in list as SeqIO object '''\n",
    "    genes_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id.replace('TU', 'model') in gene_list:\n",
    "            genes_fasta.append(x)\n",
    "    return genes_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_contig_fasta(contig_list, gg_fasta):\n",
    "    '''Returns the fasta of contig in list as SeqIO object '''\n",
    "    contig_fasta = []\n",
    "    for x in SeqIO.parse(gg_fasta, 'fasta'):\n",
    "        if x.id in contig_list:\n",
    "            contig_fasta.append(x)\n",
    "    return contig_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shg_GC, genome_GC = GC_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.936932047 45.7863006323\n"
     ]
    }
   ],
   "source": [
    "#gc content per gene\n",
    "print(np.mean(shg_GC), np.mean(genome_GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=1.7879649018298396, pvalue=0.073781670619541995)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "stats.ranksums(shg_GC, genome_GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gene length\n",
    "shg_len, genome_len = len_per_gene(shg, ph_gene_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334.79282869 1538.62967371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-4.8395122876180281, pvalue=1.3015814430474663e-06)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing difference\n",
    "print(np.mean(shg_len), np.mean(genome_len))\n",
    "stats.ranksums(shg_len, genome_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get gene fastas and save those\n",
    "shg_fasta = return_gene_fasta(shg, ph_gene_fasta)\n",
    "shg_fn = os.path.join(OUT_PATH, \"Pst_104E_v12_ph_ctg.single_haplotype_genes.fasta\")\n",
    "with open(shg_fn, 'w') as fh:\n",
    "    SeqIO.write(shg_fasta, fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get gene fastas and save those\n",
    "shg_fasta = return_gene_fasta(shg, ph_cds_fasta)\n",
    "shg_fn = os.path.join(OUT_PATH, \"Pst_104E_v12_ph_ctg.single_haplotype_genes.cds.fasta\")\n",
    "with open(shg_fn, 'w') as fh:\n",
    "    SeqIO.write(shg_fasta, fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a look after of the shg genes without a blast it in NCBI nt or ensembl cDNA\n",
    "BLASTR_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/post_allele_analysis/proteinortho_graph516_QC_Qcov80_PctID70_evalue01/blast/'\n",
    "ensembl_blast = os.path.join(BLASTR_FOLDER, 'Pst_104E_v12_ph_ctg.single_haplotype_genes.cds.0817_e36_cdna.fa.outfmt6')\n",
    "ncbi_blast = os.path.join(BLASTR_FOLDER,'Pst_104E_ph_ctg.single_haplotype_genes.fasta.NCBI10032017.01.blastn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of single haplotype genes that are on pwoh:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of single haplotype genes that are on pwoh:')\n",
    "len([x for x in shg if re.findall(r'([ph]contig_[0-9]*)', x)[0] in pwoh_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in gene beds\n",
    "p_gene_bed = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_p_all.gene.bed'), header=None, sep='\\t')\n",
    "h_gene_bed = pd.read_csv(os.path.join(LIST_PATH, 'Pst_104E_v12_h_all.gene.bed'), header=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do check if neighbors shg are more likely to have neighbours that are also shg compare to random subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look into if shg are more likely to be neighbours and a random subsample\n",
    "p_genes_ordered = p_gene_bed.sort_values([0, 1])[3].tolist()\n",
    "h_genes_ordered = h_gene_bed.sort_values([0, 1])[3].tolist()\n",
    "#make a dict that contains ordered gene lists per contig\n",
    "gene_list_per_contig_dict = {}\n",
    "for gene in p_genes_ordered:\n",
    "    contig = re.findall(r'[ph]contig[^.]*', gene)[0]\n",
    "    if not contig in gene_list_per_contig_dict.keys():\n",
    "        gene_list_per_contig_dict[contig] = [x for x in p_genes_ordered if contig in x]\n",
    "for gene in h_genes_ordered:\n",
    "    contig = re.findall(r'[ph]contig[^.]*', gene)[0]\n",
    "    if not contig in gene_list_per_contig_dict.keys():\n",
    "        gene_list_per_contig_dict[contig] = [x for x in h_genes_ordered if contig in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check if we got all genes\n",
    "count = 0\n",
    "for x in gene_list_per_contig_dict.values():\n",
    "    count += len(x)\n",
    "count == (len(p_genes_ordered) + len(h_genes_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the index of all shg_genes in the ordered gene list\n",
    "ordered_gl_index_dict = {}\n",
    "#initiat the empty list for the dict\n",
    "for key in gene_list_per_contig_dict.keys():\n",
    "    ordered_gl_index_dict[key] = []\n",
    "#now populate those for the genes we have\n",
    "for y in shg:\n",
    "    contig = re.findall(r'[ph]contig[^.]*', y)[0]\n",
    "    #get the index of the gene specific for the contig\n",
    "    _index = gene_list_per_contig_dict[contig].index(y.replace('model', 'TU'))\n",
    "    #append it to the specfic contig list\n",
    "    ordered_gl_index_dict[contig].append(_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "have_neighbours = []\n",
    "for key in ordered_gl_index_dict.keys():\n",
    "    subset_gene_index_list = ordered_gl_index_dict[key]\n",
    "    for y in subset_gene_index_list:\n",
    "        if y+1 in subset_gene_index_list or y-1 in subset_gene_index_list:\n",
    "            have_neighbours.append(True)\n",
    "        else:\n",
    "            have_neighbours.append(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make this a function\n",
    "def does_have_neighbour(input_gene_list, gene_list_per_contig_dict=gene_list_per_contig_dict):\n",
    "    '''Return a list of True/False indicating if the respective element of the entry list has \n",
    "    a neighbour present in the same list.\n",
    "    It also requires a dictionary of the ordered gene list per contig.'''\n",
    "    #get the index of all shg_genes in the ordered gene list\n",
    "    ordered_gl_index_dict = {}\n",
    "    #initiat the empty list for the dict\n",
    "    for key in gene_list_per_contig_dict.keys():\n",
    "        ordered_gl_index_dict[key] = []\n",
    "    #now populate those for the genes we have, adding indexes of each in in the list per contig\n",
    "    for y in input_gene_list:\n",
    "        contig = re.findall(r'[ph]contig[^.]*', y)[0]\n",
    "        #get the index of the gene specific for the contig\n",
    "        _index = gene_list_per_contig_dict[contig].index(y.replace('model', 'TU'))\n",
    "        #append it to the specfic contig list\n",
    "        ordered_gl_index_dict[contig].append(_index)\n",
    "    have_neighbours = []\n",
    "    #now loop over the list dictonary and see if each list contains an index+-1\n",
    "    for key in ordered_gl_index_dict.keys():\n",
    "        subset_gene_index_list = ordered_gl_index_dict[key]\n",
    "        for y in subset_gene_index_list:\n",
    "            if y+1 in subset_gene_index_list or y-1 in subset_gene_index_list:\n",
    "                have_neighbours.append(True)\n",
    "            else:\n",
    "                have_neighbours.append(False)\n",
    "    return have_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of shg genes with neighbours\n",
    "does_have_neighbour(shg).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.179553264604811, 2.3486743760141017e-115)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random subsampling of genes based on the obsereved numbers of \n",
    "#total genes and shg genes per contig\n",
    "random_gene_list = [p_genes_ordered[x] for x in np.random.choice(15928, 1346,replace=False)]\n",
    "for _index in np.random.choice(14321,160,replace=False):\n",
    "    random_gene_list.append(h_genes_ordered[_index])\n",
    "rand_neighbours = does_have_neighbour(random_gene_list).count(True)\n",
    "print(rand_neighbours)\n",
    "stats.fisher_exact([[rand_neighbours, 1506],[1164,1506]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elements_with_overlap(gene_list, all_gene_bed_fn, feature_bed_fn):\n",
    "    \"\"\"The takes a list of genes/proteins and checks which of those overlap with\n",
    "    a feature in the feature bed.\n",
    "    Returns the number of elements with overlap and\n",
    "    number of tested overlaps.\"\"\"\n",
    "    from pybedtools import BedTool\n",
    "    tmp_gene_df = pd.read_csv(all_gene_bed_fn, header=None, sep='\\t')\n",
    "    #now subset the tmp_gene_df and save to file\n",
    "    tmp_fn = all_gene_bed_fn.replace('bed','bed_tmp')\n",
    "    #fix gene list\n",
    "    new_gene_list = []\n",
    "    for x in gene_list:\n",
    "        if 'model' in x:\n",
    "            new_gene_list.append(x.replace('model', 'TU'))\n",
    "        elif 'TU' in x:\n",
    "            new_gene_list.append(x)\n",
    "        \n",
    "    tmp_gene_df[tmp_gene_df[3].isin(new_gene_list)]\\\n",
    "                .to_csv(tmp_fn, header =None, sep='\\t', index=None)\n",
    "    tmp_gene_bed = BedTool(tmp_fn)\n",
    "    feature_bed = BedTool(feature_bed_fn)\n",
    "    tmp_bed = tmp_gene_bed.intersect(feature_bed,c=True)\n",
    "    total_querries = len(tmp_bed)\n",
    "    querries_w_overlap = tmp_bed.to_dataframe().iloc[:, -1].sum()\n",
    "    #n = 0\n",
    "    return querries_w_overlap, total_querries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##look how much overlap we got\n",
    "mapped_on_each_other_p_fn = os.path.join(ALLELE_PATH, '..','Pst_104E_v12_p_ctg.p_by_h_cov.gff')\n",
    "mapped_on_each_other_h_fn = os.path.join(ALLELE_PATH, '..','Pst_104E_v12_ph_ctg.p_on_h_cov.gff')\n",
    "p_gene_bed_fn = os.path.join(LIST_PATH, 'Pst_104E_v12_p_all.gene.bed')\n",
    "h_gene_bed_fn = os.path.join(LIST_PATH, 'Pst_104E_v12_h_all.gene.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_w_overlap, ps = elements_with_overlap(shg, p_gene_bed_fn, mapped_on_each_other_p_fn)\n",
    "h_w_overlap, hs = elements_with_overlap(shg, h_gene_bed_fn, mapped_on_each_other_h_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1506 shg 14 are have a corresponding associated contig overlap\n"
     ]
    }
   ],
   "source": [
    "print('Out of %i shg %i are have a corresponding associated contig overlap' \\\n",
    "      % (ps+hs, p_w_overlap+ h_w_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1506 random gene list 1230 are have a corresponding associated contig overlap\n"
     ]
    }
   ],
   "source": [
    "random_gene_list = [p_genes_ordered[x] for x in np.random.choice(15928, 1346, replace=False)]\n",
    "for _index in np.random.choice(14321,160, replace=False):\n",
    "    random_gene_list.append(h_genes_ordered[_index])\n",
    "p_w_overlap, ps = elements_with_overlap(random_gene_list, p_gene_bed_fn, mapped_on_each_other_p_fn)\n",
    "h_w_overlap, hs = elements_with_overlap(random_gene_list, h_gene_bed_fn, mapped_on_each_other_h_fn)\n",
    "print('Out of %i random gene list %i are have a corresponding associated contig overlap' \\\n",
    "      % (ps+hs, p_w_overlap+ h_w_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87.5, 4.5616436800986692e-265)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.fisher_exact([[1225, 1506],[14,1506]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##lazy old version\n",
    "#this is a dirty and quick way to check if genes are in regions that have and primary/hapltig overlap.\n",
    "intersect_list = []\n",
    "#this could also be written with pybedtools and -c flag which gives the cound of how often each\n",
    "#element in a has overlaped with b in the last column \n",
    "for y in shg:\n",
    "    gene = y.replace('model', 'TU')\n",
    "    if 'pcontig' in y:\n",
    "        mapped_on_each_other_fn = os.path.join(ALLELE_PATH, '..','Pst_104E_v12_p_ctg.p_by_h_cov.gff')\n",
    "        gene_list_fn = os.path.join(LIST_PATH, 'Pst_104E_v12_p_all.gene.bed')\n",
    "    elif 'hcontig' in y:\n",
    "        mapped_on_each_other_fn = os.path.join(ALLELE_PATH, '..','Pst_104E_v12_ph_ctg.p_on_h_cov.gff')\n",
    "        gene_list_fn = os.path.join(LIST_PATH, 'Pst_104E_v12_h_all.gene.bed')\n",
    "    a = !grep -w '{gene}' {gene_list_fn} | bedtools intersect -a - -b {mapped_on_each_other_fn}\n",
    "    intersect_list.append(a)\n",
    "print(intersect_list.count([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are looking a bit on how many hits the shg have in the NCBI and in the ensmble database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemblhits = pd.read_csv(ensembl_blast, header=None, sep='\\t')[0].unique()\n",
    "ncbihits = pd.read_csv(ncbi_blast, header=None, sep='\\t')[0].unique()\n",
    "shg_db_hits = [x for x in ensemblhits]\n",
    "print(len(shg_db_hits ))\n",
    "for _id in ncbihits:\n",
    "    if _id.replace('TU', 'model') not in ensemblhits:\n",
    "        shg_db_hits.append(_id.replace('TU', 'model'))\n",
    "print(len(shg_db_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the no hits\n",
    "shg_db_nohits = [x for x in shg if x not in shg_db_hits]\n",
    "print(len(shg_db_nohits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shg_db_nohits_len = [len(x.seq) for x in return_gene_fasta(shg_db_nohits, ph_gene_fasta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(shg_db_nohits_len), np.mean(genome_len))\n",
    "len([x for x in p_gene_dict['EFFECTORS'] if x in shg_db_nohits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(shg_db_nohits_len, genome_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.median(shg_db_nohits_len), np.median(genome_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many are effectors\n",
    "print(len([x for x in p_gene_dict['EFFECTORS'] if x in shg_db_nohits]) +\\\n",
    "     len([x for x in h_gene_dict['EFFECTORS'] if x in shg_db_nohits]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sectreted\n",
    "print(len([x for x in p_gene_dict['SIGNALP3'] if x in shg_db_nohits]) +\\\n",
    "     len([x for x in h_gene_dict['SIGNALP3'] if x in shg_db_nohits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#haustoria\n",
    "print(len([x for x in p_gene_dict['HAUSTORIA'] if x in shg_db_nohits]) +\\\n",
    "     len([x for x in h_gene_dict['HAUSTORIA'] if x in shg_db_nohits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quickly check for expression\n",
    "expression = []\n",
    "for x  in shg_db_nohits:\n",
    "    p_counttable = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/expression_analysis/TSRM/Pst_104E_v12_p_ctg/stringtie/Pst_104E_v12_p_ctg.in_house_IDParent.STAR.featureCounts.txt'\n",
    "    h_counttable = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/expression_analysis/TSRM/Pst_104E_v12_h_ctg/stringtie/Pst_104E_v12_h_ctg.in_house.STAR.featureCounts.txt'\n",
    "    gene_name = x #.replace(\"model\", \"TU\")\n",
    "    if 'pcontig' in x:\n",
    "        hit = !grep -w '{gene_name}' {p_counttable}\n",
    "        expression.append(hit)\n",
    "    if 'hcontig' in x:\n",
    "        hit = !grep -w '{gene_name}' {h_counttable}\n",
    "        expression.append(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make an expression dict were the read counts are a list with each position representig count\n",
    "#mapped reads under one condition\n",
    "shg_db_nohits_exp_dict = {}\n",
    "for x in expression:\n",
    "    gene = x[0].split('\\t')[0]\n",
    "    shg_db_nohits_exp_dict[gene] = x[0].split('\\t')[-18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if the expression (count of aligned fragments in sum) is > 100\n",
    "len([x for x in shg_db_nohits_exp_dict.keys() \\\n",
    "     if np.sum([int(y) for y in shg_db_nohits_exp_dict[x]]) > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if those are effectors\n",
    "len([x for x in shg_db_nohits_exp_dict.keys() \\\n",
    "     if (np.sum([int(y) for y in shg_db_nohits_exp_dict[x]]) > 100)\\\n",
    "     and (x in p_gene_dict['EFFECTORS'] or x in h_gene_dict['EFFECTORS'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare for paml codeml analysis\n",
    "* write out protein sequences and cds sequences for each pair to new folder\n",
    "* write bash script for alignment and codeml\n",
    "* make pmal cnt file in same folder and tree file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAML_PATH = os.path.join(OUT_PATH, 'paml')\n",
    "if not os.path.exists(PAML_PATH):\n",
    "    os.mkdir(PAML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(os.path.join(PAML_PATH, 'paml_script.sh'), 'a') as aln_fh:\n",
    "        print('#!/bin/bash', file=aln_fh)\n",
    "for index, row in allele_df.iterrows():\n",
    "    #make new folder\n",
    "    _tmp_allele_path = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]))\n",
    "    if not os.path.exists(_tmp_allele_path):\n",
    "        os.mkdir(os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1])))\n",
    "    _tmp_cds_list = return_gene_fasta_paml([row[0], row[1]], ph_cds_fasta)\n",
    "    _tmp_protein_list = return_gene_fasta([row[0], row[1]], ph_protein_fasta)\n",
    "    with open(os.path.join(_tmp_allele_path, 'protein.fa'),'w') as p_fh:\n",
    "        SeqIO.write(_tmp_protein_list, p_fh, 'fasta')\n",
    "    with open(os.path.join(_tmp_allele_path, 'cds.fa'),'w') as p_fh:\n",
    "        SeqIO.write(_tmp_cds_list, p_fh, 'fasta')\n",
    "    #now write tree file\n",
    "    with open(os.path.join(_tmp_allele_path, 'tree.tree'), 'w') as tree_fh:\n",
    "        print('(%s, %s);' % (_tmp_protein_list[0].id, _tmp_protein_list[1].id), file=tree_fh)\n",
    "    #now write alignment bash alignment script\n",
    "    with open(os.path.join(PAML_PATH, 'paml_script.sh'), 'a') as aln_fh:\n",
    "        print('cd %s' % _tmp_allele_path, file=aln_fh)\n",
    "        print('muscle -clwstrict -in protein.fa -out protein.aln', file=aln_fh)\n",
    "        print('perl ../pal2nal.pl -output paml protein.aln cds.fa > cds_codon.aln', file=aln_fh)\n",
    "        print('perl ../pal2nal.pl protein.aln cds.fa > cds_codon.clustal', file=aln_fh)\n",
    "        print('cp %s/codeml.ctl ./' % PAML_PATH, file=aln_fh )\n",
    "        print('codeml', file=aln_fh)\n",
    "    #to test briefly\n",
    "    count +=1\n",
    "    #if count >3:\n",
    "       # break\n",
    "stderr = !bash {os.path.join(PAML_PATH, 'paml_script.sh')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22629969418960244\n",
      "0.22629969418960244\n",
      "0.22256201155283725\n",
      "0.22256201155283725\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "overall_count = 0\n",
    "for x in [1]:\n",
    "    seq_list = []\n",
    "    folder = 'evm.model.pcontig_002.283_evm.model.hcontig_002_028.41'\n",
    "    tmp_protein_aln =os.path.join(PAML_PATH, \\\n",
    "                            folder,'protein.aln')\n",
    "    for x in AlignIO.read(open(tmp_protein_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    print(distance.hamming(seq_list[0], seq_list[1], normalized=True))\n",
    "    print(distance.levenshtein(seq_list[0], seq_list[1], normalized=True))\n",
    "    #from the clustal alignment alignment done one th\n",
    "    tmp_cds_aln = os.path.join(PAML_PATH, folder,'cds_codon.clustal')\n",
    "    seq_list = []\n",
    "    for x in AlignIO.read(open(tmp_cds_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    print(distance.hamming(seq_list[0], seq_list[1], normalized=True))\n",
    "    print(distance.levenshtein(seq_list[0], seq_list[1], normalized=True))\n",
    "    overall_count += 1\n",
    "    print(overall_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tmp_yn = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]),'yn.out')\n",
    "tmp_yn= os.path.join(PAML_PATH, 'evm.model.pcontig_057.104_evm.model.hcontig_057_009.2', 'yn.out')\n",
    "yn_count = 0\n",
    "yn_seq_count = 0\n",
    "with open(tmp_yn, 'r') as fn:\n",
    "        for line in fn:\n",
    "            yn_count += 1\n",
    "            if line.startswith('seq. seq. '):\n",
    "                yn_seq_count = yn_count\n",
    "            if yn_seq_count >0  and yn_count == yn_seq_count + 2:\n",
    "                #print(re.findall(r'dN/dS=(.*)dN', line))\n",
    "                #dNdS = re.findall(r'dN/dS=(.*)dN', line)[0].replace(' ','')\n",
    "                dN = line.split('+-')[0].rstrip().split(' ')[-1]\n",
    "                dS = line.split('+-')[1].rstrip().split(' ')[-1]\n",
    "                if float(dS) > 0:\n",
    "                    print(float(dN)/float(dS))\n",
    "            if line.startswith('LWL85:'):\n",
    "                dN = re.findall(r'dN =  (.*) w',line)[0]\n",
    "                dS = re.findall(r'dS =  (.*) dN', line)[0]\n",
    "                if float(dS) > 0:\n",
    "                    print(float(dN)/float(dS))\n",
    "                #print(dNdS)\n",
    "                #allele_df.loc[index, 'codmel_dN/dS'] = dNdS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_df['vn00_dN/dS'] = np.nan\n",
    "allele_df['LWL85_dN/dS'] = np.nan\n",
    "allele_df['LWL85m_dN/dS'] = np.nan\n",
    "allele_df['LPB93_dN/dS'] = np.nan\n",
    "allele_df['codmel_dN/dS'] = np.nan\n",
    "allele_df['protein_hamming'] = np.nan\n",
    "allele_df['cds_hamming'] = np.nan\n",
    "allele_df['protein_levenshtein'] = np.nan\n",
    "allele_df['cds_levenshtein'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_allele_df = allele_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "#now pull in the dN/dS ratios\n",
    "\n",
    "overall_count = 0\n",
    "for index, row in allele_df.iterrows():\n",
    "    seq_list = []\n",
    "    tmp_protein_aln = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]),'protein.aln')\n",
    "    for x in AlignIO.read(open(tmp_protein_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    new_allele_df.loc[index, 'protein_hamming'] = distance.hamming(seq_list[0], seq_list[1], normalized=True)\n",
    "    new_allele_df.loc[index, 'protein_levenshtein'] \\\n",
    "    = distance.levenshtein(seq_list[0], seq_list[1], normalized=True)\n",
    "    #print(index)\n",
    "    #print(new_allele_df.loc[index, 'protein_levenshtein'])\n",
    "    #from the clustal alignment alignment done one th\n",
    "    tmp_cds_aln = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]),'cds_codon.clustal')\n",
    "    seq_list = []\n",
    "    for x in AlignIO.read(open(tmp_cds_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    new_allele_df.loc[index, 'cds_hamming'] = distance.hamming(seq_list[0], seq_list[1], normalized=True)\n",
    "    new_allele_df.loc[index, 'cds_levenshtein'] \\\n",
    "    = distance.levenshtein(seq_list[0], seq_list[1], normalized=True)\n",
    "    overall_count += 1\n",
    "    #print(overall_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_allele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_count = 0\n",
    "\n",
    "for index, row in allele_df.iterrows():\n",
    "    #fix the yn\n",
    "    tmp_yn = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]),'yn.out')\n",
    "    #fix the yn\n",
    "    with open(tmp_yn, 'r') as fn:\n",
    "        #initiate a bunch of values\n",
    "        dN = 0\n",
    "        dS = 0\n",
    "        dN_L = 0\n",
    "        dS_L = 0\n",
    "        dN_m = 0\n",
    "        dS_m = 0\n",
    "        dN_p = 0 \n",
    "        dS_p = 0 \n",
    "        #now loop over the lines and parse out stuff\n",
    "        for line in fn:\n",
    "            yn_count += 1\n",
    "            if line.startswith('seq. seq. '):\n",
    "                yn_seq_count = yn_count\n",
    "            if yn_seq_count >0  and yn_count == yn_seq_count + 2:\n",
    "                #print(re.findall(r'dN/dS=(.*)dN', line))\n",
    "                #dNdS = re.findall(r'dN/dS=(.*)dN', line)[0].replace(' ','')\n",
    "                dN = line.split('+-')[0].rstrip().split(' ')[-1]\n",
    "                dS = line.split('+-')[1].rstrip().split(' ')[-1]\n",
    "                if float(dS) > 0:\n",
    "                    new_allele_df.loc[index, 'vn00_dN/dS'] = float(dN)/float(dS)\n",
    "            if line.startswith('LWL85:') and 'nan' not in line:\n",
    "                dN_L =re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                dS_L = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_L) > 0:\n",
    "                    new_allele_df.loc[index, 'LWL85_dN/dS'] = float(dN_L)/float(dS_L)\n",
    "            if line.startswith('LWL85m:') and 'nan' not in line:\n",
    "                dN_m = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                dS_m = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_m) > 0:\n",
    "                    new_allele_df.loc[index, 'LWL85m_dN/dS'] = float(dN_m)/float(dS_m)\n",
    "            if line.startswith('LPB93:') and 'nan' not in line:\n",
    "                dN_p = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                dS_p = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_m) > 0:\n",
    "                    new_allele_df.loc[index, 'LPB93_dN/dS'] = float(dN_p)/float(dS_p)\n",
    "    #fix codmel\n",
    "    tmp_codmel = os.path.join(PAML_PATH, '%s_%s' % (row[0],row[1]),'codeml.out')\n",
    "    #now open the file an pull out the dN/dS ratio\n",
    "    with open(tmp_codmel, 'r') as fn:\n",
    "        dNdS = 0\n",
    "        for line in fn:\n",
    "            if line.startswith('t='):\n",
    "                #print(re.findall(r'dN/dS=(.*)dN', line))\n",
    "                dNdS = re.findall(r'dN/dS=(.*)dN', line)[0].replace(' ','')\n",
    "                #print(line)\n",
    "                #print(dNdS)\n",
    "                new_allele_df.loc[index, 'codmel_dN/dS'] = dNdS\n",
    "    #now get the vn00 results\n",
    "            \n",
    "    #now get the distance of an alignment\n",
    "    #protein first\n",
    "    overall_count += 1\n",
    "    #print(overall_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems still an issue with the parsing for yn00 results otherwise it should be okay but double check 4 places. Issue is not changing the dataframe you are iterrating over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the fixed up dataframe to file\n",
    "new_allele_df_fn = shg_fh = os.path.join(OUT_PATH, 'Pst_104E_v12_p_ctg.all.alleles.new.df')\n",
    "new_allele_df.to_csv(new_allele_df_fn, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_gene', 'h_gene', 'Linkage', 'codmel_dN/dS', 'protein_hamming',\n",
       "       'cds_hamming', 'protein_levenshtein', 'cds_levenshtein', 'vn00_dN/dS',\n",
       "       'LWL85_dN/dS', 'LWL85m_dN/dS', 'LPB93_dN/dS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_allele_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way doing it with dictionaries that are afterwards attached to the dataframe seems the most reliable method so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_df['folder'] = allele_df.p_gene +'_'+allele_df.h_gene \n",
    "allele_df.index = allele_df['folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try a different approach with making dictonaries first and those will be fused to the\n",
    "#dataframe later on\n",
    "dicts_of_dN_sS = {}\n",
    "dicts_of_dN_sS['codmel_dN/dS'] = dict(zip(allele_df.folder, len(allele_df.folder)*[np.nan]))\n",
    "dicts_of_dN_sS['LWL85_dN/dS'] = dict(zip(allele_df.folder, len(allele_df.folder)*[np.nan]))\n",
    "dicts_of_dN_sS['LWL85m_dN/dS'] = dict(zip(allele_df.folder, len(allele_df.folder)*[np.nan]))\n",
    "dicts_of_dN_sS['LPB93_dN/dS'] = dict(zip(allele_df.folder, len(allele_df.folder)*[np.nan]))\n",
    "dicts_of_dN_sS['vn00_dN/dS'] = dict(zip(allele_df.folder, len(allele_df.folder)*[np.nan]))\n",
    "dicts_of_distances = {}\n",
    "dicts_of_distances['cds_hamming'] = {}\n",
    "dicts_of_distances['protein_hamming'] = {}\n",
    "dicts_of_distances['protein_levenshtein'] = {}\n",
    "dicts_of_distances['cds_levenshtein'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "#now pull in the dN/dS ratios\n",
    "overall_count = 0\n",
    "#loop over the folder and add the values as key=folder value pairs to the dict\n",
    "for folder in allele_df.folder:\n",
    "    seq_list = []\n",
    "    tmp_protein_aln = os.path.join(PAML_PATH, folder,'protein.aln')\n",
    "    for x in AlignIO.read(open(tmp_protein_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    dicts_of_distances['protein_hamming'][folder]\\\n",
    "    = distance.hamming(seq_list[0], seq_list[1], normalized=True)\n",
    "    dicts_of_distances['protein_levenshtein'][folder]\\\n",
    "    = distance.levenshtein(seq_list[0], seq_list[1], normalized=True)\n",
    "    \n",
    "    tmp_cds_aln = os.path.join(PAML_PATH, folder,'cds_codon.clustal')\n",
    "    seq_list = []\n",
    "    for x in AlignIO.read(open(tmp_cds_aln, 'r'), format = \"clustal\", seq_count=2):\n",
    "        seq_list.append(str(x.seq).upper())\n",
    "    dicts_of_distances['cds_hamming'][folder]\\\n",
    "    = distance.hamming(seq_list[0], seq_list[1], normalized=True)\n",
    "    dicts_of_distances['cds_levenshtein'][folder]\\\n",
    "    = distance.levenshtein(seq_list[0], seq_list[1], normalized=True)\n",
    "    overall_count += 1\n",
    "    #print(overall_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_count = 0\n",
    "\n",
    "for folder in allele_df.folder:\n",
    "    #fix the yn\n",
    "    tmp_yn = os.path.join(PAML_PATH, folder,'yn.out')\n",
    "    #fix the yn\n",
    "    with open(tmp_yn, 'r') as fn:\n",
    "        #initiate a bunch of values\n",
    "        dN = 0\n",
    "        dS = 0\n",
    "        dN_L = 0\n",
    "        dS_L = 0\n",
    "        dN_m = 0\n",
    "        dS_m = 0\n",
    "        dN_p = 0 \n",
    "        dS_p = 0 \n",
    "        #now loop over the lines and parse out stuff\n",
    "        for line in fn:\n",
    "            yn_count += 1\n",
    "            if line.startswith('seq. seq. '):\n",
    "                yn_seq_count = yn_count\n",
    "            if yn_seq_count >0  and yn_count == yn_seq_count + 2:\n",
    "                #print(re.findall(r'dN/dS=(.*)dN', line))\n",
    "                #dNdS = re.findall(r'dN/dS=(.*)dN', line)[0].replace(' ','')\n",
    "                dN = line.split('+-')[0].rstrip().split(' ')[-1]\n",
    "                dS = line.split('+-')[1].rstrip().split(' ')[-1]\n",
    "                if float(dS) > 0:\n",
    "                    dicts_of_dN_sS['vn00_dN/dS'][folder] = float(dN)/float(dS)\n",
    "                else: \n",
    "                    dicts_of_dN_sS['vn00_dN/dS'][folder] = np.nan\n",
    "            if line.startswith('LWL85:') and 'nan' not in line:\n",
    "                dN_L =re.findall(r'dN = [-| ]?(.*) w', line)[0]\n",
    "                dS_L = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_L) > 0:\n",
    "                    dicts_of_dN_sS['LWL85_dN/dS'][folder] = float(dN_L)/float(dS_L)\n",
    "                else:\n",
    "                    dicts_of_dN_sS['LWL85_dN/dS'][folder] = np.nan\n",
    "            if line.startswith('LWL85m:') and 'nan' not in line:\n",
    "                dN_m = re.findall(r'dN = [-| ]?(.*) w', line)[0]\n",
    "                dS_m = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_m) > 0:\n",
    "                    dicts_of_dN_sS['LWL85m_dN/dS'][folder] = float(dN_m)/float(dS_m)\n",
    "                else:\n",
    "                    dicts_of_dN_sS['LWL85m_dN/dS'][folder] = np.nan\n",
    "            if line.startswith('LPB93:') and 'nan' not in line:\n",
    "                dN_p = re.findall(r'dN = [-| ]?(.*) w', line)[0]\n",
    "                dS_p = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "                if float(dS_m) > 0:\n",
    "                    dicts_of_dN_sS['LPB93_dN/dS'][folder] = float(dN_p)/float(dS_p)\n",
    "                else:\n",
    "                    dicts_of_dN_sS['LPB93_dN/dS'][folder] = np.nan\n",
    "    #fix codmel\n",
    "    tmp_codmel = os.path.join(PAML_PATH, folder,'codeml.out')\n",
    "    #now open the file an pull out the dN/dS ratio\n",
    "    with open(tmp_codmel, 'r') as fn:\n",
    "        dNdS = 0\n",
    "        for line in fn:\n",
    "            if line.startswith('t='):\n",
    "                #print(re.findall(r'dN/dS=(.*)dN', line))\n",
    "                dNdS = re.findall(r'dN/dS=(.*)dN', line)[0].replace(' ','')\n",
    "                #print(line)\n",
    "                #print(dNdS)\n",
    "                dicts_of_dN_sS['codmel_dN/dS'][folder] = dNdS\n",
    "    #now get the vn00 results\n",
    "            \n",
    "    #now get the distance of an alignment\n",
    "    #protein first\n",
    "    overall_count += 1\n",
    "    #print(overall_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LWL85_dN/dS', 'vn00_dN/dS', 'codmel_dN/dS', 'LPB93_dN/dS', 'LWL85m_dN/dS'])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dicts_of_dN_sS.keys():\n",
    "    allele_df[key] = allele_df.folder.apply(lambda x: dicts_of_dN_sS[key][x])\n",
    "dicts_of_dN_sS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cds_hamming', 'protein_hamming', 'cds_levenshtein', 'protein_levenshtein'])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dicts_of_distances.keys():\n",
    "    allele_df[key] = allele_df.folder.apply(lambda x: dicts_of_distances[key][x])\n",
    "dicts_of_distances.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this out above did four spot checks and they all look good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_gene                                          evm.model.pcontig_002.42\n",
       "h_gene                                      evm.model.hcontig_002_011.37\n",
       "Linkage                                                 h_contig_overlap\n",
       "codmel_dN/dS                                                      0.0571\n",
       "protein_hamming                                               0.00531915\n",
       "cds_hamming                                                    0.0106383\n",
       "protein_levenshtein                                           0.00531915\n",
       "cds_levenshtein                                                0.0106383\n",
       "vn00_dN/dS                                                     0.0657534\n",
       "LWL85_dN/dS                                                    0.0538642\n",
       "LWL85m_dN/dS                                                   0.0764526\n",
       "LPB93_dN/dS                                                    0.0626866\n",
       "folder                 evm.model.pcontig_002.42_evm.model.hcontig_002...\n",
       "Name: evm.model.pcontig_002.42_evm.model.hcontig_002_011.37, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df.iloc[1100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the fixed up dataframe to file\n",
    "allele_df_fn = shg_fh = os.path.join(OUT_PATH, 'Pst_104E_v12_p_ctg.all.alleles.df')\n",
    "allele_df.to_csv(allele_df_fn, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do some quick stats on the dN/dS comparing BUSCOS vs. effectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery',\n",
       "       'StopQuery', 'StartTarget', 'StopTarget', 'e-value', 'BitScore',\n",
       "       'QLgth', 'QCov', 'q_contig', 't_contig', 'q_contig == t_contig',\n",
       "       'p_protein', 'h_contig_overlap', 't_contig == h_contig_overlap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_blast_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now fuse the important columns to the allele blast dataframe\n",
    "allele_blast_df['folder'] = allele_blast_df['Query'] + '_' + allele_blast_df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_hit_df = allele_blast_df[allele_blast_df.folder.isin(allele_df['folder'])]\\\n",
    "        .sort_values(['folder', 'PctID']).drop_duplicates('folder').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_hit_df = pd.merge(allele_hit_df,allele_df.loc[:,\\\n",
    "            ['folder', 'codmel_dN/dS', 'protein_hamming',\n",
    "       'cds_hamming', 'protein_levenshtein', 'cds_levenshtein', 'vn00_dN/dS',\n",
    "       'LWL85_dN/dS', 'LWL85m_dN/dS', 'LPB93_dN/dS']], on='folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_hit_df.to_csv(os.path.join(OUT_PATH, 'Pst_104E_v12_p_ctg.all.alleles.hit.df')\\\n",
    "                     , index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(allele_hit_df.Query.apply(lambda x: x in p_gene_dict['EFFECTORS'])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_hit_df['P_EFFECTOR'] = allele_hit_df.Query.apply(lambda x: x in p_gene_dict['EFFECTORS'])\n",
    "allele_hit_df['P_BUSCO'] =  allele_hit_df.Query.apply(lambda x: x in p_gene_dict['BUSCOS'])\n",
    "allele_hit_df['H_EFFECTOR'] = allele_hit_df.Target.apply(lambda x: x in h_gene_dict['EFFECTORS'])\n",
    "allele_hit_df['H_BUSCO'] =  allele_hit_df.Target.apply(lambda x: x in h_gene_dict['BUSCOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_hit_df['P_OTHER_GENE'] =  allele_hit_df.Query.apply(lambda x:\\\n",
    "                        x not in p_gene_dict['BUSCOS'] and x not in p_gene_dict['EFFECTORS'])\n",
    "allele_hit_df['H_OTHER_GENE'] =  allele_hit_df.Target.apply(lambda x:\\\n",
    "                        x not in h_gene_dict['BUSCOS'] and x not in h_gene_dict['EFFECTORS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Target</th>\n",
       "      <th>PctID</th>\n",
       "      <th>AlnLgth</th>\n",
       "      <th>NumMis</th>\n",
       "      <th>NumGap</th>\n",
       "      <th>StartQuery</th>\n",
       "      <th>StopQuery</th>\n",
       "      <th>StartTarget</th>\n",
       "      <th>StopTarget</th>\n",
       "      <th>...</th>\n",
       "      <th>vn00_dN/dS</th>\n",
       "      <th>LWL85_dN/dS</th>\n",
       "      <th>LWL85m_dN/dS</th>\n",
       "      <th>LPB93_dN/dS</th>\n",
       "      <th>P_EFFECTOR</th>\n",
       "      <th>P_BUSCO</th>\n",
       "      <th>H_EFFECTOR</th>\n",
       "      <th>H_BUSCO</th>\n",
       "      <th>H_OTHER_GENE</th>\n",
       "      <th>P_OTHER_GENE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evm.model.pcontig_000.100</td>\n",
       "      <td>evm.model.hcontig_000_003.107</td>\n",
       "      <td>99.21</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379032</td>\n",
       "      <td>0.364341</td>\n",
       "      <td>0.445455</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evm.model.pcontig_000.101</td>\n",
       "      <td>evm.model.hcontig_000_003.108</td>\n",
       "      <td>89.03</td>\n",
       "      <td>237.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.408971</td>\n",
       "      <td>0.650298</td>\n",
       "      <td>0.971717</td>\n",
       "      <td>0.894180</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evm.model.pcontig_000.102</td>\n",
       "      <td>evm.model.hcontig_000_003.109</td>\n",
       "      <td>100.00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evm.model.pcontig_000.103</td>\n",
       "      <td>evm.model.hcontig_000_003.110</td>\n",
       "      <td>97.73</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evm.model.pcontig_000.104</td>\n",
       "      <td>evm.model.hcontig_000_003.111</td>\n",
       "      <td>98.53</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Query                         Target   PctID  AlnLgth  \\\n",
       "0  evm.model.pcontig_000.100  evm.model.hcontig_000_003.107   99.21   1141.0   \n",
       "1  evm.model.pcontig_000.101  evm.model.hcontig_000_003.108   89.03    237.0   \n",
       "2  evm.model.pcontig_000.102  evm.model.hcontig_000_003.109  100.00    107.0   \n",
       "3  evm.model.pcontig_000.103  evm.model.hcontig_000_003.110   97.73     88.0   \n",
       "4  evm.model.pcontig_000.104  evm.model.hcontig_000_003.111   98.53     68.0   \n",
       "\n",
       "   NumMis  NumGap  StartQuery  StopQuery  StartTarget  StopTarget  \\\n",
       "0     9.0     0.0         1.0     1141.0          1.0      1141.0   \n",
       "1    20.0     1.0         1.0      231.0          1.0       237.0   \n",
       "2     0.0     0.0         1.0      107.0          1.0       107.0   \n",
       "3     2.0     0.0         8.0       95.0          1.0        88.0   \n",
       "4     1.0     0.0         1.0       68.0          1.0        68.0   \n",
       "\n",
       "       ...       vn00_dN/dS  LWL85_dN/dS  LWL85m_dN/dS  LPB93_dN/dS  \\\n",
       "0      ...         0.379032     0.364341      0.445455     0.465347   \n",
       "1      ...         1.408971     0.650298      0.971717     0.894180   \n",
       "2      ...              NaN          NaN           NaN          NaN   \n",
       "3      ...              NaN          NaN           NaN          NaN   \n",
       "4      ...              NaN          NaN           NaN          NaN   \n",
       "\n",
       "  P_EFFECTOR P_BUSCO  H_EFFECTOR H_BUSCO H_OTHER_GENE  P_OTHER_GENE  \n",
       "0      False   False       False   False         True          True  \n",
       "1      False   False       False   False         True          True  \n",
       "2      False   False       False   False         True          True  \n",
       "3      False   False       False   False         True          True  \n",
       "4      False   False       False   False         True          True  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_hit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_hit_df.to_csv(os.path.join(OUT_PATH, 'Pst_104E_v12_p_ctg.all.alleles.hit.df')\\\n",
    "                     , index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe7a6ab3358>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAELCAYAAADuufyvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a4066a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['protein_levenshtein'],cut=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe7a16f3b00>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAELCAYAAADuufyvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a40df5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['protein_levenshtein'],cut=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe7a4067b70>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAELCAYAAADuufyvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a4066cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(allele_df[~(allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])|\\\n",
    "            allele_df.p_gene.isin(p_gene_dict['BUSCOS']))]['cds_levenshtein'], cut=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['dN/dS'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-1.9831977958239608, pvalue=0.047345340018046141)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ranksums(allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['cds_levenshtein'].tolist()\\\n",
    "               ,allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['cds_levenshtein'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unequal N in wilcoxon.  Aborting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-923f007ad8bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwilcoxon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallele_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallele_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_gene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_gene_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EFFECTORS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cds_levenshtein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;34m,\u001b[0m\u001b[0mallele_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallele_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_gene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_gene_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BUSCOS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cds_levenshtein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/scipy/stats/morestats.py\u001b[0m in \u001b[0;36mwilcoxon\u001b[0;34m(x, y, zero_method, correction)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unequal N in wilcoxon.  Aborting.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unequal N in wilcoxon.  Aborting."
     ]
    }
   ],
   "source": [
    "#make a wilcoxon possible\n",
    "array_1 = allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['cds_levenshtein']\n",
    "array_2 = allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['cds_levenshtein']\n",
    "if len(array_1) != len(array_2) and len(array_1) > len(array_2):\n",
    "    n = len(array_2)\n",
    "else:\n",
    "    n = len(array_1)\n",
    "    \n",
    "sub_array_1 = np.random.choice(array_1, )\n",
    "stats.wilcoxon(allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['cds_levenshtein'].tolist()\\\n",
    "               ,allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['cds_levenshtein'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04068398168371404"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['cds_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028763144144375755"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['cds_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05912425136643261"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])]['protein_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026462810242390274"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[allele_df.p_gene.isin(p_gene_dict['BUSCOS'])]['protein_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057879375674427296"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[~(allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])|\\\n",
    "            allele_df.p_gene.isin(p_gene_dict['BUSCOS']))]['cds_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06372272433230429"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_df[~(allele_df.p_gene.isin(p_gene_dict['EFFECTORS'])|\\\n",
    "            allele_df.p_gene.isin(p_gene_dict['BUSCOS']))]['protein_levenshtein'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pick a couple of the non_respective_haplotype alignements and get sequencing data for those to make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_respective_alleles_fn = os.path.join(ALLELE_PATH, 'Pst_104E_v12_p_ctg.no_respective_h_contig_overlap.alleles')\n",
    "contig_fa_fn = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.fa')\n",
    "gene_fa_fn = os.path.join(BASE_A_PATH, 'Pst_104E_v12_ph_ctg.anno.gene.fa')\n",
    "OUT_PATH_NO_RES = os.path.join(OUT_PATH, 'no_respect_fasta')\n",
    "if not os.path.exists(OUT_PATH_NO_RES):\n",
    "    os.mkdir(OUT_PATH_NO_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_respective_alleles_df = pd.read_csv(no_respective_alleles_fn, sep='\\t', header=None, names=['pgene', 'hgene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the contig genes are on\n",
    "no_respective_alleles_df['pcontig'] = no_respective_alleles_df.pgene.str.extract(r'(p[^.]*)')\n",
    "no_respective_alleles_df['hcontig'] = no_respective_alleles_df.hgene.str.extract(r'(h[^.]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare for filtering on most hit contigs. First by a group by function\n",
    "no_ra_linkage_count_df = no_respective_alleles_df.groupby(['pcontig','hcontig'])['pgene'].count()\n",
    "no_ra_linkage_count_max = no_respective_alleles_df.groupby(['pcontig','hcontig'])['pgene']\\\n",
    "            .count().max(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ra_linkage_count_df = no_ra_linkage_count_df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_contig_list = []\n",
    "most_linked_hcontig = []\n",
    "number_of_hits = []\n",
    "for _index, row in no_ra_linkage_count_df.iterrows():\n",
    "    if row.max() > 2:\n",
    "        p_contig_list.append(_index)\n",
    "        most_linked_hcontig.append(row[row==no_ra_linkage_count_max[_index]].index.tolist()[0])\n",
    "        number_of_hits.append(row[row==no_ra_linkage_count_max[_index]].max())\n",
    "        #print('primary contig %s and %s overlaps %i' %\\\n",
    "              #(_index, row[row==no_ra_linkage_count_max[_index]].index.tolist()[0],row[row==no_ra_linkage_count_max[_index]].max() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df = pd.concat([pd.Series(p_contig_list)\\\n",
    "                            , pd.Series(most_linked_hcontig), pd.Series(number_of_hits)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df.rename(columns={0:'pcontig', 1:'hcontig', 2:'number_of_overlaps'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now loop over the best hit dataframe to get all the fasta sequences of the repective alleles\n",
    "\n",
    "for _index, row in most_linked_non_ra_alleles_df.iterrows():\n",
    "    tmp_p_contig = row['pcontig']\n",
    "    tmp_h_contig = row['hcontig']\n",
    "    h_genes = no_respective_alleles_df[(no_respective_alleles_df.pcontig==tmp_p_contig)&\\\n",
    "                                      (no_respective_alleles_df.hcontig==tmp_h_contig)]\\\n",
    "                                        ['hgene'].unique()\n",
    "    p_genes = no_respective_alleles_df[(no_respective_alleles_df.pcontig==tmp_p_contig)&\\\n",
    "                                      (no_respective_alleles_df.hcontig==tmp_h_contig)]\\\n",
    "                                        ['pgene'].unique()\n",
    "    #get the h_gene and p_gene sequenes\n",
    "    h_gene_seq = return_gene_fasta(h_genes, gene_fa_fn)\n",
    "    p_gene_seq = return_gene_fasta(p_genes, gene_fa_fn)\n",
    "    with open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_pgene.fa' %tmp_p_contig), 'w') as fh:\n",
    "        SeqIO.write(p_gene_seq, fh, 'fasta')\n",
    "    with open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_hgene.fa' %tmp_p_contig), 'w') as fh:\n",
    "        SeqIO.write(h_gene_seq, fh, 'fasta')\n",
    "    #get the contig sequences\n",
    "    p_contig_seq = return_contig_fasta([tmp_p_contig], contig_fa_fn)\n",
    "    h_contig_seq = return_contig_fasta([tmp_h_contig], contig_fa_fn)\n",
    "    with open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_pcontig.fa' %tmp_p_contig), 'w') as fh:\n",
    "        SeqIO.write(p_contig_seq, fh, 'fasta')\n",
    "    with open(os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_hcontig.fa' %tmp_p_contig), 'w') as fh:\n",
    "        SeqIO.write(h_contig_seq, fh, 'fasta')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add quick mummerplots\n",
    "os.chdir(OUT_PATH_NO_RES)\n",
    "for _index, row in most_linked_non_ra_alleles_df.iterrows():\n",
    "    tmp_p_contig = row['pcontig']\n",
    "    tmp_h_contig = row['hcontig']\n",
    "    ref = os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_pcontig.fa' %tmp_p_contig)\n",
    "    query = os.path.join(OUT_PATH_NO_RES, 'no_res_allele_%s_hcontig.fa' %tmp_p_contig)\n",
    "    nucmer = '/home/benjamin/anaconda3/bin/nucmer'\n",
    "    !nucmer --maxgap=500 --mincluster=100 --prefix={ref[:-3]} {ref} {query}\n",
    "    !show-coords -r {ref[:-3]}.delta > {ref[:-3]}.coords\n",
    "    !delta-filter -q -r {ref[:-3]}.delta > {ref[:-3]}.filter\n",
    "    !perl /home/benjamin/anaconda3/bin/mummerplot --postscript {ref[:-3]}.filter -R {ref} -Q {query} --prefix={ref[:-3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!which nucmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df.sort_values('number_of_overlaps', inplace=True)\n",
    "most_linked_non_ra_alleles_df.to_csv(os.path.join(OUT_PATH_NO_RES, 'max_linkage_per_pcontig.tab'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check out the lenght of those contigs\n",
    "c_list = return_contig_fasta(most_linked_non_ra_alleles_df.pcontig.unique(), contig_fa_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_len_list = [len(x.seq) for x in c_list]\n",
    "all_len_list = [len(x.seq) for x in return_contig_fasta(allele_blast_df.q_contig.unique(), contig_fa_fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.ranksums(c_len_list, all_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mean and median of contigs with 2> linkages to another haplotig\n",
    "print(np.mean(c_len_list),np.median(c_len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mean and median of contigs with 2> linkages to another haplotig\n",
    "print(np.mean(all_len_list),np.median(all_len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_linked_non_ra_alleles_df.number_of_overlaps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ra_linkage_count_df.sum(axis=1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ra_linkage_count_df.sum(axis=1)/\\\n",
    "[len(x.seq) for x in return_contig_fasta(no_ra_linkage_count_df.sum(axis=1).index, contig_fa_fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls {BASE_A_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tmp_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df.QCov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QP_filter = (allele_QC_df.QCov >= QCov_limit) & (allele_QC_df.PctID >= PctID_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now a bit more specific for each haplotyp\n",
    "os.chdir(ALLELE_QC_PATH)\n",
    "allele_blast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
