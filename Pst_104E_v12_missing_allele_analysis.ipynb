{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Jupyter notebook is targeted towards QC analysis of gene models without alleles in a phased assembly\n",
    "The script will pick up were *_defining alleles left off. In general it can take a list of genes without alleles in a phased assembly and can look why those were missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will consider the following options:\n",
    "\n",
    "#### The allele was left out of the annotation in the other haplotig:\n",
    "* It takes the gene sequence of a single allele gene and blast its against the other haplotic\n",
    "* If there is an gene sequence it pulls out a region around this and align the protein sequence using exonerate\n",
    "* The exonerate alignment is used to scan for matches without frame shifts and without stop codons\n",
    "* In cases where a good aligment is possible these alleles are written noted\n",
    "\n",
    "#### The allele was left out because it was not phased in the first place\n",
    "This step relies on the Pst_104E_v12_coverage_analysis_training script to give out homozygous regions when doing p mapping when compare to p to ph mapping. Might need to be adapted a bit more.\n",
    "* All remaining single allele genes are tested if they fall into a homozygous coverage area\n",
    "* If they do not overlap with an ortholgos contig alignement p on h mapping and reverse\n",
    "* Maybe if they overlap with a unique coverage area. Only possible for p alleles so far. \n",
    "\n",
    "#### Else to consider would:\n",
    "* look for gene that have no-haplotig aligned and their variation in terms of SNPs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### script considerations\n",
    "\n",
    "What to do when mulitple filtered allele files are present? Mabye have previous script write out different options to different folders if they already exist.\n",
    "When filtering through the exonerate vulgar output one migth want to consider partial alignments as well covering \n",
    "QcPct of the protein sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_outfmt6_to_bed(x):\n",
    "    \"Quick function that converts a blast outfmt6 file to a bed file.\"\n",
    "    blast_fo = open(x, 'r')\n",
    "    blast_lines = blast_fo.readlines()\n",
    "    bed_file_name = x + '.bed'\n",
    "    bed_fo = open(bed_file_name, 'w+')\n",
    "    for l in blast_lines:\n",
    "        content = l.split('\\t')\n",
    "        if int(content[8]) - int(content[9]) < 1:\n",
    "            print(content[1], int(content[8]) -1, content[9], content[0], content[10], \"+\", sep=\"\\t\", file=bed_fo) \n",
    "        else:\n",
    "            print(content[1], int(content[9]) -1, content[8],  content[0], content[10], \"-\", sep = \"\\t\", file=bed_fo)\n",
    "    blast_fo.close()\n",
    "    bed_fo.close()\n",
    "    return bed_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwh_set = []\n",
    "def pwh_filter (q_contig, pwh_set=pwh_set):\n",
    "    '''Checks if contig belongs to the primary with haplotig set.'''\n",
    "    if q_contig in pwh_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_contig_blast(x,y):\n",
    "    '''Function that checks if the blast hit in columne x is on the same contig as the the query sequence in\n",
    "    column y.\n",
    "    '''\n",
    "    q_contig = x.split('.')[2].split('_')[1]\n",
    "    hit_contig = y.split('_')[1]\n",
    "    if q_contig == hit_contig:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_primary_contig (q_contig):\n",
    "    '''Quick function that checks if query is on primary contig or not'''\n",
    "    if q_contig.startswith('hcontig'):\n",
    "        return False\n",
    "    elif q_contig.startswith('pcontig'):\n",
    "        return True\n",
    "    else:\n",
    "        print('Contig annotation needs to start with hcontig or pcontig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH variables to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the PATH\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "BLAST_RESULT_PATH = os.path.join(BASE_AA_PATH,'allele_analysis' )\n",
    "ALLELE_PATH =os.path.join(BASE_AA_PATH ,'allele_analysis/alleles')\n",
    "BLAST_DB = os.path.join(BASE_AA_PATH, 'blast_DB')\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'allele_analysis', 'no_alleles_QC')\n",
    "OUT_PATH_tmp = os.path.join(OUT_PATH, 'tmp')\n",
    "EXONERATE_PATH = os.path.join(OUT_PATH_tmp, 'exonerate')\n",
    "if not os.path.isdir(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n",
    "if not os.path.isdir(OUT_PATH_tmp):\n",
    "    os.mkdir(OUT_PATH_tmp)\n",
    "if not os.path.isdir(EXONERATE_PATH):\n",
    "    os.mkdir(EXONERATE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script variables to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up the tmp folder?\n",
    "clean_up = True #True will delete the tmp folder with tmp blast hits and exonerate output files\n",
    "exonerate_script_name = 'exonerate_alignments_vulgar.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genome IDs to enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#genome\n",
    "p_genome = 'Pst_104E_v12_p_ctg'\n",
    "h_genome = 'Pst_104E_v12_h_ctg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENV parameters and Qcov and PctID cut_offs to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define ENV parameters for blast hits and threads used in blast analysis\n",
    "n_threads = 4\n",
    "e_value = 1e-3\n",
    "blast_stderr_dict ={} #keep track of all the blast outputs and errors if so\n",
    "#here enter the Qcov and PctID cut off you would like to get analyzed. \n",
    "Qcov_cut_off = 80 #this defines the mimimum coverage of the Query to be required for filtering. Will become part of name.\n",
    "PctID_cut_off = 70 #this defines the mimimum PctID accross the alignment to be required for filtering. Will become part of name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protein_fa_files = [os.path.join(BASE_A_PATH, x) for x in os.listdir(BASE_A_PATH) if x.endswith('protein.fa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in protein ids for p and h contigs and store names in a list in a dict with unique key id [first part of\n",
    "#file name].\n",
    "fa_protein_dict = {}\n",
    "fa_protein_seq_dict = {}\n",
    "fa_protein_length_dict = {}\n",
    "for file in protein_fa_files:\n",
    "    seq_list = []\n",
    "    length_list =[]\n",
    "    for seq in SeqIO.parse(open(file), 'fasta'):\n",
    "        fa_protein_seq_dict[seq.id] = seq\n",
    "        fa_protein_length_dict[seq.id] = len(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the file names of the no allele cases including the filtered settings with Qcov and PctID cut offs and the no alleles\n",
    "#at all that in principle is all p and h proteins without a blast hit with a given e-value right now 0.001\n",
    "filtered_no_alleles = [os.path.join(ALLELE_PATH, x) for x in os.listdir(ALLELE_PATH)\\\n",
    "                       if (x.split('.')[1] == 'no' and 'Qcov' in x and 'PctID' in x and x.startswith(p_genome) )or \\\n",
    "                           (x.startswith(h_genome) and 'Qcov' in x and 'PctID' in x and 'no.no_p_hits' in x)]\n",
    "filtered_no_alleles_dict = {}\n",
    "for x in filtered_no_alleles:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    filtered_no_alleles_dict[key] = x\n",
    "    \n",
    "no_alleles_at_all = [os.path.join(ALLELE_PATH, x) for x in os.listdir(ALLELE_PATH)\\\n",
    "                       if (x.split('.')[1] == 'no' and 'Qcov' not in x and 'PctID' not in x and x.startswith(p_genome) )or \\\n",
    "                           (x.startswith(h_genome) and 'Qcov' not in x and 'PctID' not in x and 'no.no_p_hits' in x)]\n",
    "no_alleles_at_all_dict ={}\n",
    "for x in no_alleles_at_all:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    no_alleles_at_all_dict[key] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Might want to be incooporated in the script in future\n",
    "Pull gff and genome fasta files over into the tmp folder make gene gff and pull out gene sequences with bedtools getfasta on the command line using subproccesses. See below ideas from original script"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#now pull gene sequences for no-besties and do blast on the corresponding other haplotype\n",
    "#gene files were generated by \n",
    "cat Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.gff3 | awk '$3==\"gene\"' > Pst_E104_v1_p_ctg.gene.RepaseTPSI_filtered.gff3\n",
    "for gff in gene_gff:\n",
    "    gene = ''\n",
    "    gene_df = pd.read_csv(folder + gff, header = None, sep='\\t' )\n",
    "    gene_df[2] = gene_df[8].apply(col_8_id)\n",
    "    gene_df.to_csv(folder+gff, header=None, sep='\\t', index=None)\n",
    "bedtools getfasta -s -name -fi Pst_E104_v1_ph_ctg.fa -bed Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.gff3 -fo Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.fa\n",
    "bedtools getfasta -s -name -bed Pst_E104_v1_h_ctg.gene.RepaseTPSI_filtered.gff3 -fi Pst_E104_v1_h_ctg.fa -fo Pst_E104_v1_h_ctg.gene.RepaseTPSI_filtered.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the gene.fa files and put them in a dict that has the genome as a key\n",
    "gene_fa_files = [os.path.join(BASE_A_PATH, x) for x in os.listdir(BASE_A_PATH) if x.endswith('gene.fa')]\n",
    "gene_fa_files_dict = {}\n",
    "for x in gene_fa_files:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    gene_fa_files_dict[key] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All databases generated and ready to go!\n"
     ]
    }
   ],
   "source": [
    "#generate the blast databases if not already present\n",
    "os.chdir(BLAST_DB)\n",
    "blast_dir_content = os.listdir(BLAST_DB)\n",
    "for x in blast_dir_content:\n",
    "    if x.endswith('.fa') and ({os.path.isfile(x + e) for e in ['.psq', '.phr', '.pin'] } != {True}\\\n",
    "           and {os.path.isfile(x + e) for e in ['.nin', '.nhr', '.nsq'] } != {True} ):\n",
    "\n",
    "        make_DB_options = ['-in']\n",
    "        make_DB_options.append(x)\n",
    "        make_DB_options.append('-dbtype')\n",
    "        if 'protein' in x:\n",
    "            make_DB_options.append('prot')\n",
    "        else:\n",
    "            make_DB_options.append('nucl')\n",
    "        make_DB_command = 'makeblastdb %s' % ' '.join(make_DB_options)\n",
    "        make_DB_stderr = subprocess.check_output(make_DB_command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print('%s is done!' % make_DB_command)\n",
    "print(\"All databases generated and ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the blast db files and put them in a dict that has the genome as a key\n",
    "gene_blast_db = [os.path.join(BLAST_DB, x) for x in os.listdir(BLAST_DB) if x.endswith('gene.fa')]\n",
    "gene_blast_db_dict ={}\n",
    "for x in gene_blast_db:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    gene_blast_db_dict[key] = x\n",
    "genome_blast_db = [os.path.join(BLAST_DB, x) for x in os.listdir(BLAST_DB) if x.endswith('_ctg.fa')]\n",
    "genome_blast_db_dict ={}\n",
    "for x in genome_blast_db:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    genome_blast_db_dict[key] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One pair of filtered non-allele files given. Good to go!\n"
     ]
    }
   ],
   "source": [
    "#using the dictionary approach to stich together all the different input files. The key is always the genome. In this cases\n",
    "#being the part of the file name before the first '.'\n",
    "if len(filtered_no_alleles) != 2:\n",
    "    print(\"This script right now is only designed for one set of filter files.\")\n",
    "    print(\"Please hold!\")\n",
    "else:\n",
    "    print(\"One pair of filtered non-allele files given. Good to go!\")\n",
    "    \n",
    "#simply pulls in the gene sequences of missing alleles. Do this on the filtered set as the unfiltered set is a subset anyway\n",
    "no_filtered_allele_gene_dict = {}\n",
    "for no_alleles_key in filtered_no_alleles_dict.keys():\n",
    "    #read in all the alleles from file this assumes that only one filter setting was run in the allele folder\n",
    "    no_filtered_allele_list = pd.read_csv(os.path.join(ALLELE_PATH, filtered_no_alleles_dict[no_alleles_key]), header=None, sep='\\t')[0].tolist()\n",
    "    #convert from proteins ids to gene ideas\n",
    "    no_filtered_allele_list =  [x.replace('evm.model', 'evm.TU') for x in no_filtered_allele_list]\n",
    "    \n",
    "    no_filtered_allele_seq = []\n",
    "    for seq in SeqIO.parse(open(gene_blast_db_dict[no_alleles_key]), 'fasta'):\n",
    "        if seq.id in no_filtered_allele_list:\n",
    "            no_filtered_allele_seq.append(seq)\n",
    "    #get the proper file name\n",
    "    out_f_prefix = filtered_no_alleles_dict[no_alleles_key].split('/')[-1]\n",
    "    out_f = out_f_prefix + '.gene.fa'\n",
    "    f_handle = open(os.path.join(OUT_PATH, out_f),'w') #need to generate handle for writing and\n",
    "    SeqIO.write(no_filtered_allele_seq, f_handle, 'fasta')\n",
    "    f_handle.close() #closing file afterwards again\n",
    "    no_filtered_allele_gene_dict[no_alleles_key] = os.path.join(OUT_PATH, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastn -query /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_QC/Pst_104E_v12_p_ctg.no.Qcov80.PctID70.alleles.gene.fa -db /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/blast_DB/Pst_104E_v12_h_ctg.fa -outfmt 6 -evalue 0.001 -num_threads 4 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_QC/tmp/Pst_104E_v12_p_ctg.no.Qcov80.PctID70.alleles.gene.fa.db_Pst_104E_v12_h_ctg.fa.0.001.blastn.outfmt6\n",
      "Previously done already!\n",
      "blastn -query /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_QC/Pst_104E_v12_h_ctg.no.no_p_hits.Qcov80.PctID70.alleles.gene.fa -db /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/blast_DB/Pst_104E_v12_p_ctg.fa -outfmt 6 -evalue 0.001 -num_threads 4 > /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/no_alleles_QC/tmp/Pst_104E_v12_h_ctg.no.no_p_hits.Qcov80.PctID70.alleles.gene.fa.db_Pst_104E_v12_p_ctg.fa.0.001.blastn.outfmt6\n",
      "Previously done already!\n"
     ]
    }
   ],
   "source": [
    "#do the gene against other haplotype blast\n",
    "no_filtered_allele_gene_genome_blast_dict ={}\n",
    "for no_alleles_key in no_filtered_allele_gene_dict.keys():\n",
    "    blast_options = ['-query']\n",
    "    query = no_filtered_allele_gene_dict[no_alleles_key]\n",
    "    blast_options.append(query)\n",
    "    blast_options.append('-db')\n",
    "    if no_alleles_key == p_genome:\n",
    "        db = genome_blast_db_dict[h_genome]\n",
    "    elif no_alleles_key == h_genome:\n",
    "        db = genome_blast_db_dict[p_genome]\n",
    "    else:\n",
    "        print(\"There is something wrong with the file name prefixes and the genome (h and p) provided!\")\n",
    "    blast_options.append(db)\n",
    "    blast_options.append('-outfmt 6')\n",
    "    blast_options.append('-evalue')\n",
    "    blast_options.append(str(e_value))\n",
    "    blast_options.append('-num_threads')\n",
    "    blast_options.append(str(n_threads))\n",
    "    #blast_options.append('-max_target_seqs 1')\n",
    "    blast_options.append('>')\n",
    "    if 'gene' in query:\n",
    "        out_name_list = [ query.split('/')[-1], 'db_' + db.split('/')[-1], str(e_value), 'blastn.outfmt6']\n",
    "        out_name = os.path.join(OUT_PATH_tmp ,'.'.join(out_name_list))\n",
    "        blast_options.append(out_name)\n",
    "        blast_command = 'blastn %s' % ' '.join(blast_options)\n",
    "    no_filtered_allele_gene_genome_blast_dict[no_alleles_key] = out_name\n",
    "    print(blast_command)\n",
    "    if not os.path.exists(out_name):\n",
    "        blast_stderr_dict[blast_command] = subprocess.check_output(blast_command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print(\"New blast run and done!\")\n",
    "    else:\n",
    "        blast_stderr_dict[blast_command] = 'Previously done already!'\n",
    "        print('Previously done already!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now convert all the gene level against genome blast hits to bed files\n",
    "no_filtered_allele_gene_genome_blast_bed_dict = {}\n",
    "for key, value in no_filtered_allele_gene_genome_blast_dict.items():\n",
    "    no_filtered_allele_gene_genome_blast_bed_dict[key] = blast_outfmt6_to_bed(value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here track what happens with the no_alleles. Meaning how many of those have a gene vs. genome hit and how many don't \n",
    "\n",
    "#these dict will hold the list of SeqIO.records of blast hit regions for each no_allele hiting the other haplotig split into\n",
    "#the id of the contig will be h/pcontig_xxx_start_end of DNA sequence\n",
    "\n",
    "#hit on associated contig\n",
    "no_filtered_allele_gene_genome_hit_asso_contig_dict = {}\n",
    "\n",
    "#hit on unlinked contigs\n",
    "no_filtered_allele_gene_genome_hit_no_asso_contig_dict = {}\n",
    "\n",
    "no_filtered_allele_gene_no_genome_hit_dict ={}\n",
    "\n",
    "for key, no_filtered_alllele_fn in filtered_no_alleles_dict.items():\n",
    "\n",
    "    no_filtered_alleles = pd.read_csv(no_filtered_alllele_fn, sep='\\t', header=None)[0].unique()\n",
    "    genome_hits_header = ['Contig', 'start', 'end', 'blast_query', 'e-value', 'strand']\n",
    "    gene_genome_hits_df = pd.read_csv(no_filtered_allele_gene_genome_blast_bed_dict[key], sep='\\t', \\\n",
    "                                         names = genome_hits_header, header=None)\n",
    "    gene_genome_hits_df['Protein_ID'] = gene_genome_hits_df['blast_query'].str.replace('evm.TU', 'evm.model')\n",
    "    #get all alleles with no gene vs. genome hit and save them to file with ending 'no_allele_no_gene_genome_blast_hit.txt'\n",
    "    no_filtered_allele_gene_no_genome_hit = np.setdiff1d(no_filtered_alleles, gene_genome_hits_df.Protein_ID.unique(), assume_unique= True)\n",
    "    out_fn = os.path.join(OUT_PATH, key +'.no_allele_no_gene_genome_blast_hit.txt')\n",
    "    no_filtered_allele_gene_no_genome_hit_dict[key] = out_fn\n",
    "    np.savetxt(out_fn, no_filtered_allele_gene_no_genome_hit, fmt='%s')\n",
    "    #now filter out the best hit on an associated contig\n",
    "    gene_genome_hits_df['asso_contig'] = gene_genome_hits_df['blast_query'].combine(gene_genome_hits_df['Contig'], func=same_contig_blast)\n",
    "    tmp_same_contig_df = ''\n",
    "    tmp_same_contig_df = gene_genome_hits_df[gene_genome_hits_df['asso_contig'] == True]\n",
    "    #now filter out the best hit on an not-associated contig <- not for now as this might get a bit complicated with paraglogs and such\n",
    "    tmp_diff_contig_df = ''\n",
    "    tmp_diff_contig_df_grouped = gene_genome_hits_df[gene_genome_hits_df['asso_contig'] == False].groupby('blast_query')\n",
    "    tmp_diff_contig_best_hits = tmp_diff_contig_df_grouped.apply(lambda g: g[g['e-value'] == g['e-value'].min()])\n",
    "    #now get all query protein ids\n",
    "    tmp_protein_id = gene_genome_hits_df['Protein_ID'].unique()\n",
    "    genome_name = ''\n",
    "    if key == p_genome:\n",
    "        genome_name = os.path.join(BASE_A_PATH, h_genome+'.fa')\n",
    "    elif key == h_genome:\n",
    "        genome_name = os.path.join(BASE_A_PATH, p_genome+'.fa')\n",
    "    genome_fa = pysam.FastaFile(genome_name)\n",
    "    \n",
    "    for protein_id in tmp_protein_id:\n",
    "        \n",
    "        #now loop through the protein_ids of no_alleles hiting the associated contig aka same contig\n",
    "        #could do something like gene_genome_hits_df.pivot_table(columns=['Protein_ID', 'Contig'], aggfunc={'start' : 'min', 'end':'min'})\n",
    "        tmp_protein_id_df = gene_genome_hits_df[(gene_genome_hits_df['Protein_ID'] == protein_id) & (gene_genome_hits_df['asso_contig'] == True) ]\n",
    "        \n",
    "        if len(tmp_protein_id_df) < 1:\n",
    "            continue\n",
    "        tmp_hit_contig = tmp_protein_id_df[\"Contig\"].unique()\n",
    "        tmp_gene_genome_seq_list = [] #saves SeqIO records from blast hits and suroundings\n",
    "        #now loop through the associated contig hits incase we have multiple associated contigs hit\n",
    "        for hit in tmp_hit_contig:\n",
    "            tmp_df_2 = tmp_protein_id_df[tmp_protein_id_df['Contig'] == hit]\n",
    "            #get the smallest starting point on the specific contig\n",
    "            start = tmp_df_2['start'].min() - 30000\n",
    "            if start < 1:\n",
    "                start = 1\n",
    "            end = tmp_df_2['end'].max() + 30000\n",
    "            seq = genome_fa.fetch(hit, start, end)\n",
    "            seq_r = '' #initialize empty SeqIO record\n",
    "            seq_id = hit + '_' + str(start) + '_' + str(end)\n",
    "            seq_ob = Seq(seq)\n",
    "            seq_ob.alphabet = 'fasta'\n",
    "            seq_r = SeqRecord(seq_ob)\n",
    "            seq_r.id = seq_id\n",
    "            tmp_gene_genome_seq_list.append(seq_r)\n",
    "        no_filtered_allele_gene_genome_hit_asso_contig_dict[protein_id] = tmp_gene_genome_seq_list\n",
    "        \n",
    "        \n",
    "    #need to loop through the protein_ids twice as the len(tmp_protein_id_df <1) introduces a silent error for \n",
    "    #hits with only not associated contigs\n",
    "    for protein_id in tmp_protein_id:   \n",
    "        #now loop through the protein_ids of no_alleles hiting unassociated contig aka diff_contig\n",
    "        tmp_protein_id_df = tmp_diff_contig_best_hits[(tmp_diff_contig_best_hits['Protein_ID'] == protein_id)]\n",
    "        if len(tmp_protein_id_df) < 1:\n",
    "            continue\n",
    "        tmp_hit_contig = tmp_protein_id_df[\"Contig\"].unique()\n",
    "        tmp_gene_genome_seq_list = [] #saves SeqIO records from blast hits and suroundings\n",
    "        #now loop through the associated contig hits incase we have multiple associated contigs hit\n",
    "        #pull out the blast hit regions (for one contig start(min) and end(max) if mulitple hits on same contig.\n",
    "        #save SeqIO.Records for each protein_id in a list\n",
    "        for hit in tmp_hit_contig:\n",
    "            tmp_df_2 = tmp_protein_id_df[tmp_protein_id_df['Contig'] == hit]\n",
    "            #get the smallest starting point on the specific contig\n",
    "            start = tmp_df_2['start'].min() - 30000\n",
    "            if start < 1:\n",
    "                start = 1\n",
    "            end = tmp_df_2['end'].max() + 30000\n",
    "            seq = genome_fa.fetch(hit, start, end)\n",
    "            seq_r = '' #initialize empty SeqIO record\n",
    "            seq_id = hit + '_' + str(start) + '_' + str(end)\n",
    "            seq_ob = Seq(seq)\n",
    "            seq_ob.alphabet = 'fasta'\n",
    "            seq_r = SeqRecord(seq_ob)\n",
    "            seq_r.id = seq_id\n",
    "            tmp_gene_genome_seq_list.append(seq_r)\n",
    "        no_filtered_allele_gene_genome_hit_no_asso_contig_dict[protein_id] = tmp_gene_genome_seq_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now write an exonerate script that aligns the protein sequences to the DNA sequences\n",
    "EXONERATE_PATH_asso = os.path.join(EXONERATE_PATH, 'hit_associated_contigs')\n",
    "EXONERATE_PATH_no_asso = os.path.join(EXONERATE_PATH, 'hit_nonassociated_contigs')\n",
    "if not os.path.exists(EXONERATE_PATH_asso):\n",
    "    os.mkdir(EXONERATE_PATH_asso)\n",
    "if not os.path.exists(EXONERATE_PATH_no_asso):\n",
    "    os.mkdir(EXONERATE_PATH_no_asso)\n",
    "#open up the script\n",
    "exonerate_script = os.path.join(OUT_PATH_tmp, exonerate_script_name)\n",
    "out_exonerate = open(exonerate_script, 'w')\n",
    "out_exonerate.write('#!/bin/bash\\n')\n",
    "for contig_key, contig_seq_list in no_filtered_allele_gene_genome_hit_asso_contig_dict.items():\n",
    "    out_folder = os.path.join(EXONERATE_PATH_asso, contig_key)\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    out_protein_fn = os.path.join(out_folder, contig_key + '.fa')\n",
    "    out_handle = open(out_protein_fn, 'w')\n",
    "    #write down the protein sequence\n",
    "    SeqIO.write(fa_protein_seq_dict[contig_key], out_handle, 'fasta')\n",
    "    out_handle.close()\n",
    "    #write the exonerate script\n",
    "    out_exonerate.write('cd %s\\n'% out_folder)\n",
    "    #write out all the genomic regions\n",
    "    for seq in contig_seq_list:\n",
    "        out_seq_name = os.path.join(out_folder, seq.id +'.fa')\n",
    "        out_seq_handle = open(out_seq_name, 'w')\n",
    "        SeqIO.write(seq, out_seq_handle, 'fasta')\n",
    "        out_seq_handle.close()\n",
    "        #write exonerate script the command\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment False -S > %s.vulgar_exn\\n'\\\n",
    "                           %(out_protein_fn, out_seq_name, out_seq_name))\n",
    "\n",
    "    #out_exonerate.write('cd %s\\n'% out_folder) #not necessary\n",
    "    \n",
    "for contig_key, contig_seq_list in no_filtered_allele_gene_genome_hit_no_asso_contig_dict.items():\n",
    "    out_folder = os.path.join(EXONERATE_PATH_no_asso, contig_key)\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    out_protein_fn = os.path.join(out_folder, contig_key + '.fa')\n",
    "    out_handle = open(out_protein_fn, 'w')\n",
    "    #write down the protein sequence\n",
    "    SeqIO.write(fa_protein_seq_dict[contig_key], out_handle, 'fasta')\n",
    "    out_handle.close()\n",
    "    #write the exonerate script\n",
    "    out_exonerate.write('cd %s\\n'% out_folder)\n",
    "    #write out all the genomic regions\n",
    "    for seq in contig_seq_list:\n",
    "        out_seq_name = os.path.join(out_folder, seq.id +'.fa')\n",
    "        out_seq_handle = open(out_seq_name, 'w')\n",
    "        SeqIO.write(seq, out_seq_handle, 'fasta')\n",
    "        out_seq_handle.close()\n",
    "        #write exonerate script the command\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment False -S > %s.vulgar_exn\\n'\\\n",
    "                           %(out_protein_fn, out_seq_name, out_seq_name))\n",
    "\n",
    "    #out_exonerate.write('cd %s\\n'% out_folder)       \n",
    "\n",
    "out_exonerate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exonerate script run successfully\n"
     ]
    }
   ],
   "source": [
    "#now run the exonerate script\n",
    "exonerate_command = 'bash %s' % exonerate_script\n",
    "exonerate_stderr = subprocess.check_output(exonerate_command , shell=True, stderr=subprocess.STDOUT)\n",
    "print('Exonerate script run successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no loop through the exonerate vulgar result and generate a dictionray of the results\n",
    "#if hsps query range == (0, query_length) and not F in .vulgar_comp it is likely that the alignment is actually good\n",
    "#and and the gene model might have been dropped for another reason\n",
    "#a dict that has the protein ID as key and the results of exonerate as list as value for each contig [contig : True/False].\n",
    "exonerate_best_hit_dict = {}\n",
    "exonerate_no_filtered_allele_gene_genome_hit_asso_contig_dict = {}\n",
    "exonerate_no_filtered_allele_asso_contig_bool_dict = {}\n",
    "\n",
    "\n",
    "#generate a best hit dict dummy place holder for each contig key\n",
    "for contig_key in set(list(no_filtered_allele_gene_genome_hit_asso_contig_dict.keys())\\\n",
    "                      + list(no_filtered_allele_gene_genome_hit_no_asso_contig_dict.keys())):\n",
    "    exonerate_best_hit_dict[contig_key] = ['dummy : 0']\n",
    "\n",
    "\n",
    "\n",
    "#now loop through the exonerate folders\n",
    "for contig_key in no_filtered_allele_gene_genome_hit_asso_contig_dict.keys():\n",
    "    out_folder = os.path.join(EXONERATE_PATH_asso, contig_key)\n",
    "    query_length = fa_protein_length_dict[contig_key]\n",
    "    #the results list will store the result for each individual exonerate alignment as boolean value. \n",
    "    #True == alignment successful (alignment range == range length protein sequence, no F(rameshit) in vulgar string)\n",
    "    exonerate_result_list = []\n",
    "    counter = 0\n",
    "    overall_best_score = 0\n",
    "    overall_best_hit = ''\n",
    "    #get all vulgar alignment results\n",
    "    vulgar_exn_list = [os.path.join(out_folder, x) for x in os.listdir(out_folder) if x.endswith('vulgar_exn')]\n",
    "    opt_query_range = (0, query_length)\n",
    "    #loop through vulgar parser and see if hit is valid \n",
    "    for fname in vulgar_exn_list:\n",
    "        best_score = 0\n",
    "        best_hit = ''\n",
    "        result = SearchIO.parse(fname, 'exonerate-vulgar')\n",
    "        genome_region = fname.split('/')[-1].split('.')[0]\n",
    "        for hit in result:\n",
    "            #loop through all hsps hits\n",
    "            for hsps in hit.hsps:\n",
    "                hsps_range = hsps.query_range\n",
    "                vulgar_list = hsps.vulgar_comp.strip(' ').split(' ')\n",
    "                #print(hsps_range, vulgar_list)\n",
    "                #this is the contition for something being a potential protein alignment that\n",
    "                #True == alignment successful (alignment range == range length protein sequence, \\\n",
    "                #no F(rameshit) in vulgar string)\n",
    "                if hsps_range == opt_query_range and 'F' not in vulgar_list:\n",
    "                    counter += 1\n",
    "                    if hsps.score > best_score:\n",
    "                        best_hit = hsps.hit_id\n",
    "                        best_score = hsps.score\n",
    "                    if hsps.score > overall_best_score:\n",
    "                        overall_best_hit = hsps.hit_id\n",
    "                        overall_best_score = hsps.score\n",
    "                    #print(key)\n",
    "        if best_score > 0:\n",
    "            exonerate_result_list.append('%s : True' % genome_region)\n",
    "        else:\n",
    "            exonerate_result_list.append('%s : False' % genome_region)\n",
    "            \n",
    "    exonerate_no_filtered_allele_gene_genome_hit_asso_contig_dict[contig_key] = exonerate_result_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    if counter > 0:\n",
    "        exonerate_no_filtered_allele_asso_contig_bool_dict[contig_key] = True\n",
    "        \n",
    "        if contig_key in exonerate_best_hit_dict.keys():\n",
    "            if int(exonerate_best_hit_dict[contig_key][0].split(':')[1][1:]) < overall_best_score:\n",
    "                exonerate_best_hit_dict[contig_key] = ['%s : %s' % (overall_best_hit, overall_best_score)]\n",
    "    else:\n",
    "        exonerate_no_filtered_allele_asso_contig_bool_dict[contig_key] = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no loop through the exonerate vulgar result and generate a dictionray of the results\n",
    "#if hsps query range == (0, query_length) and not F in .vulgar_comp it is likely that the alignment is actually good\n",
    "#and and the gene model might have been dropped for another reason\n",
    "#a dict that has the protein ID as key and the results of exonerate as list as value for each contig [contig : True/False].\n",
    "exonerate_no_filtered_allele_gene_genome_hit_no_asso_contig_dict = {}\n",
    "exonerate_no_filtered_allele_no_asso_contig_bool_dict = {}\n",
    "#now loop through the exonerate folders\n",
    "\n",
    "\n",
    "for contig_key in no_filtered_allele_gene_genome_hit_no_asso_contig_dict.keys():\n",
    "    out_folder = os.path.join(EXONERATE_PATH_no_asso, contig_key)\n",
    "    query_length = fa_protein_length_dict[contig_key]\n",
    "    #the results list will store the result for each individual exonerate alignment as boolean value. \n",
    "    #True == alignment successful (alignment range == range length protein sequence, no F(rameshit) in vulgar string)\n",
    "    exonerate_result_list = []\n",
    "    counter = 0\n",
    "    overall_best_score = 0\n",
    "    overall_best_hit = ''\n",
    "    #get all vulgar alignment results\n",
    "    vulgar_exn_list = [os.path.join(out_folder, x) for x in os.listdir(out_folder) if x.endswith('vulgar_exn')]\n",
    "    opt_query_range = (0, query_length)\n",
    "    #loop through vulgar parser and see if hit is valid \n",
    "    for fname in vulgar_exn_list:\n",
    "        best_score = 0\n",
    "        best_hit = ''\n",
    "        result = SearchIO.parse(fname, 'exonerate-vulgar')\n",
    "        genome_region = fname.split('/')[-1].split('.')[0]\n",
    "        for hit in result:\n",
    "            #loop through all hsps hits\n",
    "            for hsps in hit.hsps:\n",
    "                hsps_range = hsps.query_range\n",
    "                vulgar_list = hsps.vulgar_comp.strip(' ').split(' ')\n",
    "                #print(hsps_range, vulgar_list)\n",
    "                #this is the contition for something being a potential protein alignment that\n",
    "                #True == alignment successful (alignment range == range length protein sequence, \\\n",
    "                #no F(rameshit) in vulgar string)\n",
    "                if hsps_range == opt_query_range and 'F' not in vulgar_list:\n",
    "                    counter += 1\n",
    "                    if hsps.score > best_score:\n",
    "                        best_hit = hsps.hit_id\n",
    "                        best_score = hsps.score\n",
    "                    if hsps.score > overall_best_score:\n",
    "                        overall_best_hit = hsps.hit_id\n",
    "                        overall_best_score = hsps.score\n",
    "                    #print(key)\n",
    "        if best_score > 0:\n",
    "            exonerate_result_list.append('%s : True' % genome_region)\n",
    "        else:\n",
    "            exonerate_result_list.append('%s : False' % genome_region)\n",
    "            \n",
    "    exonerate_no_filtered_allele_gene_genome_hit_no_asso_contig_dict[contig_key] = exonerate_result_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    if counter > 0:\n",
    "        exonerate_no_filtered_allele_no_asso_contig_bool_dict[contig_key] = True\n",
    "        \n",
    "        if contig_key in exonerate_best_hit_dict.keys():\n",
    "            if int(exonerate_best_hit_dict[contig_key][0].split(':')[1][1:]) < overall_best_score:\n",
    "                exonerate_best_hit_dict[contig_key] = ['%s : %s' % (overall_best_hit, overall_best_score)]\n",
    "    else:\n",
    "        exonerate_no_filtered_allele_no_asso_contig_bool_dict[contig_key] = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out the exonerate dictonaries, combine vulgar results and delete all the exonerate files if clean up == True\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg', '') + 'exonerate_no_filtered_allele_asso_contig_bool_dict.txt')\n",
    "json.dump(exonerate_no_filtered_allele_asso_contig_bool_dict,open(out_name, 'w'))\n",
    "\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg', '') + 'exonerate_no_filtered_allele_no_asso_contig_bool_dict.txt')\n",
    "json.dump(exonerate_no_filtered_allele_no_asso_contig_bool_dict,open(out_name, 'w'))\n",
    "\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg', '') + 'exonerate_no_filtered_allele_gene_genome_hit_asso_contig_dict.txt')\n",
    "json.dump(exonerate_no_filtered_allele_gene_genome_hit_asso_contig_dict,open(out_name, 'w'))\n",
    "\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg', '') + 'exonerate_no_filtered_allele_gene_genome_hit_no_asso_contig_dict.txt')\n",
    "json.dump(exonerate_no_filtered_allele_gene_genome_hit_no_asso_contig_dict,open(out_name, 'w'))\n",
    "\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg', '') + 'exonerate_best_hit_dict.txt')\n",
    "json.dump(exonerate_best_hit_dict,open(out_name, 'w'))\n",
    "\n",
    "\n",
    "vulgar_files = glob.glob(os.path.join(EXONERATE_PATH, '*/*/*.vulgar_exn' ))\n",
    "out_name = os.path.join(OUT_PATH, p_genome.replace('p_ctg','') +'exonerate_vulgar_exn_all.txt')\n",
    "with open(out_name, 'wb') as outfile:\n",
    "    for f in vulgar_files:\n",
    "        with open(f, 'rb') as infile:\n",
    "            outfile.write(infile.read())\n",
    "\n",
    "if clean_up == True:\n",
    "    shutil.rmtree(EXONERATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:30: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:31: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:34: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#now read in the initial blast dataframes, filter them down to all no_alleles_filtered\n",
    "blast_out_dict = {}\n",
    "blast_header = ['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery', 'StopQuery', 'StartTarget',\\\n",
    "              'StopTarget', 'e-value','BitScore']\n",
    "blastp_result_files = [os.path.join(BLAST_RESULT_PATH,x) for x in os.listdir(BLAST_RESULT_PATH) if x.endswith('outfmt6') and x.split('.')[-2] == 'blastp' ]\n",
    "blastp_results_dict = {}\n",
    "for x in blastp_result_files:\n",
    "    key = x.split('/')[-1].split('.')[0]\n",
    "    blastp_results_dict[key] = x\n",
    "\n",
    "for key, blastp_fn in blastp_results_dict.items():\n",
    "    tmp_df = pd.read_csv(blastp_fn, sep='\\t', header=None, names=blast_header)\n",
    "    tmp_no_allele_list = pd.read_csv(filtered_no_alleles_dict[key], sep ='\\t', header = None)[0].tolist()\n",
    "    tmp_df = tmp_df[tmp_df.Query.isin(tmp_no_allele_list)]\n",
    "    tmp_df[\"QLgth\"] = tmp_df[\"Query\"].apply(lambda x: fa_protein_length_dict[x])\n",
    "    tmp_df[\"QCov\"] = tmp_df['AlnLgth']/tmp_df['QLgth']*100\n",
    "    tmp_df.sort_values(by=['Query', 'e-value','BitScore', ],ascending=[True, True, False], inplace=True)\n",
    "    #now make sure to add proteins/genes without blast hit to the dataframes e.g. some of the no_alleles will have had no blast hit in the initial blast\n",
    "    tmp_all_queries_w_hit = tmp_df[\"Query\"].unique()\n",
    "    tmp_queries_no_hit = set(tmp_no_allele_list) - set(tmp_all_queries_w_hit)\n",
    "    no_hit_list = []\n",
    "    #loop over the quieres with no hit and make list of list out of them the first element being the query id\n",
    "    for x in tmp_queries_no_hit:\n",
    "        NA_list = ['False'] * len(tmp_df.columns)\n",
    "        NA_list[0] = x\n",
    "        no_hit_list.append(NA_list)\n",
    "    tmp_no_hit_df = pd.DataFrame(no_hit_list)\n",
    "    tmp_no_hit_df.columns = tmp_df.columns\n",
    "    tmp_no_hit_df['QLgth'] = tmp_no_hit_df.Query.apply(lambda x: fa_protein_length_dict[x])\n",
    "    tmp_df = tmp_df.append(tmp_no_hit_df)\n",
    "    tmp_df['q_contig'] = tmp_df['Query'].str.extract(r'([p|h][a-z]*_[^.]*).?')\n",
    "    tmp_df['t_contig'] = tmp_df['Target'].str.extract(r'([p|h][a-z]*_[^.]*).?')\n",
    "    #fix that if you don't extract anything return False and not 'nan'\n",
    "    tmp_df['t_contig'].fillna(False, inplace=True)\n",
    "    tmp_df['q_contig == t_contig'] = (tmp_df[\"Query\"].str.extract(r'[p|h][a-z]*_([0-9]*)') == tmp_df[\"Target\"].str.extract(r'[p|h][a-z]*_([0-9]*)'))\n",
    "    tmp_df.reset_index(inplace=True, drop=True)\n",
    "    blast_out_dict[key] = tmp_df.iloc[:,:]\n",
    "#no make one summary_df for everything.\n",
    "no_filtered_allele_summary_df = pd.concat(blast_out_dict.values())\n",
    "no_filtered_allele_summary_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get all primary contigs with and without haplotigs as pwh_set and pwoh_set\n",
    "p_ctgs = []\n",
    "h_ctgs = []\n",
    "for seq in SeqIO.parse(os.path.join(BASE_A_PATH, p_genome + '.fa'), 'fasta'):\n",
    "    p_ctgs.append(seq.id)\n",
    "for seq in SeqIO.parse(os.path.join(BASE_A_PATH, h_genome + '.fa'), 'fasta'):\n",
    "    h_ctgs.append(seq.id)\n",
    "pwh_set = {re.search(r'[a-z]*_[0-9]*', h_ctg).group().replace('h', 'p') for h_ctg in h_ctgs}\n",
    "pwoh_set = set(pwh_set) - pwh_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add column for being on primary contig\n",
    "no_filtered_allele_summary_df['primary_contig'] = no_filtered_allele_summary_df.q_contig.apply(on_primary_contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add column for being on primary contig with haplotig\n",
    "no_filtered_allele_summary_df['pwh_contig'] = no_filtered_allele_summary_df.q_contig.apply(pwh_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the list of gene no genome hits \n",
    "no_filtered_allele_gene_no_genome_hit_list = []\n",
    "for key, value in no_filtered_allele_gene_no_genome_hit_dict.items():\n",
    "    no_filtered_allele_gene_no_genome_hit_list += pd.read_csv(value, header=None, sep ='\\t')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add gene_on_genome hit column\n",
    "no_filtered_allele_summary_df['gene_on_genome_blast_hit'] = ~no_filtered_allele_summary_df[\"Query\"].isin(no_filtered_allele_gene_no_genome_hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5635"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_filtered_allele_summary_df.Query.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Target</th>\n",
       "      <th>PctID</th>\n",
       "      <th>AlnLgth</th>\n",
       "      <th>NumMis</th>\n",
       "      <th>NumGap</th>\n",
       "      <th>StartQuery</th>\n",
       "      <th>StopQuery</th>\n",
       "      <th>StartTarget</th>\n",
       "      <th>StopTarget</th>\n",
       "      <th>e-value</th>\n",
       "      <th>BitScore</th>\n",
       "      <th>QLgth</th>\n",
       "      <th>QCov</th>\n",
       "      <th>q_contig</th>\n",
       "      <th>t_contig</th>\n",
       "      <th>q_contig == t_contig</th>\n",
       "      <th>primary_contig</th>\n",
       "      <th>pwh_contig</th>\n",
       "      <th>gene_on_genome_blast_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95337</th>\n",
       "      <td>evm.model.hcontig_028_015.23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>117</td>\n",
       "      <td>False</td>\n",
       "      <td>hcontig_028_015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95338</th>\n",
       "      <td>evm.model.hcontig_049_002.53</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>hcontig_049_002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95339</th>\n",
       "      <td>evm.model.hcontig_014_027.16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>hcontig_014_027</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95340</th>\n",
       "      <td>evm.model.hcontig_041_005.15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>hcontig_041_005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95341</th>\n",
       "      <td>evm.model.hcontig_030_006.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>226</td>\n",
       "      <td>False</td>\n",
       "      <td>hcontig_030_006</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Query Target  PctID AlnLgth NumMis NumGap  \\\n",
       "95337  evm.model.hcontig_028_015.23  False  False   False  False  False   \n",
       "95338  evm.model.hcontig_049_002.53  False  False   False  False  False   \n",
       "95339  evm.model.hcontig_014_027.16  False  False   False  False  False   \n",
       "95340  evm.model.hcontig_041_005.15  False  False   False  False  False   \n",
       "95341   evm.model.hcontig_030_006.5  False  False   False  False  False   \n",
       "\n",
       "      StartQuery StopQuery StartTarget StopTarget e-value BitScore  QLgth  \\\n",
       "95337      False     False       False      False   False    False    117   \n",
       "95338      False     False       False      False   False    False     92   \n",
       "95339      False     False       False      False   False    False     84   \n",
       "95340      False     False       False      False   False    False     92   \n",
       "95341      False     False       False      False   False    False    226   \n",
       "\n",
       "        QCov         q_contig t_contig  q_contig == t_contig  primary_contig  \\\n",
       "95337  False  hcontig_028_015    False                 False           False   \n",
       "95338  False  hcontig_049_002    False                 False           False   \n",
       "95339  False  hcontig_014_027    False                 False           False   \n",
       "95340  False  hcontig_041_005    False                 False           False   \n",
       "95341  False  hcontig_030_006    False                 False           False   \n",
       "\n",
       "       pwh_contig  gene_on_genome_blast_hit  \n",
       "95337       False                      True  \n",
       "95338       False                      True  \n",
       "95339       False                      True  \n",
       "95340       False                     False  \n",
       "95341       False                      True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_filtered_allele_summary_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evm.model.hcontig_014_017.28': True,\n",
       " 'evm.model.pcontig_014.18': True,\n",
       " 'evm.model.pcontig_129.9': True,\n",
       " 'evm.model.pcontig_059.82': True,\n",
       " 'evm.model.pcontig_001.222': True,\n",
       " 'evm.model.pcontig_057.116': True,\n",
       " 'evm.model.hcontig_001_021.198': False,\n",
       " 'evm.model.pcontig_001.470': False,\n",
       " 'evm.model.pcontig_000.498': True,\n",
       " 'evm.model.hcontig_035_008.52': False,\n",
       " 'evm.model.pcontig_073.78': True,\n",
       " 'evm.model.pcontig_078.69': False,\n",
       " 'evm.model.pcontig_008.98': True,\n",
       " 'evm.model.hcontig_001_002.51': True,\n",
       " 'evm.model.pcontig_035.61': False,\n",
       " 'evm.model.pcontig_019.237': True,\n",
       " 'evm.model.hcontig_059_005.5': True,\n",
       " 'evm.model.pcontig_066.48': False,\n",
       " 'evm.model.pcontig_023.104': False,\n",
       " 'evm.model.hcontig_035_008.103': False,\n",
       " 'evm.model.hcontig_009_142.7': False,\n",
       " 'evm.model.pcontig_083.12': True,\n",
       " 'evm.model.pcontig_004.47': False,\n",
       " 'evm.model.pcontig_028.155': False,\n",
       " 'evm.model.pcontig_000.394': True,\n",
       " 'evm.model.pcontig_026.70': True,\n",
       " 'evm.model.pcontig_001.126': False,\n",
       " 'evm.model.pcontig_010.169': True,\n",
       " 'evm.model.hcontig_011_016.113': True,\n",
       " 'evm.model.pcontig_018.2': True,\n",
       " 'evm.model.hcontig_064_098.19': False,\n",
       " 'evm.model.hcontig_011_016.69': False,\n",
       " 'evm.model.pcontig_037.205': True,\n",
       " 'evm.model.pcontig_029.136': False,\n",
       " 'evm.model.pcontig_042.179': False,\n",
       " 'evm.model.pcontig_052.69': False,\n",
       " 'evm.model.pcontig_046.13': False,\n",
       " 'evm.model.hcontig_000_003.65': False,\n",
       " 'evm.model.hcontig_030_011.144': True,\n",
       " 'evm.model.hcontig_043_003.18': False,\n",
       " 'evm.model.pcontig_013.289': True,\n",
       " 'evm.model.pcontig_018.226': True,\n",
       " 'evm.model.pcontig_018.279': False,\n",
       " 'evm.model.pcontig_084.12': True,\n",
       " 'evm.model.pcontig_007.9': False,\n",
       " 'evm.model.hcontig_009_024.31': False,\n",
       " 'evm.model.pcontig_047.134': True,\n",
       " 'evm.model.hcontig_001_180.3': False,\n",
       " 'evm.model.pcontig_036.212': False,\n",
       " 'evm.model.pcontig_019.326': True,\n",
       " 'evm.model.pcontig_004.376': False,\n",
       " 'evm.model.pcontig_041.88': True,\n",
       " 'evm.model.pcontig_010.179': True,\n",
       " 'evm.model.pcontig_031.81': True,\n",
       " 'evm.model.pcontig_070.108': True,\n",
       " 'evm.model.hcontig_001_044.3': False,\n",
       " 'evm.model.pcontig_054.104': False,\n",
       " 'evm.model.hcontig_044_016.5': False,\n",
       " 'evm.model.pcontig_013.32': False,\n",
       " 'evm.model.pcontig_028.49': False,\n",
       " 'evm.model.pcontig_069.112': True,\n",
       " 'evm.model.hcontig_064_007.20': True,\n",
       " 'evm.model.pcontig_029.135': True,\n",
       " 'evm.model.hcontig_026_002.170': False,\n",
       " 'evm.model.pcontig_059.127': False,\n",
       " 'evm.model.pcontig_001.86': True,\n",
       " 'evm.model.pcontig_005.269': False,\n",
       " 'evm.model.hcontig_005_043.70': True,\n",
       " 'evm.model.pcontig_022.181': False,\n",
       " 'evm.model.pcontig_040.88': True,\n",
       " 'evm.model.hcontig_005_002.71': False,\n",
       " 'evm.model.pcontig_027.66': True,\n",
       " 'evm.model.pcontig_033.185': False,\n",
       " 'evm.model.hcontig_004_020.87': True,\n",
       " 'evm.model.hcontig_055_012.26': False,\n",
       " 'evm.model.pcontig_036.61': False,\n",
       " 'evm.model.hcontig_026_013.1': True,\n",
       " 'evm.model.pcontig_040.60': False,\n",
       " 'evm.model.pcontig_002.360': True,\n",
       " 'evm.model.hcontig_007_005.65': True,\n",
       " 'evm.model.pcontig_056.136': True,\n",
       " 'evm.model.hcontig_031_015.8': True,\n",
       " 'evm.model.hcontig_003_136.19': True,\n",
       " 'evm.model.pcontig_012.27': True,\n",
       " 'evm.model.hcontig_009_024.110': False,\n",
       " 'evm.model.hcontig_042_009.34': False,\n",
       " 'evm.model.hcontig_002_023.3': False,\n",
       " 'evm.model.pcontig_003.44': False,\n",
       " 'evm.model.pcontig_041.56': False,\n",
       " 'evm.model.pcontig_008.64': True,\n",
       " 'evm.model.pcontig_029.25': True,\n",
       " 'evm.model.pcontig_055.75': True,\n",
       " 'evm.model.pcontig_030.277': False,\n",
       " 'evm.model.pcontig_041.21': False,\n",
       " 'evm.model.pcontig_001.53': True,\n",
       " 'evm.model.pcontig_056.49': False,\n",
       " 'evm.model.hcontig_006_013.64': True,\n",
       " 'evm.model.hcontig_011_017.56': False,\n",
       " 'evm.model.pcontig_013.19': True,\n",
       " 'evm.model.pcontig_000.667': True,\n",
       " 'evm.model.pcontig_031.21': False,\n",
       " 'evm.model.hcontig_017_004.54': False,\n",
       " 'evm.model.pcontig_010.211': True,\n",
       " 'evm.model.hcontig_065_094.39': False,\n",
       " 'evm.model.pcontig_044.50': True,\n",
       " 'evm.model.pcontig_035.35': True,\n",
       " 'evm.model.hcontig_007_005.29': False,\n",
       " 'evm.model.pcontig_008.71': True,\n",
       " 'evm.model.pcontig_052.56': False,\n",
       " 'evm.model.hcontig_011_016.30': True,\n",
       " 'evm.model.pcontig_045.49': False,\n",
       " 'evm.model.pcontig_054.79': False,\n",
       " 'evm.model.pcontig_065.28': False,\n",
       " 'evm.model.pcontig_050.24': True,\n",
       " 'evm.model.pcontig_019.1': False,\n",
       " 'evm.model.hcontig_019_001.28': True,\n",
       " 'evm.model.hcontig_019_013.61': False,\n",
       " 'evm.model.hcontig_036_004.9': False,\n",
       " 'evm.model.pcontig_106.6': True,\n",
       " 'evm.model.hcontig_082_002.3': True,\n",
       " 'evm.model.pcontig_018.296': False,\n",
       " 'evm.model.pcontig_010.218': False,\n",
       " 'evm.model.pcontig_002.314': True,\n",
       " 'evm.model.hcontig_001_056.1': False,\n",
       " 'evm.model.hcontig_060_001.12': True,\n",
       " 'evm.model.hcontig_057_003.95': False,\n",
       " 'evm.model.pcontig_049.88': True,\n",
       " 'evm.model.pcontig_007.195': False,\n",
       " 'evm.model.pcontig_047.112': True,\n",
       " 'evm.model.pcontig_009.380': False,\n",
       " 'evm.model.pcontig_057.133': True,\n",
       " 'evm.model.pcontig_000.208': False,\n",
       " 'evm.model.pcontig_022.244': True,\n",
       " 'evm.model.pcontig_023.168': False,\n",
       " 'evm.model.pcontig_010.159': True,\n",
       " 'evm.model.hcontig_036_004.12': True,\n",
       " 'evm.model.pcontig_039.85': False,\n",
       " 'evm.model.hcontig_078_002.26': False,\n",
       " 'evm.model.pcontig_030.29': False,\n",
       " 'evm.model.pcontig_030.156': True,\n",
       " 'evm.model.pcontig_029.166': True,\n",
       " 'evm.model.pcontig_036.213': False,\n",
       " 'evm.model.pcontig_009.144': False,\n",
       " 'evm.model.pcontig_021.19': True,\n",
       " 'evm.model.pcontig_008.358': False,\n",
       " 'evm.model.pcontig_002.249': True,\n",
       " 'evm.model.hcontig_013_023.42': True,\n",
       " 'evm.model.pcontig_020.49': True,\n",
       " 'evm.model.pcontig_007.325': False,\n",
       " 'evm.model.pcontig_011.85': False,\n",
       " 'evm.model.pcontig_084.57': False,\n",
       " 'evm.model.pcontig_003.448': True,\n",
       " 'evm.model.pcontig_104.32': False,\n",
       " 'evm.model.pcontig_017.269': True,\n",
       " 'evm.model.hcontig_003_045.7': True,\n",
       " 'evm.model.hcontig_084_003.16': False,\n",
       " 'evm.model.pcontig_001.376': True,\n",
       " 'evm.model.pcontig_013.187': True,\n",
       " 'evm.model.pcontig_065.16': False,\n",
       " 'evm.model.pcontig_148.3': True,\n",
       " 'evm.model.hcontig_020_021.110': False,\n",
       " 'evm.model.pcontig_012.381': False,\n",
       " 'evm.model.hcontig_046_007.122': False,\n",
       " 'evm.model.pcontig_057.121': False,\n",
       " 'evm.model.pcontig_002.426': False,\n",
       " 'evm.model.hcontig_017_004.1': True,\n",
       " 'evm.model.hcontig_009_024.88': False,\n",
       " 'evm.model.pcontig_081.28': False,\n",
       " 'evm.model.pcontig_029.195': True,\n",
       " 'evm.model.hcontig_036_008.71': False,\n",
       " 'evm.model.hcontig_002_028.23': True,\n",
       " 'evm.model.pcontig_036.184': True,\n",
       " 'evm.model.pcontig_019.301': False,\n",
       " 'evm.model.hcontig_001_123.30': False,\n",
       " 'evm.model.hcontig_004_020.316': False,\n",
       " 'evm.model.pcontig_018.301': True,\n",
       " 'evm.model.hcontig_055_009.32': False,\n",
       " 'evm.model.pcontig_017.115': False,\n",
       " 'evm.model.hcontig_003_135.5': False,\n",
       " 'evm.model.pcontig_005.494': True,\n",
       " 'evm.model.hcontig_034_001.75': False,\n",
       " 'evm.model.pcontig_008.273': True,\n",
       " 'evm.model.pcontig_019.25': True,\n",
       " 'evm.model.hcontig_013_012.18': False,\n",
       " 'evm.model.pcontig_022.252': True,\n",
       " 'evm.model.pcontig_011.86': True,\n",
       " 'evm.model.pcontig_054.30': False,\n",
       " 'evm.model.pcontig_001.517': False,\n",
       " 'evm.model.pcontig_000.200': False,\n",
       " 'evm.model.pcontig_026.23': True,\n",
       " 'evm.model.pcontig_014.207': False,\n",
       " 'evm.model.pcontig_003.220': False,\n",
       " 'evm.model.hcontig_037_011.45': True,\n",
       " 'evm.model.hcontig_026_018.37': True,\n",
       " 'evm.model.pcontig_006.23': True,\n",
       " 'evm.model.pcontig_016.79': False,\n",
       " 'evm.model.pcontig_000.95': False,\n",
       " 'evm.model.hcontig_018_022.31': True,\n",
       " 'evm.model.pcontig_031.201': False,\n",
       " 'evm.model.pcontig_048.68': True,\n",
       " 'evm.model.pcontig_056.17': True,\n",
       " 'evm.model.pcontig_004.300': False,\n",
       " 'evm.model.pcontig_031.37': False,\n",
       " 'evm.model.pcontig_005.37': False,\n",
       " 'evm.model.pcontig_030.38': True,\n",
       " 'evm.model.pcontig_058.56': False,\n",
       " 'evm.model.pcontig_054.11': False,\n",
       " 'evm.model.pcontig_007.301': True,\n",
       " 'evm.model.pcontig_060.56': False,\n",
       " 'evm.model.pcontig_017.127': True,\n",
       " 'evm.model.pcontig_010.80': True,\n",
       " 'evm.model.pcontig_020.305': False,\n",
       " 'evm.model.pcontig_003.436': False,\n",
       " 'evm.model.pcontig_011.146': True,\n",
       " 'evm.model.hcontig_001_001.38': False,\n",
       " 'evm.model.pcontig_049.55': False,\n",
       " 'evm.model.pcontig_003.398': True,\n",
       " 'evm.model.hcontig_065_003.24': False,\n",
       " 'evm.model.pcontig_003.413': True,\n",
       " 'evm.model.hcontig_017_004.106': False,\n",
       " 'evm.model.hcontig_023_006.2': False,\n",
       " 'evm.model.hcontig_001_001.122': True,\n",
       " 'evm.model.hcontig_011_016.241': False,\n",
       " 'evm.model.pcontig_021.314': True,\n",
       " 'evm.model.pcontig_044.100': True,\n",
       " 'evm.model.pcontig_001.424': True,\n",
       " 'evm.model.pcontig_009.47': False,\n",
       " 'evm.model.hcontig_029_001.2': False,\n",
       " 'evm.model.pcontig_091.34': True,\n",
       " 'evm.model.pcontig_086.51': False,\n",
       " 'evm.model.hcontig_023_002.102': True,\n",
       " 'evm.model.pcontig_057.22': True,\n",
       " 'evm.model.pcontig_018.146': True,\n",
       " 'evm.model.pcontig_031.14': True,\n",
       " 'evm.model.pcontig_021.85': True,\n",
       " 'evm.model.pcontig_001.421': True,\n",
       " 'evm.model.pcontig_014.172': True,\n",
       " 'evm.model.pcontig_040.53': True,\n",
       " 'evm.model.hcontig_027_006.70': True,\n",
       " 'evm.model.pcontig_014.169': True,\n",
       " 'evm.model.pcontig_029.79': False,\n",
       " 'evm.model.pcontig_086.15': True,\n",
       " 'evm.model.pcontig_007.291': True,\n",
       " 'evm.model.hcontig_001_156.14': False,\n",
       " 'evm.model.hcontig_006_015.104': True,\n",
       " 'evm.model.pcontig_000.237': True,\n",
       " 'evm.model.pcontig_048.46': False,\n",
       " 'evm.model.hcontig_064_098.18': False,\n",
       " 'evm.model.pcontig_003.475': True,\n",
       " 'evm.model.hcontig_037_011.28': False,\n",
       " 'evm.model.pcontig_016.250': True,\n",
       " 'evm.model.pcontig_057.108': False,\n",
       " 'evm.model.pcontig_050.44': True,\n",
       " 'evm.model.hcontig_035_008.123': False,\n",
       " 'evm.model.pcontig_026.202': False,\n",
       " 'evm.model.hcontig_078_002.28': False,\n",
       " 'evm.model.pcontig_011.95': False,\n",
       " 'evm.model.hcontig_048_010.12': False,\n",
       " 'evm.model.pcontig_001.311': True,\n",
       " 'evm.model.hcontig_020_025.24': False,\n",
       " 'evm.model.pcontig_086.23': False,\n",
       " 'evm.model.pcontig_003.298': True,\n",
       " 'evm.model.hcontig_007_006.161': False,\n",
       " 'evm.model.hcontig_012_024.84': False,\n",
       " 'evm.model.hcontig_055_012.50': False,\n",
       " 'evm.model.pcontig_021.276': False,\n",
       " 'evm.model.hcontig_012_010.14': True,\n",
       " 'evm.model.hcontig_084_003.18': False,\n",
       " 'evm.model.hcontig_054_001.24': False,\n",
       " 'evm.model.hcontig_081_004.7': False,\n",
       " 'evm.model.pcontig_004.188': False,\n",
       " 'evm.model.hcontig_039_012.7': False,\n",
       " 'evm.model.hcontig_018_016.90': False,\n",
       " 'evm.model.pcontig_007.193': True,\n",
       " 'evm.model.hcontig_016_015.39': False,\n",
       " 'evm.model.hcontig_000_003.36': True,\n",
       " 'evm.model.pcontig_006.472': False,\n",
       " 'evm.model.hcontig_006_002.26': True,\n",
       " 'evm.model.pcontig_001.123': True,\n",
       " 'evm.model.pcontig_043.132': False,\n",
       " 'evm.model.pcontig_026.189': False,\n",
       " 'evm.model.hcontig_004_020.158': False,\n",
       " 'evm.model.hcontig_009_024.119': True,\n",
       " 'evm.model.pcontig_052.125': True,\n",
       " 'evm.model.hcontig_004_076.31': False,\n",
       " 'evm.model.pcontig_031.193': True,\n",
       " 'evm.model.hcontig_026_018.35': True,\n",
       " 'evm.model.pcontig_021.212': True,\n",
       " 'evm.model.hcontig_055_009.56': False,\n",
       " 'evm.model.pcontig_026.138': True,\n",
       " 'evm.model.pcontig_019.157': False,\n",
       " 'evm.model.pcontig_030.95': False,\n",
       " 'evm.model.pcontig_060.38': False,\n",
       " 'evm.model.pcontig_000.395': True,\n",
       " 'evm.model.pcontig_013.321': False,\n",
       " 'evm.model.pcontig_083.48': True,\n",
       " 'evm.model.pcontig_052.100': True,\n",
       " 'evm.model.hcontig_044_003.16': True,\n",
       " 'evm.model.hcontig_020_009.6': False,\n",
       " 'evm.model.pcontig_001.29': False,\n",
       " 'evm.model.pcontig_004.57': True,\n",
       " 'evm.model.pcontig_020.247': False,\n",
       " 'evm.model.pcontig_005.483': False,\n",
       " 'evm.model.pcontig_003.94': False,\n",
       " 'evm.model.pcontig_064.39': True,\n",
       " 'evm.model.pcontig_007.28': True,\n",
       " 'evm.model.pcontig_014.244': False,\n",
       " 'evm.model.pcontig_036.38': True,\n",
       " 'evm.model.pcontig_017.83': False,\n",
       " 'evm.model.pcontig_026.190': False,\n",
       " 'evm.model.pcontig_002.272': True,\n",
       " 'evm.model.pcontig_041.67': True,\n",
       " 'evm.model.pcontig_034.64': True,\n",
       " 'evm.model.pcontig_004.327': False,\n",
       " 'evm.model.pcontig_003.532': True,\n",
       " 'evm.model.hcontig_003_002.73': False,\n",
       " 'evm.model.hcontig_016_124.5': False,\n",
       " 'evm.model.pcontig_007.214': True,\n",
       " 'evm.model.pcontig_002.40': True,\n",
       " 'evm.model.hcontig_004_020.128': False,\n",
       " 'evm.model.pcontig_005.69': False,\n",
       " 'evm.model.pcontig_189.6': False,\n",
       " 'evm.model.pcontig_034.208': True,\n",
       " 'evm.model.pcontig_010.34': False,\n",
       " 'evm.model.hcontig_059_008.128': True,\n",
       " 'evm.model.pcontig_022.263': True,\n",
       " 'evm.model.pcontig_029.67': True,\n",
       " 'evm.model.pcontig_110.11': False,\n",
       " 'evm.model.pcontig_070.121': False,\n",
       " 'evm.model.pcontig_002.415': False,\n",
       " 'evm.model.pcontig_021.338': False,\n",
       " 'evm.model.pcontig_016.324': False,\n",
       " 'evm.model.pcontig_000.466': False,\n",
       " 'evm.model.pcontig_000.113': True,\n",
       " 'evm.model.pcontig_081.50': False,\n",
       " 'evm.model.pcontig_005.58': True,\n",
       " 'evm.model.pcontig_001.576': False,\n",
       " 'evm.model.pcontig_017.298': True,\n",
       " 'evm.model.pcontig_066.24': False,\n",
       " 'evm.model.pcontig_082.40': False,\n",
       " 'evm.model.hcontig_027_011.26': False,\n",
       " 'evm.model.pcontig_029.269': True,\n",
       " 'evm.model.pcontig_030.43': True,\n",
       " 'evm.model.hcontig_067_005.7': True,\n",
       " 'evm.model.pcontig_014.182': True,\n",
       " 'evm.model.hcontig_007_006.158': True,\n",
       " 'evm.model.pcontig_009.102': True,\n",
       " 'evm.model.hcontig_014_004.76': True,\n",
       " 'evm.model.hcontig_028_011.61': False,\n",
       " 'evm.model.pcontig_056.117': True,\n",
       " 'evm.model.hcontig_006_013.81': True,\n",
       " 'evm.model.hcontig_000_050.74': False,\n",
       " 'evm.model.pcontig_016.10': False,\n",
       " 'evm.model.hcontig_018_016.8': True,\n",
       " 'evm.model.pcontig_022.178': True,\n",
       " 'evm.model.pcontig_014.192': False,\n",
       " 'evm.model.pcontig_009.196': False,\n",
       " 'evm.model.pcontig_003.551': False,\n",
       " 'evm.model.hcontig_057_003.99': False,\n",
       " 'evm.model.hcontig_000_054.10': True,\n",
       " 'evm.model.hcontig_023_003.7': False,\n",
       " 'evm.model.pcontig_052.172': False,\n",
       " 'evm.model.hcontig_006_015.18': False,\n",
       " 'evm.model.pcontig_052.138': True,\n",
       " 'evm.model.hcontig_018_022.92': False,\n",
       " 'evm.model.pcontig_020.78': True,\n",
       " 'evm.model.pcontig_023.203': False,\n",
       " 'evm.model.pcontig_010.312': False,\n",
       " 'evm.model.pcontig_040.135': True,\n",
       " 'evm.model.hcontig_064_098.21': False,\n",
       " 'evm.model.pcontig_026.174': True,\n",
       " 'evm.model.pcontig_010.174': False,\n",
       " 'evm.model.hcontig_033_007.1': False,\n",
       " 'evm.model.hcontig_047_006.19': True,\n",
       " 'evm.model.pcontig_026.166': False,\n",
       " 'evm.model.hcontig_017_160.8': False,\n",
       " 'evm.model.hcontig_001_001.115': True,\n",
       " 'evm.model.hcontig_029_013.84': False,\n",
       " 'evm.model.pcontig_000.636': True,\n",
       " 'evm.model.pcontig_042.163': False,\n",
       " 'evm.model.pcontig_003.165': True,\n",
       " 'evm.model.pcontig_011.382': False,\n",
       " 'evm.model.pcontig_005.327': False,\n",
       " 'evm.model.pcontig_033.186': False,\n",
       " 'evm.model.hcontig_055_003.3': False,\n",
       " 'evm.model.hcontig_044_023.76': True,\n",
       " 'evm.model.hcontig_001_123.32': False,\n",
       " 'evm.model.pcontig_012.3': False,\n",
       " 'evm.model.pcontig_060.62': True,\n",
       " 'evm.model.pcontig_010.310': False,\n",
       " 'evm.model.hcontig_002_011.78': False,\n",
       " 'evm.model.hcontig_009_024.113': False,\n",
       " 'evm.model.hcontig_081_005.12': False,\n",
       " 'evm.model.pcontig_005.380': True,\n",
       " 'evm.model.hcontig_005_043.232': False,\n",
       " 'evm.model.hcontig_003_002.185': True,\n",
       " 'evm.model.hcontig_022_008.1': True,\n",
       " 'evm.model.pcontig_000.304': True,\n",
       " 'evm.model.pcontig_021.172': True,\n",
       " 'evm.model.pcontig_030.20': False,\n",
       " 'evm.model.hcontig_034_158.2': True,\n",
       " 'evm.model.pcontig_033.65': True,\n",
       " 'evm.model.hcontig_001_001.71': True,\n",
       " 'evm.model.pcontig_004.290': True,\n",
       " 'evm.model.pcontig_018.185': True,\n",
       " 'evm.model.hcontig_000_050.64': True,\n",
       " 'evm.model.pcontig_036.164': False,\n",
       " 'evm.model.pcontig_009.313': False,\n",
       " 'evm.model.hcontig_000_003.438': False,\n",
       " 'evm.model.pcontig_042.80': True,\n",
       " 'evm.model.pcontig_084.38': True,\n",
       " 'evm.model.pcontig_010.295': True,\n",
       " 'evm.model.pcontig_010.167': True,\n",
       " 'evm.model.pcontig_002.476': False,\n",
       " 'evm.model.pcontig_129.10': True,\n",
       " 'evm.model.hcontig_072_009.25': False,\n",
       " 'evm.model.hcontig_033_071.75': True,\n",
       " 'evm.model.pcontig_008.286': False,\n",
       " 'evm.model.pcontig_023.89': True,\n",
       " 'evm.model.pcontig_014.105': True,\n",
       " 'evm.model.pcontig_000.147': True,\n",
       " 'evm.model.pcontig_004.218': True,\n",
       " 'evm.model.pcontig_004.207': False,\n",
       " 'evm.model.pcontig_009.182': True,\n",
       " 'evm.model.pcontig_028.215': False,\n",
       " 'evm.model.hcontig_059_008.130': False,\n",
       " 'evm.model.hcontig_054_038.18': False,\n",
       " 'evm.model.hcontig_050_003.14': True,\n",
       " 'evm.model.pcontig_148.15': True,\n",
       " 'evm.model.hcontig_042_141.4': False,\n",
       " 'evm.model.pcontig_023.78': False,\n",
       " 'evm.model.pcontig_007.69': True,\n",
       " 'evm.model.pcontig_006.508': False,\n",
       " 'evm.model.hcontig_029_010.11': False,\n",
       " 'evm.model.hcontig_022_007.31': True,\n",
       " 'evm.model.pcontig_016.131': True,\n",
       " 'evm.model.pcontig_005.491': False,\n",
       " 'evm.model.pcontig_009.54': False,\n",
       " 'evm.model.pcontig_022.224': True,\n",
       " 'evm.model.hcontig_007_005.24': True,\n",
       " 'evm.model.pcontig_049.118': False,\n",
       " 'evm.model.pcontig_070.68': True,\n",
       " 'evm.model.hcontig_013_023.101': False,\n",
       " 'evm.model.pcontig_066.66': False,\n",
       " 'evm.model.pcontig_002.514': False,\n",
       " 'evm.model.pcontig_064.29': False,\n",
       " 'evm.model.pcontig_021.311': False,\n",
       " 'evm.model.pcontig_033.179': False,\n",
       " 'evm.model.hcontig_014_004.68': False,\n",
       " 'evm.model.pcontig_008.136': False,\n",
       " 'evm.model.pcontig_104.43': True,\n",
       " 'evm.model.pcontig_033.192': False,\n",
       " 'evm.model.hcontig_017_004.56': False,\n",
       " 'evm.model.pcontig_020.159': True,\n",
       " 'evm.model.pcontig_045.122': False,\n",
       " 'evm.model.pcontig_013.379': False,\n",
       " 'evm.model.hcontig_026_018.31': False,\n",
       " 'evm.model.pcontig_040.67': True,\n",
       " 'evm.model.pcontig_030.188': True,\n",
       " 'evm.model.pcontig_045.72': True,\n",
       " 'evm.model.pcontig_007.202': False,\n",
       " 'evm.model.hcontig_007_006.34': True,\n",
       " 'evm.model.pcontig_092.33': True,\n",
       " 'evm.model.hcontig_036_008.143': False,\n",
       " 'evm.model.pcontig_021.221': True,\n",
       " 'evm.model.pcontig_086.58': False,\n",
       " 'evm.model.hcontig_039_004.43': True,\n",
       " 'evm.model.pcontig_059.114': True,\n",
       " 'evm.model.hcontig_021_027.87': False,\n",
       " 'evm.model.pcontig_029.147': False,\n",
       " 'evm.model.hcontig_001_033.7': False,\n",
       " 'evm.model.pcontig_104.41': False,\n",
       " 'evm.model.hcontig_020_025.38': False,\n",
       " 'evm.model.pcontig_000.295': True,\n",
       " 'evm.model.pcontig_009.356': True,\n",
       " 'evm.model.pcontig_004.170': False,\n",
       " 'evm.model.pcontig_004.29': False,\n",
       " 'evm.model.pcontig_058.28': True,\n",
       " 'evm.model.hcontig_017_160.18': False,\n",
       " 'evm.model.hcontig_009_024.170': True,\n",
       " 'evm.model.pcontig_016.116': False,\n",
       " 'evm.model.pcontig_065.61': True,\n",
       " 'evm.model.hcontig_010_016.137': True,\n",
       " 'evm.model.hcontig_030_011.92': True,\n",
       " 'evm.model.hcontig_000_003.240': False,\n",
       " 'evm.model.pcontig_064.45': False,\n",
       " 'evm.model.pcontig_014.48': False,\n",
       " 'evm.model.hcontig_047_006.13': True,\n",
       " 'evm.model.pcontig_000.618': True,\n",
       " 'evm.model.pcontig_022.109': False,\n",
       " 'evm.model.hcontig_005_002.96': True,\n",
       " 'evm.model.pcontig_047.83': False,\n",
       " 'evm.model.hcontig_055_012.47': False,\n",
       " 'evm.model.pcontig_009.75': True,\n",
       " 'evm.model.hcontig_049_009.6': True,\n",
       " 'evm.model.hcontig_039_004.20': True,\n",
       " 'evm.model.pcontig_027.265': False,\n",
       " 'evm.model.hcontig_012_005.1': False,\n",
       " 'evm.model.hcontig_074_001.1': True,\n",
       " 'evm.model.pcontig_039.2': False,\n",
       " 'evm.model.pcontig_004.44': False,\n",
       " 'evm.model.pcontig_006.331': True,\n",
       " 'evm.model.hcontig_040_015.83': False,\n",
       " 'evm.model.hcontig_007_006.184': False,\n",
       " 'evm.model.pcontig_034.87': False,\n",
       " 'evm.model.pcontig_006.68': True,\n",
       " 'evm.model.hcontig_049_206.5': False,\n",
       " 'evm.model.pcontig_086.56': False,\n",
       " 'evm.model.pcontig_086.20': True,\n",
       " 'evm.model.pcontig_072.8': True,\n",
       " 'evm.model.hcontig_057_003.47': False,\n",
       " 'evm.model.pcontig_084.30': False,\n",
       " 'evm.model.pcontig_008.271': True,\n",
       " 'evm.model.pcontig_033.212': True,\n",
       " 'evm.model.hcontig_010_016.93': True,\n",
       " 'evm.model.pcontig_052.19': False,\n",
       " 'evm.model.hcontig_055_009.27': True,\n",
       " 'evm.model.pcontig_055.80': True,\n",
       " 'evm.model.pcontig_069.126': False,\n",
       " 'evm.model.pcontig_050.103': False,\n",
       " 'evm.model.pcontig_004.403': False,\n",
       " 'evm.model.pcontig_070.52': False,\n",
       " 'evm.model.pcontig_004.15': True,\n",
       " 'evm.model.pcontig_019.172': True,\n",
       " 'evm.model.hcontig_046_010.1': False,\n",
       " 'evm.model.pcontig_021.225': True,\n",
       " 'evm.model.hcontig_030_011.221': False,\n",
       " 'evm.model.pcontig_034.47': True,\n",
       " 'evm.model.pcontig_033.58': False,\n",
       " 'evm.model.hcontig_007_005.2': True,\n",
       " 'evm.model.pcontig_008.75': True,\n",
       " 'evm.model.hcontig_017_013.7': True,\n",
       " 'evm.model.pcontig_022.239': True,\n",
       " 'evm.model.pcontig_025.192': False,\n",
       " 'evm.model.hcontig_005_013.4': False,\n",
       " 'evm.model.hcontig_069_108.8': True,\n",
       " 'evm.model.pcontig_018.128': True,\n",
       " 'evm.model.pcontig_017.192': True,\n",
       " 'evm.model.pcontig_018.73': False,\n",
       " 'evm.model.pcontig_057.5': False,\n",
       " 'evm.model.hcontig_029_013.45': False,\n",
       " 'evm.model.pcontig_019.111': True,\n",
       " 'evm.model.pcontig_001.340': False,\n",
       " 'evm.model.pcontig_055.21': True,\n",
       " 'evm.model.pcontig_046.11': True,\n",
       " 'evm.model.pcontig_035.151': False,\n",
       " 'evm.model.pcontig_027.233': True,\n",
       " 'evm.model.hcontig_036_008.3': False,\n",
       " 'evm.model.pcontig_020.245': False,\n",
       " 'evm.model.pcontig_009.348': False,\n",
       " 'evm.model.pcontig_013.46': True,\n",
       " 'evm.model.hcontig_028_011.101': True,\n",
       " 'evm.model.hcontig_002_011.214': False,\n",
       " 'evm.model.pcontig_017.200': False,\n",
       " 'evm.model.hcontig_035_008.45': False,\n",
       " 'evm.model.pcontig_005.318': True,\n",
       " 'evm.model.hcontig_055_012.90': True,\n",
       " 'evm.model.pcontig_010.85': False,\n",
       " 'evm.model.pcontig_040.147': True,\n",
       " 'evm.model.hcontig_041_005.50': True,\n",
       " 'evm.model.pcontig_019.91': True,\n",
       " 'evm.model.hcontig_034_001.24': True,\n",
       " 'evm.model.hcontig_040_005.5': False,\n",
       " 'evm.model.pcontig_001.509': True,\n",
       " 'evm.model.hcontig_050_003.46': False,\n",
       " 'evm.model.pcontig_000.294': True,\n",
       " 'evm.model.hcontig_004_020.154': False,\n",
       " 'evm.model.pcontig_019.71': False,\n",
       " 'evm.model.pcontig_059.125': True,\n",
       " 'evm.model.pcontig_066.53': True,\n",
       " 'evm.model.hcontig_004_076.37': True,\n",
       " 'evm.model.hcontig_043_012.7': False,\n",
       " 'evm.model.pcontig_008.253': True,\n",
       " 'evm.model.pcontig_001.124': False,\n",
       " 'evm.model.pcontig_039.144': False,\n",
       " 'evm.model.pcontig_062.21': True,\n",
       " 'evm.model.pcontig_027.254': False,\n",
       " 'evm.model.hcontig_045_002.30': True,\n",
       " 'evm.model.pcontig_056.65': False,\n",
       " 'evm.model.hcontig_029_013.13': False,\n",
       " 'evm.model.pcontig_054.16': False,\n",
       " 'evm.model.hcontig_054_001.1': True,\n",
       " 'evm.model.hcontig_004_076.4': True,\n",
       " 'evm.model.pcontig_012.277': False,\n",
       " 'evm.model.pcontig_002.358': True,\n",
       " 'evm.model.pcontig_006.148': True,\n",
       " 'evm.model.hcontig_017_011.6': True,\n",
       " 'evm.model.hcontig_043_007.6': True,\n",
       " 'evm.model.hcontig_028_011.105': True,\n",
       " 'evm.model.hcontig_019_008.6': False,\n",
       " 'evm.model.pcontig_003.505': False,\n",
       " 'evm.model.pcontig_004.307': False,\n",
       " 'evm.model.pcontig_092.42': False,\n",
       " 'evm.model.hcontig_005_043.99': False,\n",
       " 'evm.model.pcontig_054.10': False,\n",
       " 'evm.model.pcontig_009.323': False,\n",
       " 'evm.model.pcontig_043.172': True,\n",
       " 'evm.model.pcontig_050.134': True,\n",
       " 'evm.model.hcontig_020_025.22': True,\n",
       " 'evm.model.hcontig_050_003.39': True,\n",
       " 'evm.model.pcontig_087.28': True,\n",
       " 'evm.model.pcontig_000.33': False,\n",
       " 'evm.model.pcontig_002.528': True,\n",
       " 'evm.model.hcontig_041_004.7': False,\n",
       " 'evm.model.pcontig_001.439': True,\n",
       " 'evm.model.pcontig_030.165': True,\n",
       " 'evm.model.hcontig_034_022.11': False,\n",
       " 'evm.model.hcontig_004_076.51': False,\n",
       " 'evm.model.pcontig_002.339': True,\n",
       " 'evm.model.pcontig_030.170': False,\n",
       " 'evm.model.pcontig_017.5': False,\n",
       " 'evm.model.hcontig_003_002.131': True,\n",
       " 'evm.model.pcontig_000.536': True,\n",
       " 'evm.model.pcontig_059.42': False,\n",
       " 'evm.model.pcontig_002.298': False,\n",
       " 'evm.model.pcontig_080.25': False,\n",
       " 'evm.model.hcontig_013_018.5': False,\n",
       " 'evm.model.hcontig_003_002.188': True,\n",
       " 'evm.model.pcontig_037.138': True,\n",
       " 'evm.model.hcontig_005_029.6': False,\n",
       " 'evm.model.pcontig_045.151': False,\n",
       " 'evm.model.pcontig_012.283': True,\n",
       " 'evm.model.hcontig_047_006.10': False,\n",
       " 'evm.model.pcontig_084.56': False,\n",
       " 'evm.model.pcontig_023.24': False,\n",
       " 'evm.model.hcontig_037_017.2': False,\n",
       " 'evm.model.pcontig_007.219': False,\n",
       " 'evm.model.pcontig_018.201': False,\n",
       " 'evm.model.hcontig_004_076.34': True,\n",
       " 'evm.model.pcontig_002.176': False,\n",
       " 'evm.model.pcontig_002.159': True,\n",
       " 'evm.model.pcontig_006.184': False,\n",
       " 'evm.model.pcontig_021.263': False,\n",
       " 'evm.model.pcontig_048.49': True,\n",
       " 'evm.model.hcontig_044_023.118': True,\n",
       " 'evm.model.pcontig_042.4': False,\n",
       " 'evm.model.pcontig_022.28': False,\n",
       " 'evm.model.hcontig_000_003.32': True,\n",
       " 'evm.model.pcontig_006.221': False,\n",
       " 'evm.model.hcontig_027_006.111': True,\n",
       " 'evm.model.pcontig_012.103': True,\n",
       " 'evm.model.pcontig_018.246': False,\n",
       " 'evm.model.hcontig_026_018.59': False,\n",
       " 'evm.model.pcontig_200.7': True,\n",
       " 'evm.model.hcontig_020_023.5': False,\n",
       " 'evm.model.pcontig_028.74': True,\n",
       " 'evm.model.pcontig_001.95': True,\n",
       " 'evm.model.pcontig_006.134': False,\n",
       " 'evm.model.hcontig_014_022.2': False,\n",
       " 'evm.model.pcontig_027.110': True,\n",
       " 'evm.model.hcontig_028_011.49': False,\n",
       " 'evm.model.pcontig_026.207': False,\n",
       " 'evm.model.pcontig_077.49': False,\n",
       " 'evm.model.hcontig_046_007.121': False,\n",
       " 'evm.model.hcontig_029_023.5': False,\n",
       " 'evm.model.pcontig_004.261': True,\n",
       " 'evm.model.pcontig_018.83': True,\n",
       " 'evm.model.pcontig_013.159': True,\n",
       " 'evm.model.hcontig_002_028.27': True,\n",
       " 'evm.model.pcontig_044.147': True,\n",
       " 'evm.model.hcontig_067_008.16': True,\n",
       " 'evm.model.hcontig_017_026.2': False,\n",
       " 'evm.model.pcontig_014.250': True,\n",
       " 'evm.model.pcontig_021.105': True,\n",
       " 'evm.model.hcontig_054_001.5': True,\n",
       " 'evm.model.pcontig_027.206': True,\n",
       " 'evm.model.pcontig_020.229': False,\n",
       " 'evm.model.pcontig_037.62': True,\n",
       " 'evm.model.hcontig_005_043.73': True,\n",
       " 'evm.model.pcontig_016.165': False,\n",
       " 'evm.model.pcontig_046.116': True,\n",
       " 'evm.model.hcontig_017_004.51': False,\n",
       " 'evm.model.hcontig_045_002.10': False,\n",
       " 'evm.model.pcontig_016.91': True,\n",
       " 'evm.model.hcontig_002_028.127': False,\n",
       " 'evm.model.pcontig_018.121': True,\n",
       " 'evm.model.pcontig_044.101': False,\n",
       " 'evm.model.pcontig_040.93': False,\n",
       " 'evm.model.pcontig_007.176': False,\n",
       " 'evm.model.pcontig_009.352': False,\n",
       " 'evm.model.pcontig_050.83': False,\n",
       " 'evm.model.pcontig_019.7': False,\n",
       " 'evm.model.pcontig_029.149': True,\n",
       " 'evm.model.pcontig_003.218': True,\n",
       " 'evm.model.pcontig_067.56': False,\n",
       " 'evm.model.hcontig_004_020.232': True,\n",
       " 'evm.model.hcontig_018_016.133': True,\n",
       " 'evm.model.pcontig_043.5': False,\n",
       " 'evm.model.pcontig_047.56': False,\n",
       " 'evm.model.pcontig_000.386': True,\n",
       " 'evm.model.pcontig_017.77': False,\n",
       " 'evm.model.pcontig_002.51': True,\n",
       " 'evm.model.hcontig_040_002.4': False,\n",
       " 'evm.model.hcontig_019_001.41': False,\n",
       " 'evm.model.hcontig_019_001.22': True,\n",
       " 'evm.model.pcontig_030.128': False,\n",
       " 'evm.model.hcontig_013_023.39': True,\n",
       " 'evm.model.pcontig_012.296': True,\n",
       " 'evm.model.hcontig_042_168.18': False,\n",
       " 'evm.model.pcontig_048.83': False,\n",
       " 'evm.model.pcontig_054.13': False,\n",
       " 'evm.model.pcontig_064.49': False,\n",
       " 'evm.model.pcontig_003.225': False,\n",
       " 'evm.model.hcontig_004_020.15': False,\n",
       " 'evm.model.hcontig_004_020.145': False,\n",
       " 'evm.model.hcontig_050_053.8': False,\n",
       " 'evm.model.pcontig_025.171': False,\n",
       " 'evm.model.pcontig_029.171': True,\n",
       " 'evm.model.pcontig_009.8': True,\n",
       " 'evm.model.pcontig_018.222': False,\n",
       " 'evm.model.pcontig_225.9': True,\n",
       " 'evm.model.pcontig_017.166': False,\n",
       " 'evm.model.pcontig_019.202': True,\n",
       " 'evm.model.pcontig_018.347': True,\n",
       " 'evm.model.pcontig_006.425': False,\n",
       " 'evm.model.pcontig_022.194': False,\n",
       " 'evm.model.pcontig_027.49': False,\n",
       " 'evm.model.pcontig_005.13': True,\n",
       " 'evm.model.pcontig_037.101': True,\n",
       " 'evm.model.pcontig_000.96': True,\n",
       " 'evm.model.hcontig_073_004.16': True,\n",
       " 'evm.model.pcontig_037.57': True,\n",
       " 'evm.model.hcontig_106_001.11': False,\n",
       " 'evm.model.pcontig_044.186': False,\n",
       " 'evm.model.pcontig_018.249': False,\n",
       " 'evm.model.pcontig_052.99': True,\n",
       " 'evm.model.hcontig_001_021.214': False,\n",
       " 'evm.model.pcontig_031.46': False,\n",
       " 'evm.model.pcontig_045.125': True,\n",
       " 'evm.model.hcontig_004_020.43': True,\n",
       " 'evm.model.hcontig_070_004.12': True,\n",
       " 'evm.model.hcontig_011_017.37': True,\n",
       " 'evm.model.pcontig_028.160': True,\n",
       " 'evm.model.pcontig_001.252': False,\n",
       " 'evm.model.pcontig_021.284': False,\n",
       " 'evm.model.pcontig_040.33': False,\n",
       " 'evm.model.hcontig_009_024.174': True,\n",
       " 'evm.model.pcontig_031.172': False,\n",
       " 'evm.model.hcontig_016_015.51': False,\n",
       " 'evm.model.pcontig_008.63': False,\n",
       " 'evm.model.pcontig_036.208': False,\n",
       " 'evm.model.hcontig_016_014.15': False,\n",
       " 'evm.model.pcontig_046.5': False,\n",
       " 'evm.model.hcontig_042_111.21': False,\n",
       " 'evm.model.hcontig_072_099.14': False,\n",
       " 'evm.model.hcontig_007_031.3': False,\n",
       " 'evm.model.pcontig_020.286': False,\n",
       " 'evm.model.hcontig_088_002.3': False,\n",
       " 'evm.model.hcontig_022_015.2': True,\n",
       " 'evm.model.hcontig_022_008.29': True,\n",
       " 'evm.model.pcontig_011.83': True,\n",
       " 'evm.model.pcontig_000.121': True,\n",
       " 'evm.model.pcontig_055.120': False,\n",
       " 'evm.model.hcontig_019_015.14': True,\n",
       " 'evm.model.pcontig_064.33': False,\n",
       " 'evm.model.pcontig_013.189': True,\n",
       " 'evm.model.pcontig_042.160': False,\n",
       " 'evm.model.pcontig_044.80': True,\n",
       " 'evm.model.hcontig_009_024.168': False,\n",
       " 'evm.model.pcontig_009.110': True,\n",
       " 'evm.model.pcontig_019.216': True,\n",
       " 'evm.model.pcontig_008.109': True,\n",
       " 'evm.model.pcontig_000.530': False,\n",
       " 'evm.model.pcontig_000.225': False,\n",
       " 'evm.model.pcontig_020.80': False,\n",
       " 'evm.model.hcontig_050_053.5': True,\n",
       " 'evm.model.hcontig_012_014.14': False,\n",
       " 'evm.model.pcontig_080.14': False,\n",
       " 'evm.model.hcontig_008_035.43': True,\n",
       " 'evm.model.hcontig_027_006.116': True,\n",
       " 'evm.model.pcontig_003.513': True,\n",
       " 'evm.model.pcontig_007.126': True,\n",
       " 'evm.model.pcontig_104.42': False,\n",
       " 'evm.model.pcontig_000.425': False,\n",
       " 'evm.model.pcontig_019.24': False,\n",
       " 'evm.model.hcontig_007_006.7': True,\n",
       " 'evm.model.pcontig_005.337': False,\n",
       " 'evm.model.pcontig_005.259': False,\n",
       " 'evm.model.hcontig_058_004.20': False,\n",
       " 'evm.model.hcontig_006_013.201': False,\n",
       " 'evm.model.pcontig_000.276': True,\n",
       " 'evm.model.pcontig_004.393': False,\n",
       " 'evm.model.hcontig_006_013.73': True,\n",
       " 'evm.model.pcontig_068.31': True,\n",
       " 'evm.model.pcontig_001.127': False,\n",
       " 'evm.model.hcontig_000_003.200': True,\n",
       " 'evm.model.pcontig_018.207': False,\n",
       " 'evm.model.hcontig_035_008.125': False,\n",
       " 'evm.model.hcontig_043_003.64': True,\n",
       " 'evm.model.hcontig_001_001.58': True,\n",
       " 'evm.model.hcontig_002_029.1': False,\n",
       " 'evm.model.pcontig_012.384': False,\n",
       " 'evm.model.hcontig_003_002.137': False,\n",
       " 'evm.model.pcontig_063.3': True,\n",
       " 'evm.model.hcontig_026_018.21': True,\n",
       " 'evm.model.pcontig_013.14': False,\n",
       " 'evm.model.pcontig_014.179': False,\n",
       " 'evm.model.pcontig_044.117': True,\n",
       " 'evm.model.pcontig_006.292': True,\n",
       " 'evm.model.hcontig_049_002.34': True,\n",
       " 'evm.model.hcontig_003_041.64': False,\n",
       " 'evm.model.pcontig_008.45': False,\n",
       " 'evm.model.pcontig_073.63': False,\n",
       " 'evm.model.pcontig_080.29': True,\n",
       " 'evm.model.pcontig_069.39': False,\n",
       " 'evm.model.hcontig_034_001.161': False,\n",
       " 'evm.model.hcontig_003_002.65': False,\n",
       " 'evm.model.pcontig_070.98': True,\n",
       " 'evm.model.pcontig_025.207': False,\n",
       " 'evm.model.hcontig_043_012.3': True,\n",
       " 'evm.model.pcontig_026.14': True,\n",
       " 'evm.model.pcontig_049.57': False,\n",
       " 'evm.model.pcontig_055.100': False,\n",
       " 'evm.model.pcontig_029.264': False,\n",
       " 'evm.model.pcontig_013.39': True,\n",
       " 'evm.model.pcontig_036.60': False,\n",
       " 'evm.model.hcontig_002_028.71': True,\n",
       " 'evm.model.pcontig_066.11': False,\n",
       " 'evm.model.pcontig_012.96': True,\n",
       " 'evm.model.hcontig_002_028.115': False,\n",
       " 'evm.model.pcontig_041.142': False,\n",
       " 'evm.model.pcontig_052.53': True,\n",
       " 'evm.model.pcontig_039.52': True,\n",
       " 'evm.model.hcontig_006_015.14': True,\n",
       " 'evm.model.hcontig_017_004.60': False,\n",
       " 'evm.model.hcontig_009_012.1': True,\n",
       " 'evm.model.pcontig_006.41': True,\n",
       " 'evm.model.hcontig_034_001.136': True,\n",
       " 'evm.model.hcontig_041_005.11': True,\n",
       " 'evm.model.hcontig_014_004.115': False,\n",
       " 'evm.model.pcontig_045.23': True,\n",
       " 'evm.model.pcontig_028.167': False,\n",
       " 'evm.model.pcontig_004.177': False,\n",
       " 'evm.model.hcontig_054_001.93': False,\n",
       " 'evm.model.pcontig_010.330': True,\n",
       " 'evm.model.pcontig_005.160': False,\n",
       " 'evm.model.pcontig_009.12': True,\n",
       " 'evm.model.pcontig_012.53': False,\n",
       " 'evm.model.hcontig_049_009.12': False,\n",
       " 'evm.model.pcontig_006.390': True,\n",
       " 'evm.model.hcontig_009_024.94': True,\n",
       " 'evm.model.pcontig_018.220': True,\n",
       " 'evm.model.pcontig_029.129': True,\n",
       " 'evm.model.pcontig_028.197': True,\n",
       " 'evm.model.pcontig_021.177': False,\n",
       " 'evm.model.pcontig_020.319': False,\n",
       " 'evm.model.hcontig_008_016.16': False,\n",
       " 'evm.model.hcontig_017_011.9': False,\n",
       " 'evm.model.hcontig_065_003.23': False,\n",
       " 'evm.model.pcontig_042.52': False,\n",
       " 'evm.model.pcontig_016.95': False,\n",
       " 'evm.model.pcontig_004.276': True,\n",
       " 'evm.model.hcontig_010_016.179': True,\n",
       " 'evm.model.hcontig_007_006.129': True,\n",
       " 'evm.model.pcontig_023.32': True,\n",
       " 'evm.model.hcontig_033_071.45': False,\n",
       " 'evm.model.pcontig_017.75': False,\n",
       " 'evm.model.pcontig_003.32': False,\n",
       " 'evm.model.hcontig_011_017.67': False,\n",
       " 'evm.model.pcontig_021.275': False,\n",
       " 'evm.model.hcontig_054_001.107': False,\n",
       " 'evm.model.pcontig_042.193': False,\n",
       " 'evm.model.pcontig_064.103': False,\n",
       " 'evm.model.pcontig_006.81': False,\n",
       " 'evm.model.pcontig_044.161': True,\n",
       " 'evm.model.pcontig_003.166': False,\n",
       " 'evm.model.pcontig_004.313': True,\n",
       " 'evm.model.hcontig_040_015.15': False,\n",
       " 'evm.model.pcontig_000.41': False,\n",
       " 'evm.model.pcontig_011.157': False,\n",
       " 'evm.model.pcontig_028.16': True,\n",
       " 'evm.model.pcontig_022.110': False,\n",
       " 'evm.model.pcontig_078.19': False,\n",
       " 'evm.model.hcontig_004_076.59': False,\n",
       " 'evm.model.pcontig_059.30': True,\n",
       " 'evm.model.pcontig_069.125': True,\n",
       " 'evm.model.pcontig_029.124': False,\n",
       " 'evm.model.pcontig_020.364': False,\n",
       " 'evm.model.hcontig_019_020.49': True,\n",
       " 'evm.model.pcontig_011.44': False,\n",
       " 'evm.model.pcontig_003.140': True,\n",
       " 'evm.model.pcontig_002.197': True,\n",
       " 'evm.model.hcontig_047_003.41': True,\n",
       " 'evm.model.hcontig_022_008.48': True,\n",
       " 'evm.model.pcontig_009.246': False,\n",
       " 'evm.model.pcontig_005.203': False,\n",
       " 'evm.model.pcontig_001.154': False,\n",
       " 'evm.model.pcontig_047.130': False,\n",
       " 'evm.model.hcontig_052_006.115': True,\n",
       " 'evm.model.hcontig_006_040.4': True,\n",
       " 'evm.model.hcontig_008_016.13': False,\n",
       " 'evm.model.pcontig_027.2': True,\n",
       " 'evm.model.pcontig_059.65': False,\n",
       " 'evm.model.hcontig_031_005.98': False,\n",
       " 'evm.model.pcontig_030.201': True,\n",
       " 'evm.model.hcontig_057_002.6': False,\n",
       " 'evm.model.pcontig_037.67': True,\n",
       " 'evm.model.pcontig_037.6': False,\n",
       " 'evm.model.pcontig_050.66': True,\n",
       " 'evm.model.pcontig_030.157': False,\n",
       " 'evm.model.pcontig_002.304': False,\n",
       " 'evm.model.pcontig_019.204': False,\n",
       " 'evm.model.pcontig_004.106': False,\n",
       " 'evm.model.pcontig_001.149': True,\n",
       " 'evm.model.pcontig_031.32': False,\n",
       " 'evm.model.hcontig_005_043.10': False,\n",
       " 'evm.model.pcontig_005.334': False,\n",
       " 'evm.model.hcontig_012_024.23': True,\n",
       " 'evm.model.hcontig_025_002.6': False,\n",
       " 'evm.model.pcontig_008.284': False,\n",
       " 'evm.model.hcontig_026_018.54': False,\n",
       " 'evm.model.pcontig_009.383': False,\n",
       " 'evm.model.hcontig_064_098.36': False,\n",
       " 'evm.model.hcontig_017_011.7': False,\n",
       " 'evm.model.pcontig_033.72': False,\n",
       " 'evm.model.pcontig_019.127': True,\n",
       " 'evm.model.pcontig_049.153': False,\n",
       " 'evm.model.hcontig_020_008.1': False,\n",
       " 'evm.model.hcontig_017_004.47': False,\n",
       " 'evm.model.hcontig_047_006.42': True,\n",
       " 'evm.model.hcontig_043_119.20': False,\n",
       " 'evm.model.pcontig_016.106': True,\n",
       " 'evm.model.pcontig_036.18': False,\n",
       " 'evm.model.pcontig_019.88': True,\n",
       " 'evm.model.hcontig_052_006.25': True,\n",
       " 'evm.model.hcontig_008_014.71': False,\n",
       " 'evm.model.pcontig_082.18': False,\n",
       " 'evm.model.hcontig_001_021.168': False,\n",
       " 'evm.model.hcontig_034_005.4': False,\n",
       " 'evm.model.hcontig_022_008.27': True,\n",
       " 'evm.model.hcontig_062_001.60': False,\n",
       " 'evm.model.hcontig_035_015.1': False,\n",
       " 'evm.model.hcontig_039_005.57': False,\n",
       " 'evm.model.pcontig_002.228': False,\n",
       " 'evm.model.pcontig_005.57': True,\n",
       " 'evm.model.pcontig_002.143': True,\n",
       " 'evm.model.hcontig_046_007.79': False,\n",
       " 'evm.model.hcontig_002_011.185': False,\n",
       " 'evm.model.hcontig_001_002.70': True,\n",
       " 'evm.model.hcontig_002_011.89': True,\n",
       " 'evm.model.pcontig_005.343': False,\n",
       " 'evm.model.pcontig_048.99': False,\n",
       " 'evm.model.pcontig_000.186': False,\n",
       " 'evm.model.pcontig_000.355': True,\n",
       " 'evm.model.pcontig_005.406': True,\n",
       " 'evm.model.pcontig_007.143': False,\n",
       " 'evm.model.pcontig_043.31': True,\n",
       " 'evm.model.pcontig_003.368': False,\n",
       " 'evm.model.hcontig_023_003.10': False,\n",
       " 'evm.model.pcontig_070.82': False,\n",
       " 'evm.model.pcontig_007.396': True,\n",
       " 'evm.model.pcontig_089.24': False,\n",
       " 'evm.model.hcontig_016_124.21': False,\n",
       " 'evm.model.hcontig_008_009.132': True,\n",
       " 'evm.model.hcontig_018_022.7': True,\n",
       " 'evm.model.pcontig_023.62': True,\n",
       " 'evm.model.pcontig_003.297': True,\n",
       " 'evm.model.pcontig_009.241': True,\n",
       " 'evm.model.pcontig_003.119': True,\n",
       " 'evm.model.pcontig_080.57': False,\n",
       " 'evm.model.pcontig_031.90': False,\n",
       " 'evm.model.pcontig_054.43': True,\n",
       " 'evm.model.hcontig_039_005.25': False,\n",
       " 'evm.model.pcontig_002.435': False,\n",
       " 'evm.model.hcontig_028_015.65': True,\n",
       " 'evm.model.pcontig_060.64': True,\n",
       " 'evm.model.hcontig_017_160.15': False,\n",
       " 'evm.model.pcontig_001.146': False,\n",
       " 'evm.model.hcontig_001_021.55': False,\n",
       " 'evm.model.pcontig_033.26': False,\n",
       " 'evm.model.pcontig_027.244': True,\n",
       " 'evm.model.pcontig_030.121': False,\n",
       " 'evm.model.hcontig_037_011.54': True,\n",
       " 'evm.model.pcontig_070.93': False,\n",
       " 'evm.model.pcontig_030.1': False,\n",
       " 'evm.model.pcontig_000.128': False,\n",
       " 'evm.model.pcontig_018.61': True,\n",
       " 'evm.model.pcontig_073.100': True,\n",
       " 'evm.model.hcontig_020_021.173': False,\n",
       " 'evm.model.pcontig_073.14': True,\n",
       " 'evm.model.pcontig_000.518': True,\n",
       " 'evm.model.hcontig_018_022.123': True,\n",
       " 'evm.model.hcontig_057_003.94': True,\n",
       " 'evm.model.pcontig_006.365': False,\n",
       " 'evm.model.hcontig_011_016.148': True,\n",
       " 'evm.model.pcontig_129.18': False,\n",
       " 'evm.model.pcontig_005.496': False,\n",
       " 'evm.model.pcontig_009.212': True,\n",
       " 'evm.model.hcontig_042_011.2': False,\n",
       " 'evm.model.pcontig_016.298': True,\n",
       " 'evm.model.pcontig_022.125': False,\n",
       " 'evm.model.hcontig_029_013.83': True,\n",
       " 'evm.model.pcontig_030.203': True,\n",
       " 'evm.model.pcontig_054.19': False,\n",
       " 'evm.model.pcontig_129.19': False,\n",
       " 'evm.model.pcontig_004.217': True,\n",
       " 'evm.model.hcontig_064_005.1': True,\n",
       " 'evm.model.pcontig_022.261': True,\n",
       " 'evm.model.hcontig_018_016.150': False,\n",
       " 'evm.model.pcontig_052.71': True,\n",
       " ...}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exonerate_no_filtered_allele_asso_contig_bool_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the exonerate dict to it\n",
    "remove exonerate tmp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_allele_gene_genome_blast_bed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pwh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r'[a-z]*_[0-9]*', test).group().replace('p', 'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_allele_gene_genome_hit_no_asso_contig_dict['evm.model.hcontig_000_003.124']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exonerate_no_filtered_allele_gene_genome_hit_asso_contig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exonerate_no_filtered_allele_asso_contig_bool_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exonerate_best_hit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if contig_key in exonerate_best_hit_dict.keys():\n",
    "    if \n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(fname.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_allele_gene_genome_hit_no_asso_contig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = gene_genome_hits_df.pivot_table(columns=['Protein_ID', 'Contig'], aggfunc={'start' : 'min', 'end':'min'}).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_protein_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_protein_id_df.groupby('Contig')['end'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fa_protein_seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_same_contig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all primary proteins no hit need to be split up into pwh and pwoh\n",
    "p_contig_list = []\n",
    "h_contig_list = []\n",
    "for seq in SeqIO.parse(os.path.join(BASE_A_PATH, h_genome +'.fa'),'fasta'):\n",
    "    h_contig_list.append(seq.id)\n",
    "for seq in SeqIO.parse(os.path.join(BASE_A_PATH, p_genome +'.fa'), 'fasta'):\n",
    "    p_contig_list.append(seq.id)\n",
    "pwh_set = set([x[0:11].replace('h','p') for x in h_contig_list])\n",
    "pwoh_set = set(p_contig_list) - pwh_set\n",
    "print(\"P_contigs with h_contig are %i and without %i\" % (len(pwh_set), len(pwoh_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.intersectaaa1d(no_filtered_alleles, no_gene_genome_hits_df.Protein_ID.unique(), assume_unique= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.setdiff1d(no_filtered_alleles, no_gene_genome_hits_df.Protein_ID.unique(), assume_unique= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.setdiff1d( no_gene_genome_hits_df.Protein_ID.unique(),no_filtered_alleles, assume_unique= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_allele_gene_no_genome_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cut -f4 Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa.outfmt6.bed | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cut -f4 Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa.outfmt6.bed | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now read in the bed files as dataframe sort by e-value, pick the best e-value and the best hit on corresponding corresponding contig. Make two dictionaries with the same keys. One for the protein sequence and one for best blast hits. For the later make the value a list of file ids for the blast hits. Make a new folder for exonerate with subfolders for each no_filtered_blast hit. Save all the sequence files in this folders. Write a bash script that goes throught these folders and exectues exonerate for each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here track what happens with the no_besties hit. Do they not have protein blast hits? How many of the no protein \n",
    "#blast hits have not gene blast hit?\n",
    "#this needs to include some folder tracking of gene.no_besties.fa that hits nothing significant \n",
    "#no_bbb in - no_bbb out = no_hits at all\n",
    "no_gene_hits = {}\n",
    "no_besties_blast_nt_bed = [x for x in os.listdir() if x.endswith('no_besties.fa.outfmt6.bed')]\n",
    "no_besties_blast_nt_bed.sort()\n",
    "for no_bbb, protein_blast in zip(no_besties_blast_nt_bed,outfmt6):\n",
    "    no_bbb_no_protein_blast_df =''\n",
    "    no_bbb_df_header = ['Contig', 'start', 'end', 'blast_query', 'e-value', 'strand']\n",
    "    no_bbb_df = pd.read_csv(folder_p+no_bbb, header=None, names=no_bbb_df_header,  sep='\\t')\n",
    "    protein_blast_df = pd.read_csv(folder_p+protein_blast, header=None, sep='\\t')\n",
    "    no_bbb_df['protein_id'] = no_bbb_df['blast_query'].str.replace('evm.TU', 'evm.model')\n",
    "    #this below is most likely correct ignores the fact that some no_bbb genes might have hit nothing\n",
    "    #at all on the gene level\n",
    "    no_bbb_no_protein_blast_df = no_bbb_df[~no_bbb_df['protein_id'].isin(protein_blast_df[0])]\n",
    "    #these are the no_besties that didn't hit anything at the gene level\n",
    "    key =''\n",
    "    key = no_bbb.split('.')[0]\n",
    "    no_gene_hits[key] = set(no_bestie_dict[key]) - set(no_bbb_df['protein_id'].unique())\n",
    "    pd.DataFrame(list(no_gene_hits[key])).to_csv(key + '.gene.no_genome_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    blast_p_no_bestie =''\n",
    "    blast_p_no_bestie = len(no_bbb_df[no_bbb_df['protein_id'].isin(protein_blast_df[0])]['blast_query'].unique())\n",
    "    print('This %i out of %i no_besties of %s had a blast hit which was not RBH' % \\\n",
    "          (blast_p_no_bestie, len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print('This %i out of %i no_besties of %s have no blast hit gene vs. other haplome' % \\\n",
    "         (len(no_gene_hits[key]),len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print(\"No gene hits that have a protein hit\", len(set(no_gene_hits[key])- set(no_hits[key])), key)\n",
    "    groups = no_bbb_no_protein_blast_df.groupby(by='blast_query')\n",
    "    #now filter the dataframe by the smallest e-value for each group == blast_hit\n",
    "    df_filtered = groups.apply(lambda g: g[g['e-value'] == g['e-value'].min()])\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    df_filtered.iloc[:,0:6].to_csv(folder_p+no_bbb[:-4]+'.filteredbesthits.bed', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all primary proteins no hit need to be split up into pwh and pwoh\n",
    "p_contig_list = []\n",
    "h_contig_list = []\n",
    "for seq in SeqIO.parse('Pst_E104_v1_h_ctg.fa', 'fasta'):\n",
    "    h_contig_list.append(seq.id)\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    p_contig_list.append(seq.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwh_set = set([x[0:11].replace('h','p') for x in h_contig_list])\n",
    "pwoh_set = set(p_contig_list) - pwh_set\n",
    "print(\"P_contigs with h_contig are %i and without %i\" % (len(pwh_set), len(pwoh_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pwh_filter (x):\n",
    "    p_contig = x.split('.')[2]\n",
    "    if p_contig in pwh_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwh_set]\n",
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwoh_set]\n",
    "print(len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']), len (fa_protein_dict['Pst_E104_v1_p_ctg']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_txt = [x for x in os.listdir(folder_p) if x.split('.')[0] == 'Pst_E104_v1_p_ctg' and x.endswith('.txt')\\\n",
    "        and not 'pwh' in x and not 'pwoh' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter and summarize the p results based on pwh and pwoh \n",
    "p_txt = [x for x in os.listdir(folder_p) if x.split('.')[0] == 'Pst_E104_v1_p_ctg' and x.endswith('.txt')\\\n",
    "        and not 'pwh' in x and not 'pwoh' in x and not x.endswith('besties.txt')]\n",
    "for x in p_txt:\n",
    "    #print(x)\n",
    "    df_p = pd.read_csv(x, header=None, sep='\\t')\n",
    "    #df_p.head()\n",
    "    df_p['pwh'] = df_p[0].apply(pwh_filter)\n",
    "    df_p[df_p['pwh'] == 1].to_csv(x[:-4]+'pwh.txt', sep ='\\t', header=None, index=None)\n",
    "    df_p[df_p['pwh'] == 0].to_csv(x[:-4]+'pwoh.txt', sep ='\\t', header=None, index=None)\n",
    "    print ('For pwh:')\n",
    "    print('For this condition %s %i proteins out of %i (%.2f) are affected for pwh'% \\\n",
    "          (x, sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), \\\n",
    "           sum(df_p['pwh'])/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh'])*100 ))\n",
    "    print ('For pwoh:')e\n",
    "    print('For this condition %s %i proteins out of %i (%i) are affected for pwoh'% \\\n",
    "         (x, len(df_p['pwh']) - sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']),\\\n",
    "        (len(df_p['pwh']) - sum(df_p['pwh']))/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh'])*100 ))\n",
    "     \n",
    "\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p')\n",
    "len_pwh = 0\n",
    "len_pwoh = 0\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    if seq.id in pwh_set:\n",
    "        len_pwh = len_pwh + len(seq.seq)\n",
    "    if seq.id in pwoh_set:\n",
    "        len_pwoh = len_pwoh + len(seq.seq)\n",
    "print(\"Lenght of pwoh %i, lenght of pwo %i, total length p %i\" %(len_pwh,len_pwoh,len_pwh+len_pwoh ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_contig_blast(x,y):\n",
    "    '''Function that checks if the blast hit in columne y is on the same contig as the the query sequence in\n",
    "    column y.\n",
    "    '''\n",
    "    q_contig = x.split('.')[2].split('_')[1]\n",
    "    hit_contig = y.split('_')[1]\n",
    "    if q_contig == hit_contig:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "nfb_gene_blast_bed = [x for x in os.listdir(folder_p) if x.endswith('no_filtered_blast_hit.fa.outfmt6.bed')]\n",
    "nfb_gene_blast_bed.sort()\n",
    "protein_dict_nfb_bhits = {}\n",
    "protein_dict_nfb = {} #get a list of all proteins of nfb that don't have a hit when blasted at the gene level too\n",
    "#get the fasta genome files\n",
    "tmp_genome_files = ['Pst_E104_v1_p_ctg.fa', 'Pst_E104_v1_h_ctg.fa']\n",
    "protein_fa_files = [x for x in os.listdir(folder_p) if x.endswith('anno.RepaseTPSI_filtered.protein.fa')]\n",
    "for bed_file in nfb_gene_blast_bed:\n",
    "    print('This %s is the current bed file being processed' % (bed_file))\n",
    "    nfb_gene_blast_bed_df =''\n",
    "    nfb_gene_blast_bed_df = pd.read_csv(bed_file, header=None, sep='\\t' )\n",
    "    #now add another column to the dateframe that stats if the hit and query are on the same contig\n",
    "    nfb_gene_blast_bed_df['Same_contig'] = nfb_gene_blast_bed_df[3].combine(nfb_gene_blast_bed_df[0], func=same_contig_blast)\n",
    "    #initialize some temporary df for filtering\n",
    "    tmp_same_contig_df =''\n",
    "    tmp_best_hits_df =''\n",
    "    tmp_groups =''\n",
    "    tmp_best_hits_filtered =''\n",
    "    #get all blast hits that are on the same contig\n",
    "    tmp_same_contig_df = nfb_gene_blast_bed_df[nfb_gene_blast_bed_df['Same_contig'] == True]\n",
    "    #get the best remaining blast hit(s)\n",
    "    tmp_best_hits_df = nfb_gene_blast_bed_df[nfb_gene_blast_bed_df['Same_contig'] == False].sort_values(by=[3,4])\n",
    "    tmp_groups = tmp_best_hits_df.groupby(by=3)\n",
    "    #now filter the dataframe by the smallest e-value for each group == Query/3\n",
    "    tmp_best_hits_df_filtered = tmp_groups.apply(lambda g: g[g[4] == g[4].min()]) \n",
    "    tmp_best_hits_df_filtered = tmp_best_hits_df_filtered.reset_index(drop=True)\n",
    "    nfb_gene_blast_bed_df_filtered = ''\n",
    "    nfb_gene_blast_bed_df_filtered = pd.concat([tmp_best_hits_df_filtered, tmp_same_contig_df]).sort_values(by=[3,4]).reset_index(drop=True)\n",
    "    #now get the loop through the df. pull out the protein sequences and corresponding hits. save them to new folders.\n",
    "    #extend the script. \n",
    "    #get all the blasted sequences that had a hit == unique querries\n",
    "    tmp_queries = ''\n",
    "    tmp_queries = nfb_gene_blast_bed_df_filtered[3].unique()\n",
    "    #get all the protein sequences in a dictionary with protein ID being the key and the values being a SeqIO object\n",
    "    #get the fasta genome files\n",
    "    tmp_genome_file = [x for x in tmp_genome_files if not x.startswith(bed_file.split('.')[0])][0]\n",
    "    genome_fa = ''\n",
    "    genome_fa = pysam.FastaFile(tmp_genome_file)\n",
    "    tmp_queries_id = [x.replace('TU', 'model') for x in tmp_queries]\n",
    "    tmp_protein_fa_file = [x for x in protein_fa_files if x.startswith(bed_file.split('.')[0])][0]\n",
    "    for seq in SeqIO.parse(open(tmp_protein_fa_file), 'fasta'):\n",
    "            if seq.id in tmp_queries_id:\n",
    "                protein_dict_nfb[seq.id] = seq\n",
    "    #add this tmp_protein_dict_nfb to the full protein dict to keep track\n",
    "    #check why only one file gets processed.\n",
    "    \n",
    "    \n",
    "    #make a dict that gets the blast hit sequences in +30kb each side for alignments of protein sequences on top of them. \n",
    "    #The value of this dict will be a list of SeqIO objects\n",
    "    \n",
    "    tmp_list = [] #tmp_list to save the SeqIO objects for the blast hits in\n",
    "    print(len(tmp_queries))\n",
    "    for query in tmp_queries:\n",
    "        #print(query)\n",
    "        tmp_list = []\n",
    "        tmp_df = nfb_gene_blast_bed_df_filtered[nfb_gene_blast_bed_df_filtered[3] == query]\n",
    "        #do groupby instead here on columns one. Take min of column 1 and max of column 2 as start/stop +-\n",
    "        #this avoids to mess around with mutliple hits on the same contig\n",
    "        tmp_hit = tmp_df[0].unique()\n",
    "        for hit in tmp_hit:\n",
    "            tmp_df_2 = tmp_df[tmp_df[0] == hit]\n",
    "            start = tmp_df_2[1].min() - 30000\n",
    "            if start < 1:\n",
    "                start = 1\n",
    "            end = tmp_df_2[2].max() + 30000\n",
    "            seq = genome_fa.fetch(hit, start, end)\n",
    "            seq_r = '' #initialize empty SeqIO record\n",
    "            seq_id = hit + '_' + str(start) + '_' + str(end)\n",
    "            seq_ob = Seq(seq)\n",
    "            seq_ob.alphabet = 'fasta'\n",
    "            seq_r = SeqRecord(seq_ob)\n",
    "            seq_r.id = seq_id\n",
    "            tmp_list.append(seq_r)\n",
    "        protein_dict_nfb_bhits[query] = tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a dicts for the summary dataframes for no_filtered_blast_hits\n",
    "no_filtered_blast_sdf = {}\n",
    "keys = no_filtered_blast_dict.keys()\n",
    "for key in keys:\n",
    "    tmp_df = ''\n",
    "    tmp_df = pd.DataFrame.from_dict(no_filtered_blast_dict[key])\n",
    "    tmp_df.rename(columns={0:'gene_model'}, inplace = True)\n",
    "    no_filtered_blast_sdf[key] = tmp_df\n",
    "\n",
    "#now add the length column to the data frame by using the fa_protein_length_dict \n",
    "for key in keys:\n",
    "    tmp_length_df = ''\n",
    "    tmp_length_df = pd.DataFrame.from_dict(fa_protein_length_dict[key], orient='index')\n",
    "    tmp_length_df['gene_model'] = tmp_length_df.index\n",
    "    tmp_length_df.reset_index(inplace=True, drop=True)\n",
    "    tmp_length_df.rename(columns={0:'protein_length'}, inplace=True)\n",
    "    tmp_length_df = tmp_length_df[tmp_length_df['gene_model'].isin(no_filtered_blast_sdf[key]['gene_model'])]\n",
    "    tmp_length_df.reset_index(inplace=True, drop = True)\n",
    "    no_filtered_blast_sdf[key] = pd.merge(tmp_length_df, no_filtered_blast_sdf[key])\n",
    "\n",
    "#now add colum to the dataframe if or no the protein had a gene blast hit\n",
    "for key in keys:\n",
    "    tmp_gene_hit_df = ''\n",
    "    #get the right df from no_filtered_gene_blast_hits\n",
    "    tmp_gene_hit_df = nfb_gene_blast_bed_df_filtered_dict[key]\n",
    "    #make a true false series if gene_models are having a blast hit\n",
    "    tmp_gene_hit_bol_series = no_filtered_blast_sdf[key]['gene_model'].isin(tmp_gene_hit_df[3].str.replace('TU', 'model'))\n",
    "    no_filtered_blast_sdf[key]['gene_hit'] = tmp_gene_hit_bol_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now loop over the dicts protein_dict_nfb_bhits and protein_dict_nfb with the keys and print out the sequences in a \n",
    "#new folder for each hit and write a script for this later\n",
    "#exonerate folder initially was based on each blast hit form blast previously using interrow over the tmp_df above. \n",
    "#in some cases this lead to hundreds of hits on the same contig often in close proximity. This has been reduced \n",
    "#to one selected contig sequence per hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make new folder for exonerate\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "exonerate_folder = os.path.join(working_dir, 'exonerate_2')\n",
    "if not os.path.exists(exonerate_folder):\n",
    "    os.mkdir(exonerate_folder)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.mkdir(new_folder)\n",
    "    os.chdir(new_folder)\n",
    "    out_p_f = open(key+'.fa', 'w')\n",
    "    SeqIO.write(protein_dict_nfb[key], out_p_f, 'fasta')\n",
    "    out_p_f.close()\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        out_t_f = open(seq.id + '.fa', 'w')\n",
    "        SeqIO.write(seq, out_t_f, 'fasta')\n",
    "        out_t_f.close()\n",
    "    os.chdir(working_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make write exonerate script\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "os.chdir(working_dir)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "out_exonerate = open('exonerate_alignments_vulgar2.sh', 'w')\n",
    "out_exonerate.write('#!/bin/bash\\n')\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    protein_file_name = key+'.fa'\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    out_exonerate.write('cd %s\\n'% (new_folder))\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        target_file_name = seq.id + '.fa'\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment False -S > %s.vulgar_exn\\n'\\\n",
    "                           %(protein_file_name, target_file_name,target_file_name ))\n",
    "out_exonerate.write('cd %s\\n' %(working_dir))\n",
    "out_exonerate.close()\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! bash exonerate_alignments_vulgar2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make write exonerate script\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "os.chdir(working_dir)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "out_exonerate = open('exonerate_alignments2.sh', 'w')\n",
    "out_exonerate.write('#!/bin/bash\\n')\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    protein_file_name = key+'.fa'\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    out_exonerate.write('cd %s\\n'% (new_folder))\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        target_file_name = seq.id + '.fa'\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment -S > %s.exn\\n'\\\n",
    "                           %(protein_file_name, target_file_name,target_file_name ))\n",
    "out_exonerate.write('cd %s\\n' %(working_dir))\n",
    "out_exonerate.close()\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!bash exonerate_alignments2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no loop through the exonerate vulgar result and generate a dictionray of the results\n",
    "#if hsps query range == (0, query_length) and not F in .vulgar_comp it is likely that the alignment is actually good\n",
    "#and and the gene model might have been dropped for another reason\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "exonerate_folder = os.path.join(working_dir, 'exonerate_2')\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "#a dict that has the gene model as key and the results of exonerate (True/False) as value.\n",
    "exonerate_dict = {}\n",
    "exonerate_best_hit_dict = {}\n",
    "#now loop through the exonerate folders\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    os.chdir(new_folder)\n",
    "    if key.split('.')[2].startswith('h'):\n",
    "        query_length = fa_protein_length_dict['Pst_E104_v1_h_ctg'][key]\n",
    "    else:\n",
    "        query_length = fa_protein_length_dict['Pst_E104_v1_p_ctg'][key]\n",
    "    counter = 0\n",
    "    vulgar_exn = [x for x in os.listdir() if x.endswith('vulgar_exn')]\n",
    "    opt_query_range = (0, query_length)\n",
    "    #loop through vulgar parser and see if hit is \n",
    "    best_score = 0\n",
    "    best_hit = ''\n",
    "    for fname in vulgar_exn:\n",
    "        result = SearchIO.parse(fname, 'exonerate-vulgar') \n",
    "        for hit in result:\n",
    "            #loop through all hsps hits\n",
    "            for hsps in hit.hsps:\n",
    "                hsps_range = hsps.query_range\n",
    "                vulgar_list = hsps.vulgar_comp.strip(' ').split(' ')\n",
    "                #print(hsps_range, vulgar_list)\n",
    "                #this is the contition for something being a potential protein alignment that\n",
    "                #has been left out\n",
    "                if hsps_range == opt_query_range and 'F' not in vulgar_list:\n",
    "                    counter += 1\n",
    "                    if hsps.score > best_score:\n",
    "                        best_hit = hsps.hit_id\n",
    "                    #print(key)\n",
    "    if counter > 0:\n",
    "        exonerate_dict[key] = True\n",
    "        exonerate_best_hit_dict[key] = best_hit\n",
    "    else:\n",
    "        exonerate_dict[key] = False\n",
    "    \n",
    "    os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now add colum to the dataframe if or not a protein sequence could be aligned back to the gene blast hit using exonerate\n",
    "#plus a column that describes the best exonerate hit\n",
    "keys = no_filtered_blast_dict.keys()\n",
    "for key in keys:\n",
    "    #pull in the two exonerate df to be combined with the no_filtered_blast_sdf dataframe\n",
    "    tmp_exonerate_dict_df = pd.DataFrame.from_dict(exonerate_dict, orient='index')\n",
    "    tmp_exonerate_dict_df['gene_model'] = tmp_exonerate_dict_df.index\n",
    "    tmp_exonerate_dict_df.rename(columns={0:'exonerate_hit'}, inplace=True)\n",
    "    tmp_exonerate_dict_df.reset_index(inplace=True, drop=True)\n",
    "    tmp_exonerate_best_hit_dict_df = pd.DataFrame.from_dict(exonerate_best_hit_dict, orient='index')\n",
    "    tmp_exonerate_best_hit_dict_df['gene_model'] = tmp_exonerate_best_hit_dict_df.index\n",
    "    tmp_exonerate_best_hit_dict_df.rename(columns={0:'exonerate_best_hit'}, inplace=True)\n",
    "    tmp_exonerate_best_hit_dict_df.reset_index(inplace=True, drop=True)\n",
    "    tmp_exonerate_df = pd.merge(tmp_exonerate_best_hit_dict_df,tmp_exonerate_dict_df)  #same length so no out neccessary\n",
    "    tmp_exonerate_df.reset_index(inplace=True, drop=True)\n",
    "    if 'h_ctg' in key:\n",
    "        tmp_exonerate_df = tmp_exonerate_df[tmp_exonerate_df.gene_model.str.contains('hcontig')]\n",
    "    else:\n",
    "        tmp_exonerate_df =tmp_exonerate_df[tmp_exonerate_df.gene_model.str.contains('pcontig')]\n",
    "    tmp_exonerate_df.reset_index(inplace=True, drop=True)\n",
    "    no_filtered_blast_sdf[key]= pd.merge( no_filtered_blast_sdf[key],tmp_exonerate_df, how='outer').fillna(value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add another column for genes being on pwh or not\n",
    "for key in keys:\n",
    "    df_p['pwh'] = df_p[0].apply(pwh_filter)\n",
    "    no_filtered_blast_sdf[key]['pwh'] = no_filtered_blast_sdf[key]['gene_model'].apply(pwh_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now save the dataframes for now\n",
    "for key in keys:\n",
    "    filename = key + '.no_filtered_blast_sdf.tab'\n",
    "    no_filtered_blast_sdf[key].to_csv(filename, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#next step is to get the gffs for all the the no_filtered blast hits for both p and h contigs that do not have a exonerate-hit\n",
    "#in case of the p contigs these need to be compared to the unqie bed dataframes using pybed tools\n",
    "\n",
    "#pull in gff dataframe and parse out gene model into a new column use this column for filtering down the dataframe\n",
    "#write this out again and load as bedfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col_8_id(x):\n",
    "    import re\n",
    "    pattern = r'ID=([a-zA-Z0-9_.]*);'\n",
    "    regex = re.compile(pattern)  \n",
    "    m = regex.search(x)\n",
    "    match = m.groups()[0].replace('TU', 'model')\n",
    "    if match.startswith('cds.'):\n",
    "        match = match[4:]\n",
    "    if 'exon' in match:\n",
    "        _list = match.split('.')\n",
    "        match = '.'.join(_list[:-1])\n",
    "    return match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in gene annotation gff files for downstream analysis\n",
    "annotation_folder = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/122016_assembly'\n",
    "gene_anno_gffs = [x for x in os.listdir(annotation_folder) if x.endswith('anno.RepaseTPSI_filtered.gff3') and x.startswith('Pst_E104_v11')]\n",
    "gene_anno_gff_dict = {}\n",
    "for file in gene_anno_gffs:\n",
    "    full_file_path = os.path.join(annotation_folder, file)\n",
    "    tmp_df =  pd.read_csv(full_file_path, header=None, sep='\\t')\n",
    "    tmp_df['gene_model'] = tmp_df[8].apply(col_8_id)\n",
    "    gene_anno_gff_dict[file.split('.')[0].replace('11', '1')] =  tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter gene annotation gff files for downstream analysis and save to file\n",
    "os.chdir(working_dir)\n",
    "keys = no_filtered_blast_sdf.keys()\n",
    "no_filtered_blast_gffs_plus = {}\n",
    "for key in keys:\n",
    "    tmp_df_gff = ''\n",
    "    tm_df_nfb = ''\n",
    "    tmp_df = ''\n",
    "    tmp_df_gff = gene_anno_gff_dict[key]\n",
    "    tmp_df_nfb = no_filtered_blast_sdf[key]\n",
    "    tmp_df = tmp_df_gff[tmp_df_gff['gene_model'].isin(tmp_df_nfb['gene_model'].tolist())]\n",
    "    tmp_df.reset_index(inplace=True, drop=True)\n",
    "    no_filtered_blast_gffs_plus[key] = tmp_df\n",
    "    file_name = key+'.anno.no_filtered_blast.gff3'\n",
    "    no_filtered_blast_gffs_plus[key].iloc[:,range(0,9)].to_csv(file_name, header=None, sep='\\t', index=None)\n",
    "    gene_file_name = key+'.gene.no_filtered_blast.gff3'\n",
    "    no_filtered_blast_gffs_plus[key][no_filtered_blast_gffs_plus[key][2] == 'gene'].iloc[:,range(0,9)].to_csv(gene_file_name, header=None, sep='\\t', index=None)\n",
    "    tmp_df_gff = ''\n",
    "    tm_df_nfb = ''\n",
    "    tmp_df = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now lead into the  Pst_E104_v1_p_ctg.gene.no_filtered_blast.gff3 and the Pst_E104_v1_ph_ctg.ph_p_homo_cov.bed as \n",
    "#bed files and do an intersect\n",
    "from pybedtools import BedTool\n",
    "cov_folder = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/COV'\n",
    "homo_cov_ph_p = 'Pst_E104_v1_ph_ctg.ph_p_homo_cov.bed'\n",
    "homo_cov_ph_p_bed = BedTool(os.path.join(cov_folder, homo_cov_ph_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in no blast hit gene gff of primary contigs \n",
    "no_filtered_blast_gene_p = 'Pst_E104_v1_p_ctg.gene.no_filtered_blast.gff3'\n",
    "no_filtered_blast_gene_p_bed = BedTool(os.path.join(working_dir, no_filtered_blast_gene_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the id of all genes of no filtered blast hits that overlap at all with homo coverage of ph mapping on p\n",
    "gene_ids_ph_p_homo = []\n",
    "for x in no_filtered_blast_gene_p_bed.intersect(homo_cov_ph_p_bed):\n",
    "    y = col_8_id(x[8])\n",
    "    gene_ids_ph_p_homo.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now filter the no_filtered_blast_gffs_plus_p and save the data frame as gff file again\n",
    "no_filtered_blast_gffs_plus_p = no_filtered_blast_gffs_plus['Pst_E104_v1_p_ctg']\n",
    "no_filtered_blast_gffs_plus_p[~no_filtered_blast_gffs_plus_p['gene_model'].isin(gene_ids_ph_p_homo)]\n",
    "no_filtered_blast_gffs_plus_p_no_homo = no_filtered_blast_gffs_plus_p[~no_filtered_blast_gffs_plus_p['gene_model'].isin(gene_ids_ph_p_homo)]\n",
    "no_filtered_blast_gffs_plus_p_no_homo.iloc[:,range(0,9)].to_csv\\\n",
    "('Pst_E104_v1_p_ctg.anno.no_filtered_blast.no_homo.gff3', header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add new column to the summary dataframe that looks for ph_h_homo coverage (this is actually only true for contigs with \n",
    "# mean coverage < 2000)\n",
    "tmp_nfb_sdf_p = no_filtered_blast_sdf['Pst_E104_v1_p_ctg']\n",
    "tmp_homo_p_series = tmp_nfb_sdf_p['gene_model'].isin(gene_ids_ph_p_homo)\n",
    "tmp_nfb_sdf_p['ph_p_homo_cov'] = tmp_homo_p_series\n",
    "no_filtered_blast_sdf['Pst_E104_v1_p_ctg'] = tmp_nfb_sdf_p\n",
    "filename = 'Pst_E104_v1_p_ctg' + '.no_filtered_blast_sdf.tab'\n",
    "no_filtered_blast_sdf['Pst_E104_v1_p_ctg'].to_csv(filename, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## up to here looks good consider that high cov contigs are not filtered out yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_nfb_sdf_p[(tmp_nfb_sdf_p['pwh'] == False)&(tmp_nfb_sdf_p['exonerate_hit'] == True)&(tmp_nfb_sdf_p['ph_p_homo_cov'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_blast_sdf['Pst_E104_v1_p_ctg'][no_filtered_blast_sdf['Pst_E104_v1_p_ctg'].pwh == 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_blast_sdf['Pst_E104_v1_p_ctg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_blast_sdf['Pst_E104_v1_h_ctg'][no_filtered_blast_sdf['Pst_E104_v1_h_ctg']['exonerate_hit'] == False]['protein_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_blast_sdf['Pst_E104_v1_h_ctg'][no_filtered_blast_sdf['Pst_E104_v1_h_ctg'].pwh == 0]['protein_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_filtered_blast_sdf['Pst_E104_v1_h_ctg']['protein_length'].hist(bins=20,alpha=0.5, color='g')\n",
    "no_filtered_blast_sdf['Pst_E104_v1_p_ctg']['protein_length'].hist(bins=20,alpha=0.5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(no_filtered_blast_sdf['Pst_E104_v1_h_ctg'][no_filtered_blast_sdf['Pst_E104_v1_h_ctg']['exonerate_hit'] == False])/15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nfb_gene_blast_bed_df_filtered[3].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
