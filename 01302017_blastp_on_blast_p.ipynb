{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.p_on_h.blast.alloutfmt6', 'Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.h_on_p.blast.alloutfmt6']\n",
      "['Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.fa', 'Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.fa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "\n",
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p')\n",
    "\n",
    "os.listdir()\n",
    "hit_df =''\n",
    "files = os.listdir()\n",
    "outfmt6 = [x for x in files if x.endswith('blast.alloutfmt6') and 'anno' in x]\n",
    "print(outfmt6)\n",
    "fa_files = [x for x in files if x.endswith('RepaseTPSI_filtered.protein.fa')]\n",
    "print(fa_files)\n",
    "\n",
    "#The next block should pull in both the initial protein and the blast df.\n",
    "#The initial protein should become a dataframe that contains proteins sequence name and length.\n",
    "#This df should be merged with the blast df in a way that proteins without hit should get NA values. \n",
    "#Once this is done make two arrays with [p, h], sort this and compare, pull out everything that is identical, and lable it with a new column reverse blast Yes/No.\n",
    "#Pull out YES and see if they are enriched/depelted in something. NOs need to be checked for high coverage in ph vs h/p mapping and levels of heterozycosity + h on p mapping mappings. \n",
    "\n",
    "#read in protein ids for p and h contigs and store names in a list in a dict with unique key id [first part of\n",
    "#file name].\n",
    "fa_protein_dict = {}\n",
    "fa_protein_length_dict = {}\n",
    "for file in fa_files:\n",
    "    seq_list = []\n",
    "    length_list =[]\n",
    "    for seq in SeqIO.parse(open(file), 'fasta'):\n",
    "        seq_list.append(seq.id)\n",
    "        length_list.append(len(seq.seq))\n",
    "    key_name = file.split('.')[0]\n",
    "    fa_protein_dict[key_name] = seq_list\n",
    "    fa_protein_length_dict[key_name] = dict(zip(seq_list, length_list))\n",
    "\n",
    "#generate df dict of blast output and filter blast output\n",
    "header = ['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery', 'StopQuery', 'StartTarget',\\\n",
    "              'StopTarget', 'e-value','BitScore']\n",
    "outfmt6_dict ={} #contains the filtered values\n",
    "outfmt6_dict_all = {} #contains the unfiltered blast hits e.g. low % identity and low query coverage\n",
    "#match_dict = {} #get best hits in match_dict[p_protein] = h_protein\n",
    "hit_df = pd.DataFrame(columns=['p_protein', 'h_protein'])\n",
    "for outfile in outfmt6:\n",
    "    key_name =  outfile.split('.')[0]\n",
    "    df = ''\n",
    "    df = pd.read_csv(outfile, header = None, names = header, sep='\\t')\n",
    "    #add the query length using to the df using the length dict generated before\n",
    "    df[\"QLgth\"] = df[\"Query\"].apply(lambda x: fa_protein_length_dict[key_name][x]) \n",
    "    df[\"QCov\"] = df['AlnLgth']/df['QLgth']*100 #calculate the % coverage for each querry\n",
    "    outfmt6_dict_all[key_name] = df\n",
    "    df = df[(df['QCov'] > 30) & (df['PctID'] > 50) ] #define paralogous as Query coverage > 30% and PctID > 50\n",
    "    #this could be more dynamic and the outfmt of blast AlnLngthPct and they greater than 60%\n",
    "    groups = df.groupby(by='Query')\n",
    "    #now filter the dataframe by the smallest e-value for each group == Query\n",
    "    df_filtered = groups.apply(lambda g: g[g['e-value'] == g['e-value'].min()]) \n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    #in case there is a blast query that hits the same subject twice with the same minimal e-value\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['Query', 'Target'], keep ='last')\n",
    "    outfmt6_dict[key_name] = df_filtered\n",
    "    if 'p_ctg' in key_name:\n",
    "        df_filtered['h_protein'] = df_filtered['Target']\n",
    "        df_filtered['p_protein'] = df_filtered['Query']\n",
    "    if 'h_ctg' in key_name:\n",
    "        df_filtered['h_protein'] = df_filtered['Query']\n",
    "        df_filtered['p_protein'] = df_filtered['Target']\n",
    "    hit_df = pd.concat([hit_df, df_filtered.loc[:, ['p_protein', 'h_protein']]])\n",
    "\n",
    "#duplicates are besties as they are entered twice from both outfmt\n",
    "\n",
    "bestie_df = hit_df[hit_df.duplicated(keep='first')]\n",
    "\n",
    "bestie_df.to_csv(list(outfmt6_dict.keys())[0][:-6] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "bestie_df['p_protein'].to_csv(list(outfmt6_dict.keys())[0] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "bestie_df['h_protein'].to_csv(list(outfmt6_dict.keys())[1] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "\n",
    "#this is pulling out the no blast hits at all. Should be a subset of no_besties\n",
    "no_hits ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_hits[key] = set(fa_protein_dict[key]) - set(outfmt6_dict_all[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits[key])).to_csv(key + '.p_proteins.no_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_hits[key] = set(fa_protein_dict[key]) - set(outfmt6_dict_all[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits[key])).to_csv(key + '.h_proteins.no_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "no_hits_filtered ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_hits_filtered[key] = set(fa_protein_dict[key]) - set(outfmt6_dict[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits_filtered[key])).to_csv(key + '.p_proteins.no_filtered_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_hits_filtered[key] = set(fa_protein_dict[key]) - set(outfmt6_dict[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits_filtered[key])).to_csv(key + '.h_proteins.no_filtered_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "        \n",
    "\n",
    "#this is now pulling out the besties\n",
    "no_bestie ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_bestie[key] = set(fa_protein_dict[key]) - set(bestie_df['p_protein'])\n",
    "        pd.DataFrame(list(no_bestie[key])).to_csv(key + '.p_proteins.no_besties.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_bestie[key] = set(fa_protein_dict[key]) - set(bestie_df['h_protein'])\n",
    "        pd.DataFrame(list(no_bestie[key])).to_csv(key + '.h_proteins.no_besties.txt', sep='\\t', header=None, index=None)        \n",
    "        \n",
    "_len_out = 0\n",
    "_len_pro = 0\n",
    "for x in fa_protein_dict.keys():\n",
    "    _len_pro += len(fa_protein_dict[x])\n",
    "    _len_out += len(no_bestie[x])\n",
    "_len_out += (len(bestie_df))*2 - bestie_df.duplicated(subset=\"p_protein\", keep='last').sum() \\\n",
    "- bestie_df.duplicated(subset=\"h_protein\", keep='last').sum()\n",
    "_len_out == _len_pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 15949 4809 have no reciprocal blast hit for Pst_E104_v1_p_ctg making it 30.15 percent.\n",
      "Out of 15949 2072 have no blast hit at all for Pst_E104_v1_p_ctg making it 12.99 percent.\n",
      "Out of 15949 3029 have no blast hit after filtering by AlnLght and QCov for Pst_E104_v1_p_ctg making it 18.99 percent.\n",
      "Out of 14321 2974 have no reciprocal blast hit for Pst_E104_v1_h_ctg making it 20.77 percent.\n",
      "Out of 14321 885 have no blast hit at all for Pst_E104_v1_h_ctg making it 6.18 percent.\n",
      "Out of 14321 1323 have no blast hit after filtering by AlnLght and QCov for Pst_E104_v1_h_ctg making it 9.24 percent.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_len_out = 0\n",
    "_len_pro = 0\n",
    "for x in fa_protein_dict.keys():\n",
    "    _len_pro += len(fa_protein_dict[x])\n",
    "    _len_out += len(no_bestie[x])\n",
    "    print(\"Out of %i %i have no reciprocal blast hit for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_bestie[x]),x, (len(no_bestie[x])/len(fa_protein_dict[x])*100) ))\n",
    "    print(\"Out of %i %i have no blast hit at all for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_hits[x]),x, (len(no_hits[x])/len(fa_protein_dict[x])*100) ))\n",
    "    print(\"Out of %i %i have no blast hit after filtering by AlnLght and QCov for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_hits_filtered[x]),x, (len(no_hits_filtered[x])/len(fa_protein_dict[x])*100) ))\n",
    "_len_out += (len(bestie_df))*2 - bestie_df.duplicated(subset=\"p_protein\", keep='last').sum() \\\n",
    "- bestie_df.duplicated(subset=\"h_protein\", keep='last').sum()\n",
    "_len_out == _len_pro"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#now pull gene sequences for no-besties and do blast on the corresponding other haplotype\n",
    "#gene files were generated by \n",
    "cat Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.gff3 | awk '$3==\"gene\"' > Pst_E104_v1_p_ctg.gene.RepaseTPSI_filtered.gff3\n",
    "for gff in gene_gff:\n",
    "    gene = ''\n",
    "    gene_df = pd.read_csv(folder + gff, header = None, sep='\\t' )\n",
    "    gene_df[2] = gene_df[8].apply(col_8_id)\n",
    "    gene_df.to_csv(folder+gff, header=None, sep='\\t', index=None)\n",
    "bedtools getfasta -s -name -fi Pst_E104_v1_ph_ctg.fa -bed Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.gff3 -fo Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_outfmt6_to_bed(x):\n",
    "    blast_fo = open(x, 'r')\n",
    "    blast_lines = blast_fo.readlines()\n",
    "    bed_file_name = x + '.bed'\n",
    "    bed_fo = open(bed_file_name, 'w+')\n",
    "    for l in blast_lines:\n",
    "        content = l.split('\\t')\n",
    "        if int(content[8]) - int(content[9]) < 1:\n",
    "            print(content[1], int(content[8]) -1, content[9], content[0], content[10], \"+\", sep=\"\\t\", file=bed_fo) \n",
    "        else:\n",
    "            print(content[1], int(content[9]) -1, content[8],  content[0], content[10], \"-\", sep = \"\\t\", file=bed_fo)\n",
    "    blast_fo.close()\n",
    "    bed_fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastn -db Pst_E104_v1_p_ctg.fa -query -Pst_E104_v1_h_ctg.h_genes.no_besties.fa > Pst_E104_v1_h_ctg.h_genes.no_besties.fa.outfmt6\n",
      "blastn -db Pst_E104_v1_h_ctg.fa -query -Pst_E104_v1_p_ctg.p_genes.no_besties.fa > Pst_E104_v1_p_ctg.p_genes.no_besties.fa.outfmt6\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "folder_p = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p/'\n",
    "\n",
    "no_besties = [x for x in os.listdir(folder_p) if x.endswith('no_besties.txt')]\n",
    "gene_files = [x for x in os.listdir(folder_p) if '.gene.' in x and '.fa' in x]\n",
    "no_besties.sort()\n",
    "gene_files.sort()\n",
    "no_bestie_dict = {}\n",
    "\n",
    "#simply pulls in the gene sequences of missing besties\n",
    "for no_b, gene_file in zip(no_besties, gene_files):\n",
    "    no_bestie_list = pd.read_csv(folder_p+no_b, header=None, sep='\\t')[0].tolist()\n",
    "    key = no_b.split('.')[0]\n",
    "    no_bestie_dict[key] = no_bestie_list\n",
    "    no_bestie_list = [x.replace('evm.model', 'evm.TU') for x in no_bestie_list]\n",
    "    no_bestie_seq = []\n",
    "    for seq in SeqIO.parse(open(folder_p + gene_file), 'fasta'):\n",
    "        if seq.id in no_bestie_list:\n",
    "            no_bestie_seq.append(seq)\n",
    "    out_f = folder_p + no_b[:-3].replace('protein', 'gene') + 'fa'\n",
    "    f_handle = open(out_f,'w') #need to generate handle for writing and\n",
    "    SeqIO.write(no_bestie_seq, f_handle, 'fasta')\n",
    "    f_handle.close() #closing file afterwards again\n",
    "\n",
    "gene_files_no_besties = [x for x in os.listdir(folder_p) if x.endswith('_genes.no_besties.fa')]\n",
    "blast_db_nt = [x for x in os.listdir(folder_p) if x.endswith('_ctg.fa')]\n",
    "gene_files_no_besties.sort()\n",
    "blast_db_nt.sort()\n",
    "\n",
    "os.chdir(folder_p)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[1], gene_files_no_besties[0],gene_files_no_besties[0]))\n",
    "!blastn -db {blast_db_nt[1]} -query {gene_files_no_besties[0]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_besties[0]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_besties[0]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[0], gene_files_no_besties[1],gene_files_no_besties[1]))\n",
    "!blastn -db {blast_db_nt[0]} -query {gene_files_no_besties[1]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_besties[1]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_besties[1]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#now read in the bed files and filter out proteins that had an initial blast hit but another protein was better\n",
    "#~befile[3].isin[alloutfmt6]\n",
    "#for the rest do a group by [3] and only save the best hits as above. Save this to file and use bedtools to fish out \n",
    "#gene models that overlap with the best blast hits of those. Everything which doesn't have a gene model is a true miss.\n",
    "#the others need to be looked at and see if there is a possible frameshit or missense mutation. if not the gene model\n",
    "#might have been dropped adenvertenly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_besties_blast_nt_bed = [x for x in os.listdir(folder_p) if x.endswith('no_besties.fa.outfmt6.bed') ]\n",
    "no_besties_blast_nt_bed.sort()\n",
    "outfmt6.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.h_on_p.blast.alloutfmt6',\n",
       " 'Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.p_on_h.blast.alloutfmt6']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfmt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pst_E104_v1_h_ctg.h_genes.no_besties.fa.outfmt6.bed',\n",
       " 'Pst_E104_v1_p_ctg.p_genes.no_besties.fa.outfmt6.bed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_besties_blast_nt_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 1993 out of 2974 no_besties of Pst_E104_v1_h_ctg had a blast hit which was not RBH\n",
      "This 171 out of 2974 no_besties of Pst_E104_v1_h_ctg have no blast hit gene vs. other haplome\n",
      "No gene hits that have a protein hit 96 Pst_E104_v1_h_ctg\n",
      "This 2105 out of 4809 no_besties of Pst_E104_v1_p_ctg had a blast hit which was not RBH\n",
      "This 1708 out of 4809 no_besties of Pst_E104_v1_p_ctg have no blast hit gene vs. other haplome\n",
      "No gene hits that have a protein hit 632 Pst_E104_v1_p_ctg\n"
     ]
    }
   ],
   "source": [
    "#this needs to include some folder tracking of gene.no_besties.fa that hits nothing significant \n",
    "#no_bbb in - no_bbb out = no_hits at all\n",
    "no_gene_hits = {}\n",
    "for no_bbb, protein_blast in zip(no_besties_blast_nt_bed,outfmt6):\n",
    "    no_bbb_no_protein_blast_df =''\n",
    "    no_bbb_df_header = ['Contig', 'start', 'end', 'blast_query', 'e-value', 'strand']\n",
    "    no_bbb_df = pd.read_csv(folder_p+no_bbb, header=None, names=no_bbb_df_header,  sep='\\t')\n",
    "    protein_blast_df = pd.read_csv(folder_p+protein_blast, header=None, sep='\\t')\n",
    "    no_bbb_df['protein_id'] = no_bbb_df['blast_query'].str.replace('evm.TU', 'evm.model')\n",
    "    #this below is most likely correct ignores the fact that some no_bbb genes might have hit nothing\n",
    "    #at all on the gene level\n",
    "    no_bbb_no_protein_blast_df = no_bbb_df[~no_bbb_df['protein_id'].isin(protein_blast_df[0])]\n",
    "    #these are the no_besties that didn't hit anything at the gene level\n",
    "    key =''\n",
    "    key = no_bbb.split('.')[0]\n",
    "    no_gene_hits[key] = set(no_bestie_dict[key]) - set(no_bbb_df['protein_id'].unique())\n",
    "    pd.DataFrame(list(no_gene_hits[key])).to_csv(key + '.gene.no_genome_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    blast_p_no_bestie =''\n",
    "    blast_p_no_bestie = len(no_bbb_df[no_bbb_df['protein_id'].isin(protein_blast_df[0])]['blast_query'].unique())\n",
    "    print('This %i out of %i no_besties of %s had a blast hit which was not RBH' % \\\n",
    "          (blast_p_no_bestie, len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print('This %i out of %i no_besties of %s have no blast hit gene vs. other haplome' % \\\n",
    "         (len(no_gene_hits[key]),len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print(\"No gene hits that have a protein hit\", len(set(no_gene_hits[key])- set(no_hits[key])), key)\n",
    "    groups = no_bbb_no_protein_blast_df.groupby(by='blast_query')\n",
    "    #now filter the dataframe by the smallest e-value for each group == blast_hit\n",
    "    df_filtered = groups.apply(lambda g: g[g['e-value'] == g['e-value'].min()])\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    df_filtered.iloc[:,0:6].to_csv(folder_p+no_bbb[:-4]+'.filteredbesthits.bed', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all primary proteins no hit need to be split up into pwh and pwoh\n",
    "p_contig_list = []\n",
    "h_contig_list = []\n",
    "for seq in SeqIO.parse('Pst_E104_v1_h_ctg.fa', 'fasta'):\n",
    "    h_contig_list.append(seq.id)\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    p_contig_list.append(seq.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_contigs with h_contig are 102 and without 74\n"
     ]
    }
   ],
   "source": [
    "pwh_set = set([x[0:11].replace('h','p') for x in h_contig_list])\n",
    "pwoh_set = set(p_contig_list) - pwh_set\n",
    "print(\"P_contigs with h_contig are %i and without %i\" % (len(pwh_set), len(pwoh_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15306 643 15949\n"
     ]
    }
   ],
   "source": [
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwh_set]\n",
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwoh_set]\n",
    "print(len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']), len (fa_protein_dict['Pst_E104_v1_p_ctg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_txt = [x for x in os.listdir(folder_p) if x.split('.')[0] == 'Pst_E104_v1_p_ctg' and x.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pwh_filter (x):\n",
    "    p_contig = x.split('.')[2]\n",
    "    if p_contig in pwh_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hitpwh.txt 1823 proteins out of 15306 (11.91) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hitpwh.txt 0 proteins out of 643 (0) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt 1456 proteins out of 15306 (9.51) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt 252 proteins out of 643 (39) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt 1823 proteins out of 15306 (11.91) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt 249 proteins out of 643 (38) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.besties.txt 14428 proteins out of 15306 (94.26) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.besties.txt 292 proteins out of 643 (45) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hitpwoh.txt 0 proteins out of 15306 (0.00) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hitpwoh.txt 375 proteins out of 643 (58) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_bestiespwh.txt 4304 proteins out of 15306 (28.12) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_bestiespwh.txt 0 proteins out of 643 (0) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_bestiespwoh.txt 0 proteins out of 15306 (0.00) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_bestiespwoh.txt 505 proteins out of 643 (78) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hitpwh.txt 2654 proteins out of 15306 (17.34) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hitpwh.txt 0 proteins out of 643 (0) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt 2654 proteins out of 15306 (17.34) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt 375 proteins out of 643 (58) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.bestiespwh.txt 14428 proteins out of 15306 (94.26) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.bestiespwh.txt 0 proteins out of 643 (0) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_besties.txt 4304 proteins out of 15306 (28.12) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_besties.txt 505 proteins out of 643 (78) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hitpwoh.txt 0 proteins out of 15306 (0.00) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hitpwoh.txt 252 proteins out of 643 (39) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.bestiespwoh.txt 0 proteins out of 15306 (0.00) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.bestiespwoh.txt 292 proteins out of 643 (45) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hitpwh.txt 1456 proteins out of 15306 (9.51) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hitpwh.txt 0 proteins out of 643 (0) are affected for pwoh\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hitpwoh.txt 0 proteins out of 15306 (0.00) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hitpwoh.txt 249 proteins out of 643 (38) are affected for pwoh\n"
     ]
    }
   ],
   "source": [
    "#filter and summarize the p results based on pwh and pwoh \n",
    "for x in p_txt:\n",
    "    df_p = pd.read_csv(x, header=None, sep='\\t')\n",
    "    df_p.head()\n",
    "    df_p['pwh'] = df_p[0].apply(pwh_filter)\n",
    "    df_p[df_p['pwh'] == 1].to_csv(x[:-4]+'pwh.txt', sep ='\\t', header=None, index=None)\n",
    "    df_p[df_p['pwh'] == 0].to_csv(x[:-4]+'pwoh.txt', sep ='\\t', header=None, index=None)\n",
    "    print ('For pwh:')\n",
    "    print('For this condition %s %i proteins out of %i (%.2f) are affected for pwh'% \\\n",
    "          (x, sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), \\\n",
    "           sum(df_p['pwh'])/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh'])*100 ))\n",
    "    print ('For pwoh:')\n",
    "    print('For this condition %s %i proteins out of %i (%i) are affected for pwoh'% \\\n",
    "         (x, len(df_p['pwh']) - sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']),\\\n",
    "        (len(df_p['pwh']) - sum(df_p['pwh']))/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh'])*100 ))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of pwoh 79847369, lenght of pwo 4178824, total length p 84026193\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p')\n",
    "len_pwh = 0\n",
    "len_pwoh = 0\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    if seq.id in pwh_set:\n",
    "        len_pwh = len_pwh + len(seq.seq)\n",
    "    if seq.id in pwoh_set:\n",
    "        len_pwoh = len_pwoh + len(seq.seq)\n",
    "print(\"Lenght of pwoh %i, lenght of pwo %i, total length p %i\" %(len_pwh,len_pwoh,len_pwh+len_pwoh ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pwh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25036"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.besties.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_besties.txt']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1993"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maybe keep track of those that have a blast hit but no bestie\n",
    "#yes save those to file and have a look at those as well e.g. p-values and best hits etc.\n",
    "len(no_bbb_df[no_bbb_df['protein_id'].isin(protein_blast_df[0])]['blast_query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#maybe better to do this feature \n",
    "no_besties_h_p_blast_hits = BedTool('Pst_E104_v1_h_ctg.h_genes.no_besties.fa.outfmt6.filteredbesthits.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcontig_000\t38121\t38929\tevm.TU.hcontig_000_003.11\t0.0\t-\n",
      " pcontig_006\t564497\t566065\tevm.TU.hcontig_000_003.125\t0.0\t+\n",
      " pcontig_000\t498148\t498837\tevm.TU.hcontig_000_003.138\t0.0\t+\n",
      " pcontig_000\t493698\t494516\tevm.TU.hcontig_000_003.139\t0.0\t+\n",
      " pcontig_000\t647841\t649077\tevm.TU.hcontig_000_003.176\t0.0\t-\n",
      " pcontig_008\t304179\t305415\tevm.TU.hcontig_000_003.176\t0.0\t+\n",
      " pcontig_023\t757954\t758439\tevm.TU.hcontig_000_003.198\t9.999999999999999e-108\t-\n",
      " pcontig_000\t948664\t949090\tevm.TU.hcontig_000_003.235\t0.0\t-\n",
      " pcontig_018\t829342\t829768\tevm.TU.hcontig_000_003.235\t0.0\t-\n",
      " pcontig_046\t202834\t203260\tevm.TU.hcontig_000_003.235\t0.0\t-\n",
      " "
     ]
    }
   ],
   "source": [
    "no_besties_h_p_blast_hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_genes = BedTool('Pst_E104_v1_p_ctg.gene.RepaseTPSI_filtered.gff3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcontig_241\tEVM\tevm.TU.pcontig_241.2\t13967\t14266\t.\t+\t.\tID=evm.TU.pcontig_241.2;Name=EVM%20prediction%2pcontig_0241.2\n",
      " pcontig_241\tEVM\tevm.TU.pcontig_241.1\t4229\t4450\t.\t-\t.\tID=evm.TU.pcontig_241.1;Name=EVM%20prediction%2pcontig_0241.1\n",
      " pcontig_193\tEVM\tevm.TU.pcontig_193.6\t5386\t5862\t.\t+\t.\tID=evm.TU.pcontig_193.6;Name=EVM%20prediction%2pcontig_0193.6\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.7\t22308\t22664\t.\t+\t.\tID=evm.TU.pcontig_225.7;Name=EVM%20prediction%2pcontig_0225.7\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.6\t18672\t21163\t.\t-\t.\tID=evm.TU.pcontig_225.6;Name=EVM%20prediction%2pcontig_0225.6\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.1\t2067\t2309\t.\t+\t.\tID=evm.TU.pcontig_225.1;Name=EVM%20prediction%2pcontig_0225.1\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.3\t3999\t5386\t.\t+\t.\tID=evm.TU.pcontig_225.3;Name=EVM%20prediction%2pcontig_0225.3\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.5\t17272\t18147\t.\t+\t.\tID=evm.TU.pcontig_225.5;Name=EVM%20prediction%2pcontig_0225.5\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.2\t2658\t2883\t.\t+\t.\tID=evm.TU.pcontig_225.2;Name=EVM%20prediction%2pcontig_0225.2\n",
      " pcontig_225\tEVM\tevm.TU.pcontig_225.8\t23727\t24271\t.\t+\t.\tID=evm.TU.pcontig_225.8;Name=EVM%20prediction%2pcontig_0225.8\n",
      " "
     ]
    }
   ],
   "source": [
    "p_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_besties_h_p_gene_intersect = no_besties_h_p_blast_hits.intersect(p_genes, wb=True, f=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(Test.bed)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_besties_h_p_gene_intersect.saveas('Test.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Test.bed', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>647841</td>\n",
       "      <td>649077</td>\n",
       "      <td>evm.TU.hcontig_000_003.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_000.162</td>\n",
       "      <td>647842</td>\n",
       "      <td>649110</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_000.162;Name=EVM%20predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pcontig_008</td>\n",
       "      <td>304179</td>\n",
       "      <td>305415</td>\n",
       "      <td>evm.TU.hcontig_000_003.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>+</td>\n",
       "      <td>pcontig_008</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_008.42</td>\n",
       "      <td>303889</td>\n",
       "      <td>305415</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_008.42;Name=EVM%20prediction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pcontig_072</td>\n",
       "      <td>306840</td>\n",
       "      <td>307338</td>\n",
       "      <td>evm.TU.hcontig_000_003.305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>pcontig_072</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_072.58</td>\n",
       "      <td>305375</td>\n",
       "      <td>307338</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_072.58;Name=EVM%20prediction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>1800902</td>\n",
       "      <td>1802027</td>\n",
       "      <td>evm.TU.hcontig_000_003.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_000.404</td>\n",
       "      <td>1799927</td>\n",
       "      <td>1802027</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_000.404;Name=EVM%20predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>1782634</td>\n",
       "      <td>1783737</td>\n",
       "      <td>evm.TU.hcontig_000_003.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>pcontig_000</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_000.400</td>\n",
       "      <td>1781648</td>\n",
       "      <td>1783737</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_000.400;Name=EVM%20predictio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2                           3    4  5   \\\n",
       "0  pcontig_000   647841   649077  evm.TU.hcontig_000_003.176  0.0  -   \n",
       "1  pcontig_008   304179   305415  evm.TU.hcontig_000_003.176  0.0  +   \n",
       "2  pcontig_072   306840   307338  evm.TU.hcontig_000_003.305  0.0  -   \n",
       "3  pcontig_000  1800902  1802027  evm.TU.hcontig_000_003.400  0.0  -   \n",
       "4  pcontig_000  1782634  1783737  evm.TU.hcontig_000_003.400  0.0  -   \n",
       "\n",
       "            6    7                       8        9        10 11 12 13  \\\n",
       "0  pcontig_000  EVM  evm.TU.pcontig_000.162   647842   649110  .  -  .   \n",
       "1  pcontig_008  EVM   evm.TU.pcontig_008.42   303889   305415  .  +  .   \n",
       "2  pcontig_072  EVM   evm.TU.pcontig_072.58   305375   307338  .  -  .   \n",
       "3  pcontig_000  EVM  evm.TU.pcontig_000.404  1799927  1802027  .  -  .   \n",
       "4  pcontig_000  EVM  evm.TU.pcontig_000.400  1781648  1783737  .  -  .   \n",
       "\n",
       "                                                  14  \n",
       "0  ID=evm.TU.pcontig_000.162;Name=EVM%20predictio...  \n",
       "1  ID=evm.TU.pcontig_008.42;Name=EVM%20prediction...  \n",
       "2  ID=evm.TU.pcontig_072.58;Name=EVM%20prediction...  \n",
       "3  ID=evm.TU.pcontig_000.404;Name=EVM%20predictio...  \n",
       "4  ID=evm.TU.pcontig_000.400;Name=EVM%20predictio...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df[\"LenBlast\"] = abs(test_df[1] - test_df[2])\n",
    "test_df[\"Lenfeature\"] = abs(test_df[9]-test_df[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['Diff'] = abs(test_df['LenBlast'] -test_df['Lenfeature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>LenBlast</th>\n",
       "      <th>Lenfeature</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pcontig_001</td>\n",
       "      <td>441768</td>\n",
       "      <td>443358</td>\n",
       "      <td>evm.TU.hcontig_001_123.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>+</td>\n",
       "      <td>pcontig_001</td>\n",
       "      <td>EVM</td>\n",
       "      <td>evm.TU.pcontig_001.110</td>\n",
       "      <td>441769</td>\n",
       "      <td>443359</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=evm.TU.pcontig_001.110;Name=EVM%20predictio...</td>\n",
       "      <td>1590</td>\n",
       "      <td>1590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1       2                         3    4  5  \\\n",
       "28  pcontig_001  441768  443358  evm.TU.hcontig_001_123.9  0.0  +   \n",
       "\n",
       "              6    7                       8       9      10 11 12 13  \\\n",
       "28  pcontig_001  EVM  evm.TU.pcontig_001.110  441769  443359  .  +  .   \n",
       "\n",
       "                                                   14  LenBlast  Lenfeature  \\\n",
       "28  ID=evm.TU.pcontig_001.110;Name=EVM%20predictio...      1590        1590   \n",
       "\n",
       "    Diff  \n",
       "28     0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['Diff'] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'e-value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2133\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2134\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'e-value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-be34a4117dc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e-value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e-value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode.chained_assignment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[1;32m--> 698\u001b[1;33m                                                    self.axis)\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m   1609\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-be34a4117dc1>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(g)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e-value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e-value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3543\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'e-value'"
     ]
    }
   ],
   "source": [
    "test_df.groupby(by=3).apply(lambda g: g[g['e-value'] == g['e-value'].min()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3079"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_besties_h_p_gene_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16797"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_besties_h_p_blast_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(pcontig_000:38121-38929)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_besties_h_p_gene_intersect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
