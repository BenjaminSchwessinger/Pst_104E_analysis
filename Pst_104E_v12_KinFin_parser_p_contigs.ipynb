{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a parser to get all annotations in a single file for kinfin analysis. Pull in files from the following two folders:\n",
    "\n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/pa_26062017\n",
    "and make a effector tablist for effectors into the same folder from\n",
    "\n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists\n",
    "\n",
    "The layout of functional annotation file is as follows.\n",
    "\n",
    " \\#protein_id GO IPR SignalP_EUK Pfam Effector Merops KEGG\n",
    "\n",
    "with the following characteriztics\n",
    "\n",
    "protein_id is simple the id used in clustering as well\n",
    "GO is a list of GO terms as GO:XX;GO:XX\n",
    "IPR is the ; sperated list of IPRterm:count for now this count will be one in all cases\n",
    "The same is true for all other categories as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import shutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = 'Pst_104E_v12_p_ctg'\n",
    "LIST_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists'\n",
    "ANNOTATION_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/pa_26062017'\n",
    "BASE_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "ASSEMBLY_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "KINFIN_FOLDER = os.path.join(BASE_FOLDER, 'KinFin')\n",
    "if not os.path.exists(KINFIN_FOLDER):\n",
    "    os.mkdir(KINFIN_FOLDER)\n",
    "#out file name for kinfin\n",
    "kinfin_out_fn = os.path.join(KINFIN_FOLDER, genome + '.functional_annotation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an initial dataframe that has the protein_id has index\n",
    "protein_fn = [os.path.join(ASSEMBLY_FOLDER, x) for x in os.listdir(ASSEMBLY_FOLDER) if genome in x\\\n",
    "             and  x.endswith('protein.fa')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now generate a list of ids and length\n",
    "protein_id_list = []\n",
    "protein_len_list = []\n",
    "for seq in SeqIO.parse(protein_fn, 'fasta'):\n",
    "    protein_id_list.append(seq.id)\n",
    "    protein_len_list.append(len(seq.seq))\n",
    "#make a dataframe out of it\n",
    "kinfin_fa_df = pd.concat([pd.Series(protein_id_list, name='#protein_id'),\\\n",
    "                          pd.Series(protein_len_list, name='protein_len')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the GO list and add to the dataframe\n",
    "GO_fn = [os.path.join(ANNOTATION_FOLDER, x) for x in os.listdir(ANNOTATION_FOLDER) \\\n",
    "        if x.startswith(genome) and x.endswith('GO_combined.tablist')][0]\n",
    "GO_df = pd.read_csv(GO_fn, header=None, sep='\\t', names=['#protein_id', 'GO'])\n",
    "#merge the GO_df and the kinfin_df\n",
    "kinfin_fa_df = pd.merge(kinfin_fa_df, GO_df, how='outer', on='#protein_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now pull in all the annotations list file names into a dictionary\n",
    "anno_keys = ['merops', 'Pfam', 'busco', 'iprscan', 'SignalP_EUK', 'dbCAN', 'KEGG_combined', 'OG']\n",
    "anno_fn_dict = {}\n",
    "for key in anno_keys:\n",
    "    anno_fn_dict[key] = [os.path.join(ANNOTATION_FOLDER, x) for x in os.listdir(ANNOTATION_FOLDER)\\\n",
    "                        if x.startswith(genome) and key in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kf_count(_comma_string):\n",
    "    \"\"\"\n",
    "    Quick function that confered a tablist ; seperated id list to a kinfin suitable occurance count.\n",
    "    \"\"\"\n",
    "    _list = _comma_string.split(';')\n",
    "    _dict = Counter(_list)\n",
    "    _new_string = ''\n",
    "    for x in _dict.keys():\n",
    "        _new_string = '%s;%s:%i'% (_new_string,x, _dict[x])\n",
    "    return _new_string[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now loop throught those anno_fn_dict and pull in the dataframes\n",
    "kinfin_fa_df\n",
    "for key in anno_keys:\n",
    "    #if key in ['merops', ]\n",
    "    column_id = key.upper()\n",
    "    tmp_df = pd.read_csv(anno_fn_dict[key], sep='\\t', header=None, names=['#protein_id', key])\n",
    "    #remove the \":\" which a left over from funnanotate\n",
    "    if \":\" in tmp_df.loc[0,key]:\n",
    "        tmp_df[column_id] = tmp_df[key].apply(lambda x: x[x.rindex(':')+1:])\n",
    "    else:\n",
    "        tmp_df[column_id] = tmp_df[key]\n",
    "    #transform the tablist to a counter list sperated by ':'\n",
    "    tmp_df[column_id] = tmp_df[column_id].apply(lambda x: kf_count(x))\n",
    "    kinfin_fa_df = pd.merge(kinfin_fa_df, tmp_df.loc[:, ['#protein_id', column_id]], how='outer', on=\"#protein_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fixes it for now. Now pull in the effector list and the haustoria expression list as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get haustoria expressed genes and effector genes (effectorP and in planta upregulated secreted genes)\n",
    "#for the primary contig cluster 15 is haustoria expressed in for the haplogtigs cluster 15\n",
    "p_effectorP_fn = os.path.join(LIST_FOLDER, 'Pst_104E_v12_p_effector.list')\n",
    "p_haustoria_fn = os.path.join(LIST_FOLDER, 'Pst_104E_v12_cluster_8.list')\n",
    "#now add the those to the dataframe\n",
    "p_effectorP_df = pd.read_csv(p_effectorP_fn, sep='\\t', header=None, names=['#protein_id'])\n",
    "p_effectorP_df['EFFECTOR'] = 'Effector:1'\n",
    "kinfin_fa_df = pd.merge(kinfin_fa_df, p_effectorP_df, how='outer', on=\"#protein_id\")\n",
    "#now add the haustoria expression\n",
    "p_haustoria_df = pd.read_csv(p_haustoria_fn, sep='\\t', header=None, names=['#protein_id'])\n",
    "p_haustoria_df[\"SHAUSTORIA\"] = 'Haustoria:1'\n",
    "kinfin_fa_df = pd.merge(kinfin_fa_df, p_haustoria_df, how='outer', on=\"#protein_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now write out two versions one with length included and one without\n",
    "kinfin_fa_df.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/KinFin/Pst_104E_v12_p_ctg.functional_annotation.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinfin_out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinfin_long_fn = kinfin_out_fn.replace('.txt', '_wlength.txt')\n",
    "kinfin_fa_df.to_csv(kinfin_long_fn, sep='\\t', index=None)\n",
    "#now write out kinfin version\n",
    "kinfin_fa_df.drop('protein_len', 1).to_csv(kinfin_out_fn, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#protein_id</th>\n",
       "      <th>GO</th>\n",
       "      <th>MEROPS</th>\n",
       "      <th>PFAM</th>\n",
       "      <th>BUSCO</th>\n",
       "      <th>IPRSCAN</th>\n",
       "      <th>SIGNALP_EUK</th>\n",
       "      <th>DBCAN</th>\n",
       "      <th>KEGG_COMBINED</th>\n",
       "      <th>OG</th>\n",
       "      <th>EFFECTOR</th>\n",
       "      <th>SHAUSTORIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evm.model.pcontig_041.101</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0ZGCE@NOG:1;0JJMJ@euNOG:1;14B0R@opiNOG:1;095NX...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evm.model.pcontig_018.256</td>\n",
       "      <td>GO:0000271;GO:0003674;GO:0003824;GO:0004610;GO...</td>\n",
       "      <td>None</td>\n",
       "      <td>PF00408:1;PF02878:1</td>\n",
       "      <td>EOG092R06LD:1</td>\n",
       "      <td>IPR005843:3;IPR005844:1;IPR016657:2;IPR016066:...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>map01110:1;map00520:1</td>\n",
       "      <td>COG1109@NOG:1;KOG2537@euNOG:1;0PHNA@fuNOG:1;09...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evm.model.pcontig_018.216</td>\n",
       "      <td>GO:0000003;GO:0003006;GO:0005575;GO:0005622;GO...</td>\n",
       "      <td>None</td>\n",
       "      <td>PF03635:1</td>\n",
       "      <td>EOG092R022P:1</td>\n",
       "      <td>IPR005378:5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0XNXC@NOG:1;0PGCB@fuNOG:1;12NYE@opiNOG:1;KOG11...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evm.model.pcontig_014.344</td>\n",
       "      <td>GO:0004190;GO:0006508</td>\n",
       "      <td>None</td>\n",
       "      <td>PF00077:1</td>\n",
       "      <td>None</td>\n",
       "      <td>IPR001969:1;IPR021109:2;IPR001995:1;IPR018061:1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>COG2801@NOG:1;KOG0017@euNOG:1;13IVJ@opiNOG:1;0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evm.model.pcontig_022.278</td>\n",
       "      <td>GO:0000086;GO:0000166;GO:0000278;GO:0000322;GO...</td>\n",
       "      <td>None</td>\n",
       "      <td>PF00069:1;PF16579:1</td>\n",
       "      <td>None</td>\n",
       "      <td>IPR032270:1;IPR011009:1;IPR000719:3;IPR008271:...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>map04151:1;map04150:1;map04113:1</td>\n",
       "      <td>0PGMD@fuNOG:1;0927K@basNOG:1;KOG0586@euNOG:1;0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 #protein_id  \\\n",
       "0  evm.model.pcontig_041.101   \n",
       "1  evm.model.pcontig_018.256   \n",
       "2  evm.model.pcontig_018.216   \n",
       "3  evm.model.pcontig_014.344   \n",
       "4  evm.model.pcontig_022.278   \n",
       "\n",
       "                                                  GO MEROPS  \\\n",
       "0                                               None   None   \n",
       "1  GO:0000271;GO:0003674;GO:0003824;GO:0004610;GO...   None   \n",
       "2  GO:0000003;GO:0003006;GO:0005575;GO:0005622;GO...   None   \n",
       "3                              GO:0004190;GO:0006508   None   \n",
       "4  GO:0000086;GO:0000166;GO:0000278;GO:0000322;GO...   None   \n",
       "\n",
       "                  PFAM          BUSCO  \\\n",
       "0                 None           None   \n",
       "1  PF00408:1;PF02878:1  EOG092R06LD:1   \n",
       "2            PF03635:1  EOG092R022P:1   \n",
       "3            PF00077:1           None   \n",
       "4  PF00069:1;PF16579:1           None   \n",
       "\n",
       "                                             IPRSCAN SIGNALP_EUK DBCAN  \\\n",
       "0                                               None        None  None   \n",
       "1  IPR005843:3;IPR005844:1;IPR016657:2;IPR016066:...        None  None   \n",
       "2                                        IPR005378:5        None  None   \n",
       "3    IPR001969:1;IPR021109:2;IPR001995:1;IPR018061:1        None  None   \n",
       "4  IPR032270:1;IPR011009:1;IPR000719:3;IPR008271:...        None  None   \n",
       "\n",
       "                      KEGG_COMBINED  \\\n",
       "0                              None   \n",
       "1             map01110:1;map00520:1   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4  map04151:1;map04150:1;map04113:1   \n",
       "\n",
       "                                                  OG EFFECTOR SHAUSTORIA  \n",
       "0  0ZGCE@NOG:1;0JJMJ@euNOG:1;14B0R@opiNOG:1;095NX...     None       None  \n",
       "1  COG1109@NOG:1;KOG2537@euNOG:1;0PHNA@fuNOG:1;09...     None       None  \n",
       "2  0XNXC@NOG:1;0PGCB@fuNOG:1;12NYE@opiNOG:1;KOG11...     None       None  \n",
       "3  COG2801@NOG:1;KOG0017@euNOG:1;13IVJ@opiNOG:1;0...     None       None  \n",
       "4  0PGMD@fuNOG:1;0927K@basNOG:1;KOG0586@euNOG:1;0...     None       None  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinfin_fa_df.drop('protein_len', 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.rindex(':')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinfin_fa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p_genome = 'Pst_104E_v12_h_ctg'\n",
    "OUT_PATH_P = os.path.join(OUT_PATH, p_genome)\n",
    "if not os.path.exists(OUT_PATH_P):\n",
    "    os.mkdir(OUT_PATH_P)\n",
    "#that is the path for all the proteins without removing the high coverage contigs and the proteins w/ \n",
    "#similarities to TE proteins\n",
    "OUT_PATH_P_ALL = os.path.join(OUT_PATH_P, 'ALL')\n",
    "if not os.path.exists(OUT_PATH_P_ALL):\n",
    "    os.mkdir(OUT_PATH_P_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all proteins that are in the final assembly\n",
    "p_protein_list = []\n",
    "protein_fa_file = [x for x in os.listdir(BASE_A_PATH) if p_genome in x and x.endswith('anno.protein.fa')][0]\n",
    "for protein in SeqIO.parse(os.path.join(BASE_A_PATH, protein_fa_file) , 'fasta'):\n",
    "    p_protein_list.append(protein.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_header = 'query_name seed_eggNOG_ortholog seed_ortholog_evalue seed_ortholog_score predicted_gene_name \\\n",
    "GO_terms KEGG_pathways Annotation_tax_scope OGs bestOG|evalue|score COG cat eggNOG annot'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df = pd.read_csv(os.path.join(BASE_FOLDER, EGGNOG_BLAST_FILE), sep ='\\t', header=None, names=eggnog_blast_header, skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df.fillna(0, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pick all annotation columns. One at a time and write them out as tab file or annotations files. The later can be used\n",
    "#to annotate gff files using gag.py\n",
    "DBs = [x for x in eggnog_blast_df.columns.tolist()[4:] if x not in ['GO_terms','KEGG_pathways', 'OGs' ] ]\n",
    "eggnog_blast_df['note'] = 'note'\n",
    "for db in DBs:\n",
    "    if len(eggnog_blast_df[eggnog_blast_df[db] !=0]) > 0:\n",
    "        eggnog_blast_df[eggnog_blast_df[db] !=0].loc[:,['query_name',db]]\\\n",
    "        .to_csv(os.path.join(OUT_PATH, db+'_terms.tab'), sep='\\t', header =None, index = None)\n",
    "        eggnog_blast_df[eggnog_blast_df[db] !=0].loc[:,['query_name', 'note', db]]\\\n",
    "        .to_csv(os.path.join(OUT_PATH, 'annotations.' +db+'.txt'), sep='\\t', header =None, index = None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dict = {}\n",
    "eggnog_blast_df['GO_terms'] = eggnog_blast_df.GO_terms.str.split(',')\n",
    "\n",
    "eggnog_blast_df[eggnog_blast_df['GO_terms'] != 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df['GO_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process the pathway files\n",
    "interpro_by_protein_KEGG = interpro_df[interpro_df.Pathway_IDs.str.contains('KEGG' or 'MetaCyc' or 'Reactome').fillna(False)]\n",
    "\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG.groupby('Updated_Protein_ID')\n",
    "\n",
    "#pull out all the KEGG terms and write them out as annotation files \n",
    "interpro_by_protein_KEGG = interpro_by_protein.Pathway_IDs.apply(set)\n",
    "\n",
    "#remove everything without KEGG term attached\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG[~(interpro_by_protein_KEGG == {0})]\n",
    "\n",
    "interpro_by_protein_KEGG_dict = dict(zip(interpro_by_protein_KEGG.index, interpro_by_protein_KEGG))\n",
    "\n",
    "ALL_KEGG_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_KEGG_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_KEGG_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_KEGG_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "KEGG_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_KEGG_LIST]).T\n",
    "KEGG_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "KEGG_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'Pathway_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'Pathway_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "KEGG_df['Transfer_ID'] = 'note'\n",
    "KEGG_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.Pathway_all.txt') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.Pathway.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all the GO terms and write them out as annotation files \n",
    "interpro_by_protein_GO = interpro_by_protein.GO_terms.apply(set)\n",
    "\n",
    "#remove everything without GO term attached\n",
    "interpro_by_protein_GO = interpro_by_protein_GO[~(interpro_by_protein_GO == {0})]\n",
    "\n",
    "interpro_by_protein_GO_dict = dict(zip(interpro_by_protein_GO.index, interpro_by_protein_GO))\n",
    "\n",
    "ALL_GO_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_GO_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_GO_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_GO_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "GO_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_GO_LIST]).T\n",
    "GO_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "GO_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'GO_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'GO_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "GO_df['Transfer_ID'] = 'note'\n",
    "GO_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.GO_all.txt') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.GO.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out other annotations files including busco, dbCAN, merops, swissprot\n",
    "annotation_files = [os.path.join(ANNOTATION_FILE_BASE_PATH, x) for x in os.listdir(ANNOTATION_FILE_BASE_PATH) \\\n",
    "                    if x.startswith('annotations') and (x.endswith('busco.txt') or x.endswith('dbCAN.txt') or x.endswith('merops.txt') or x.endswith('swissprot.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for anno in annotation_files:\n",
    "    _tmp_df = pd.read_csv(anno, header=None, sep='\\t', names=['Protein_ID','Transfer_ID', 'DB_ID'])\n",
    "    anno_file_name = anno.split('/')[-1]\n",
    "    anno_midfix = anno_file_name.split('.')[1]\n",
    "    _tmp_df['Updated_Protein_ID'] = protein_id_conversion(_tmp_df)\n",
    "    #write out filtered down tab file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P, anno_midfix+'_terms.tab'), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].\\\n",
    "    to_csv(os.path.join(OUT_PATH_P, anno_file_name ), sep = '\\t', header =None, index=None)\n",
    "     #write out not down tab file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_midfix+'_terms_all.tab' ), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_file_name.replace('.txt', '_all.txt') ), sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
