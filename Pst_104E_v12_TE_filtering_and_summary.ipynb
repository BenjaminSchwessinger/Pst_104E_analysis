{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SearchIO\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import multiprocessing\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome = 'Pst_104E_v12_p_ctg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/TE_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove all commenting lines from the initial repet file\n",
    "!grep -v \"^#\" {source_dir}/{genome}.REPET.gff > {out_dir}/{genome}.REPET.gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff = pd.read_csv(out_dir+'/'+genome+'.REPET.gff', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/REPET/Pst79_p/Pst79_p_full_annotate/postanalysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = 'TE      length  covg    frags   fullLgthFrags   copies  fullLgthCopies  meanId  sdId    minId   q25Id   medId   q75Id   maxId   meanLgth        sdLgth  minLgth q25Lgth medLgth q75Lgth maxLgth meanLgthPerc    sdLgthPerc      minLgthPerc  q25LgthPerc     medLgthPerc     q75LgthPerc     maxLgthPerc'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = [x for x in TE_post_analysis_p_header if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this needs to be fixed up to pick the proper summary table\n",
    "p_repet_summary_df = pd.read_csv(TE_post_analysis_p+'/'+'Pst79p_anno_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' ,\\\n",
    "                                names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#check if I can filter the tab files for removing all TEs that are on the 2000 plus contigs\n",
    "#remove tRNAs TEs with infernal\n",
    "\n",
    "p_repet_summary_df['Code'] = p_repet_summary_df['TE'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "code_keys = p_repet_summary_df['Code'].unique()\n",
    "\n",
    "code_keys.sort()\n",
    "\n",
    "code_long = ['DNA_transposon Helitron', 'DNA_transposon Helitron', 'DNA_transposon Helitron', 'DNA_transposon Maverick',\\\n",
    "            'DNA_transposon TIR', 'DNA_transposon TIR', 'DNA_transposon TIR', 'DNA_transposon TIR', 'DNA_transposon noCat',\\\n",
    "             'DNA_transposon MITE','DNA_transposon MITE', 'Potential Host Gene', 'Retrotransposon LINE', 'Retrotransposon LINE',\\\n",
    "             'Retrotransposon LINE','Retrotransposon LTR','Retrotransposon LTR', 'Retrotransposon LTR', 'Retrotransposon LTR', 'Retrotransposon PLE', \\\n",
    "             'Retrotransposon SINE',  'Retrotransposon SINE', 'Retrotransposon noCat', 'Retrotransposon LARD',\\\n",
    "             'Retrotransposon LARD', 'Retrotransposon TRIM', 'Retrotransposon TRIM', 'Retrotransposon noCat',  \\\n",
    "             'Retrotransposon DIRS','Retrotransposon DIRS','Retrotransposon DIRS','Retrotransposon DIRS',\\\n",
    "             'noCat', 'noCat']\n",
    "\n",
    "code_dict = dict(zip(code_keys, code_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copies</th>\n",
       "      <th>covg</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code long</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Helitron</th>\n",
       "      <td>1075</td>\n",
       "      <td>817566</td>\n",
       "      <td>2989.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon MITE</th>\n",
       "      <td>3789</td>\n",
       "      <td>886304</td>\n",
       "      <td>490.240741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Maverick</th>\n",
       "      <td>268</td>\n",
       "      <td>345406</td>\n",
       "      <td>8562.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon TIR</th>\n",
       "      <td>19166</td>\n",
       "      <td>12711595</td>\n",
       "      <td>4020.474359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon noCat</th>\n",
       "      <td>5286</td>\n",
       "      <td>2376456</td>\n",
       "      <td>3034.734513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potential Host Gene</th>\n",
       "      <td>1372</td>\n",
       "      <td>1375304</td>\n",
       "      <td>6120.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon DIRS</th>\n",
       "      <td>1337</td>\n",
       "      <td>1049299</td>\n",
       "      <td>6874.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LARD</th>\n",
       "      <td>10752</td>\n",
       "      <td>4947564</td>\n",
       "      <td>5407.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LINE</th>\n",
       "      <td>323</td>\n",
       "      <td>237992</td>\n",
       "      <td>4446.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LTR</th>\n",
       "      <td>18893</td>\n",
       "      <td>16276421</td>\n",
       "      <td>6384.627841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon PLE</th>\n",
       "      <td>75</td>\n",
       "      <td>41843</td>\n",
       "      <td>8954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon SINE</th>\n",
       "      <td>163</td>\n",
       "      <td>31138</td>\n",
       "      <td>317.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon TRIM</th>\n",
       "      <td>507</td>\n",
       "      <td>238695</td>\n",
       "      <td>1583.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon noCat</th>\n",
       "      <td>112</td>\n",
       "      <td>101098</td>\n",
       "      <td>4365.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noCat</th>\n",
       "      <td>1218</td>\n",
       "      <td>850828</td>\n",
       "      <td>1679.829268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         copies      covg       length\n",
       "Code long                                             \n",
       "DNA_transposon Helitron    1075    817566  2989.764706\n",
       "DNA_transposon MITE        3789    886304   490.240741\n",
       "DNA_transposon Maverick     268    345406  8562.666667\n",
       "DNA_transposon TIR        19166  12711595  4020.474359\n",
       "DNA_transposon noCat       5286   2376456  3034.734513\n",
       "Potential Host Gene        1372   1375304  6120.490566\n",
       "Retrotransposon DIRS       1337   1049299  6874.526316\n",
       "Retrotransposon LARD      10752   4947564  5407.736111\n",
       "Retrotransposon LINE        323    237992  4446.625000\n",
       "Retrotransposon LTR       18893  16276421  6384.627841\n",
       "Retrotransposon PLE          75     41843  8954.000000\n",
       "Retrotransposon SINE        163     31138   317.923077\n",
       "Retrotransposon TRIM        507    238695  1583.434783\n",
       "Retrotransposon noCat       112    101098  4365.857143\n",
       "noCat                      1218    850828  1679.829268"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_repet_summary_df['Code long'] = p_repet_summary_df['Code'].apply(lambda x: code_dict[x])\n",
    "\n",
    "p_repet_summary_sum_df = pd.pivot_table(p_repet_summary_df, values=['covg', 'copies'], index='Code long', aggfunc=np.sum)\n",
    "\n",
    "p_repet_summary_mean_df = pd.pivot_table(p_repet_summary_df, values='length', index='Code long', aggfunc=np.mean)\n",
    "\n",
    "pd.concat([p_repet_summary_sum_df,p_repet_summary_mean_df], axis=1 )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p_repet_gff needs to be filtered to remove all the the high coverage contigs and such\n",
    "the filters are located in this folder\n",
    "/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now filter the gff dataframe to delete all the high coverage contigs\n",
    "#This might would have to be fixed as well. If we don't delete it as files should be already filtered\n",
    "contigs_smaller_2000 = pd.read_csv('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly/pcontig_smaller_2000.txt',\\\n",
    "                                  header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered = p_repet_gff[p_repet_gff[0].isin(contigs_smaller_2000)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ID_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out the top level id form the 9th gff column form a REPET gff file.\n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "\n",
    "        TE_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9,-]*)_'\n",
    "        TE_prog = re.compile(TE_pattern)\n",
    "        TE_match = TE_prog.search(_id)\n",
    "        return TE_match.group(1)\n",
    "    if _type == 'REPET_SSRs':\n",
    "        \n",
    "        SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "        SSR_prog = re.compile(SSR_pattern)\n",
    "        SSR_match = SSR_prog.search(_id)\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        #if \"#\" in _id:\n",
    "        #     blast_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*[_]?[A-Z,a-z,0-9,-]*[_|#|0-9]+?:[A-Z,a-z,0-9,-,:]*)'\n",
    "        #else:\n",
    "        #    blast_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([\\w+|:|-]*)'\n",
    "        blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([^;| ]*)')\n",
    "        #blast_prog = re.compile(blast_pattern)\n",
    "        blast_match = blast_prog.search(_id)\n",
    "        return blast_match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered['ID'] = p_repet_gff_filtered.apply(lambda row: ID_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter out potential host genes\n",
    "p_repet_gff_filtered = p_repet_gff_filtered[~p_repet_gff_filtered[8].str.contains(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_unique_REs = len(p_repet_gff_filtered['ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of unique repetitive elements: 48659\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of unique repetitive elements: %i' % num_unique_REs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequency_of_REs  = p_repet_gff_filtered.groupby('ID')[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequency_of_REs.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered.to_csv(out_dir+'/'+genome+'.REPET.filtered.gff', sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered[8] = p_repet_gff_filtered['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2 = p_repet_gff_filtered.iloc[:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2.to_csv(out_dir+'/'+genome+'.REPET.ID_column.gff', sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#have another dataframe that only contains the REPET denovo annotation and not blast hits\n",
    "#repet_gff_filtered_TEs = p_repet_gff_filtered_2[~p_repet_gff_filtered_2[1].str.contains('blast')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the 'Code' phrases blast hits and make a blast_code_dict\n",
    "#this needs to get the subsetting filters set for different dataframes\n",
    "\n",
    "blast_codes = p_repet_gff_filtered_2[(p_repet_gff_filtered_2[1]=='Pst79p_anno_REPET_tblastx') | (p_repet_gff_filtered_2[1]=='Pst79p_anno_REPET_blastx')][8]\n",
    "\n",
    "blast_codes_list = [ ':'.join(x.split(':')[1:-1]) for x in blast_codes.unique()]\n",
    "\n",
    "blast_codes_list_unique = list(set(blast_codes_list))\n",
    "\n",
    "blast_codes_list_unique.sort()\n",
    "\n",
    "blast_codes_list_unique\n",
    "\n",
    "blast_code_long = ['Retrotransposon noCat', 'Retrotransposon DIRS', 'Retrotransposon LINE', 'Retrotransposon LTR', 'Retrotransposon PLE','DNA_transposon noCat',\\\n",
    "                   'DNA_transposon Crypton','DNA_transposon Helitron','DNA_transposon Maverick','DNA_transposon TIR']\n",
    "\n",
    "blast_code_dict = dict(zip(blast_codes_list_unique, blast_code_long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClassI:?': 'Retrotransposon noCat',\n",
       " 'ClassI:DIRS': 'Retrotransposon DIRS',\n",
       " 'ClassI:LINE': 'Retrotransposon LINE',\n",
       " 'ClassI:LTR': 'Retrotransposon LTR',\n",
       " 'ClassI:PLE': 'Retrotransposon PLE',\n",
       " 'ClassII:?': 'DNA_transposon noCat',\n",
       " 'ClassII:Crypton': 'DNA_transposon Crypton',\n",
       " 'ClassII:Helitron': 'DNA_transposon Helitron',\n",
       " 'ClassII:Maverick': 'DNA_transposon Maverick',\n",
       " 'ClassII:TIR': 'DNA_transposon TIR'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blast_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a filer function that adds a 'code long'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def code_long_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out Order and class of the TE based on Wicker et al. using the previously generated ID column. \n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        #split the \n",
    "        code = _id.split('_')[0]\n",
    "        return code_dict[code]\n",
    "    if _type == 'REPET_SSRs':\n",
    "        return 'SSR'\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        code = ':'.join(_id.split(':')[1:-1])\n",
    "        return blast_code_dict[code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2['Classification'] = p_repet_gff_filtered_2.apply(lambda row: code_long_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DNA_transposon TIR', 'Retrotransposon DIRS', 'Retrotransposon LTR',\n",
       "       'SSR', 'DNA_transposon noCat', 'DNA_transposon MITE',\n",
       "       'Retrotransposon LARD', 'Retrotransposon SINE', 'noCat',\n",
       "       'DNA_transposon Helitron', 'DNA_transposon Maverick',\n",
       "       'Retrotransposon LINE', 'Retrotransposon TRIM',\n",
       "       'Retrotransposon noCat', 'Retrotransposon PLE',\n",
       "       'DNA_transposon Crypton'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_repet_gff_filtered_2[\"Classification\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#in the .classificaiton gff the feature column 2 is the Wicker classification of the transposon\n",
    "p_repet_gff_filtered_2[8] = p_repet_gff_filtered_2['Classification'] \n",
    "#repet_gff_filtered_TEs[1] = repet_gff_filtered_TEs[\"Classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2.iloc[:,:-1].to_csv(out_dir+'/'+genome+'.REPET.classification.gff', sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the no_blast hit REPET gff as well.\n",
    "p_repet_gff_filtered_2[~p_repet_gff_filtered_2[1].str.contains('blast')].iloc[:,:-1].to_csv(out_dir+'/'+genome+'.REPET_noblast.classification.gff', sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a similar filter as before using bedtools to move through all the classifications and caclulate coverage\n",
    "#summarize this in a table and compare to published stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the directory structure to safe specific coverage files\n",
    "os.chdir(out_dir)\n",
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))\n",
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repet_prefix = genome+'.REPET.classification'\n",
    "p_genome_file = genome+'.genome_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter_classification(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id_classification(_id, bed_object):\n",
    "    #retrotransposon \n",
    "    if 'Retrotransposon' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #DNA_transponson\n",
    "    elif 'DNA_transposon' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #notCat \n",
    "    elif 'noCat' in _id:\n",
    "        out_path = TE_path_dict['noCat']\n",
    "    #SSR\n",
    "    elif 'SSR' in _id:\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    repet_prefix = genome+ '.'+bed_object.fn.split('.')[-3] + '.classification'\n",
    "    out_fn = out_path+'/'+repet_prefix+'.'+_id+'.gff'\n",
    "    out_fn= out_fn.replace(\" \", '_')\n",
    "    result = bed_object.filter(id_filter_classification, _id).saveas(out_fn)\n",
    "    cov_fn = out_fn.replace('gff','cov')\n",
    "    cov = result.genome_coverage(dz=True,g=p_genome_file)\n",
    "    cov.saveas(cov_fn)\n",
    "    print(\"Done with %s using %s as bedfile \" % (out_fn.split('/')[-1], g.fn.split('/')[-1]))\n",
    "    #return pybedtools.BedTool(result.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pull in the classification gff, make classification array, loop over array to save all the cov_dataframes\n",
    "RE_id_gff = pybedtools.BedTool(out_dir+'/'+genome+'.REPET.classification.gff')\n",
    "g = RE_id_gff.remove_invalid().saveas(out_dir+'/'+genome+'.REPET.classification.bedobject')\n",
    "#use the blast filtered dataframe as well\n",
    "RE_id_gff_noblast = pybedtools.BedTool(out_dir+'/'+genome+'.REPET_noblast.classification.gff')\n",
    "g_noblast = RE_id_gff_noblast.remove_invalid().saveas(out_dir+'/'+genome+'.REPET_noblast.classification.bedobject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter through the whole REPET_TE bedobject\n",
    "#maybe make some multiproccesses out of this\n",
    "classifications = p_repet_gff_filtered_2[\"Classification\"].unique()\n",
    "#[subset_id_classification(x, g) for x in classifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-1.exitcode = None\n",
      "Process-2.exitcode = None\n",
      "Process-3.exitcode = None\n",
      "Process-4.exitcode = None\n",
      "Process-5.exitcode = None\n",
      "Process-6.exitcode = None\n",
      "Process-7.exitcode = None\n",
      "Process-8.exitcode = None\n",
      "Process-9.exitcode = None\n",
      "Process-10.exitcode = None\n",
      "Process-11.exitcode = None\n",
      "Process-12.exitcode = None\n",
      "Process-13.exitcode = None\n",
      "Process-14.exitcode = None\n",
      "Process-15.exitcode = None\n",
      "Process-16.exitcode = None\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_SINE.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_Crypton.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_PLE.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_noCat.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_TRIM.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_LINE.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_Maverick.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_MITE.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.noCat.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_Helitron.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_DIRS.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.SSR.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_noCat.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_LARD.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.DNA_transposon_TIR.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "Done with Pst_104E_v12_p_ctg.REPET.classification.Retrotransposon_LTR.gff using Pst_104E_v12_p_ctg.REPET.classification.bedobject as bedfile \n",
      "Waiting for Subset_id_classification to finish!\n",
      "All Subset_id_classifications done!\n"
     ]
    }
   ],
   "source": [
    "#use multiprocessing to do the bedcov genome coverage per classification. Keep track if everything is already done.\n",
    "jobs = []\n",
    "bed_file = g\n",
    "for classi in classifications:\n",
    "    p = multiprocessing.Process(target=subset_id_classification, args=(classi, bed_file,))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "while set([j.is_alive() for j in jobs]) != {False}:\n",
    "    time.sleep(15)\n",
    "    print(\"Waiting for Subset_id_classification to finish!\")\n",
    "print(\"All Subset_id_classifications done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-1.exitcode = 0\n",
      "Process-2.exitcode = 0\n",
      "Process-3.exitcode = 0\n",
      "Process-4.exitcode = 0\n",
      "Process-5.exitcode = 0\n",
      "Process-6.exitcode = 0\n",
      "Process-7.exitcode = 0\n",
      "Process-8.exitcode = 0\n",
      "Process-9.exitcode = 0\n",
      "Process-10.exitcode = 0\n",
      "Process-11.exitcode = 0\n",
      "Process-12.exitcode = 0\n",
      "Process-13.exitcode = 0\n",
      "Process-14.exitcode = 0\n",
      "Process-15.exitcode = 0\n",
      "Process-16.exitcode = 0\n"
     ]
    }
   ],
   "source": [
    "#print out the exitcodes for each\n",
    "for j in jobs:\n",
    "    #j.join()\n",
    "    print('%s.exitcode = %s' % (j.name, j.exitcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([ x for x in zip(classifications,bed_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in jobs:\n",
    "    #j.join()\n",
    "    print('%s.exitcode = %s' % (j.name, j.exitcode))\n",
    "#while set([j.is_alive() for j in jobs]) != {False}:\n",
    "    #time.sleep(15)\n",
    "    #print(\"Waiting for Subset_id_classification to finish!\")\n",
    "print(\"All Subset_id_classifications done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter through the whole REPET_TE bedobject having removed the blast hits\n",
    "#maybe make some multiproccesses out of this\n",
    "classifications_noblast = p_repet_gff_filtered_2[~p_repet_gff_filtered_2[1].str.contains('blast')][\"Classification\"].unique()\n",
    "[subset_id_classification(x, g_noblast) for x in classifications_noblast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.abspath(os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome_df = pd.read_csv(p_genome_file, sep='\\t', header=None,names=['contig', 'length'])\n",
    "\n",
    "genome_size = genome_df['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this caputures all REPET classifications including blast and internal REPET_TEs\n",
    "#the problem found here is that the blast and the REPET annotation is sometimes contratictory and overlapping\n",
    "class_cov_files = []\n",
    "for dirpath, dirname, filenames in os.walk(cur_dir):\n",
    "    #print(dirpath)\n",
    "    #print(len(filenames))\n",
    "    if len(filenames) == 0:  # empty folder\n",
    "        continue\n",
    "    cov_files = [dirpath +'/'+x for x in filenames if x.endswith('.cov') and 'REPET.classification' in x]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Code long\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True)\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])\n",
    "\n",
    "df_REPET_classification = pd.concat(df_list)\n",
    "\n",
    "cov_per_class = df_REPET_classification.pivot_table(values=1, columns= 'Code long', aggfunc='count')\n",
    "cov_per_contig_per_class = df_REPET_classification.groupby([0, 'Code long'])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this caputures all REPET classifications including internal REPET_TEs classification only. No blast hits included\n",
    "class_cov_files = []\n",
    "for dirpath, dirname, filenames in os.walk(cur_dir):\n",
    "    #print(dirpath)\n",
    "    #print(len(filenames))\n",
    "    if len(filenames) == 0:  # empty folder\n",
    "        continue\n",
    "    cov_files = [dirpath +'/'+x for x in filenames if x.endswith('.cov') and 'REPET_noblast.classification' in x ]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Code long\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True)\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])\n",
    "\n",
    "df_REPET_noblast_classification = pd.concat(df_list)\n",
    "\n",
    "cov_per_class_noblast = df_REPET_noblast_classification.pivot_table(values=1, columns= 'Code long', aggfunc='count')\n",
    "cov_per_contig_per_class_noblast = df_REPET_noblast_classification.groupby([0, 'Code long'])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_per_class/genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_per_class_noblast/genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(cov_per_class/genome_size*100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(cov_per_class_noblast/genome_size*100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_REPET_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_REPET_noblast_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_REPET_noblast_classification.drop_duplicates([0,1]))/genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = p_repet_gff_filtered_2[~p_repet_gff_filtered_2[1].str.contains('blast')].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[(test[0]== 'pcontig_000' )&(test[3] < 20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_values([0,3],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_REPET_noblast_classification.sort_values([0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_REPET_noblast_classification[df_REPET_noblast_classification.duplicated([0,1], keep=False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_REPET_classification.drop_duplicates(subset=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_REPET_classification.sort_values([0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_REPET_classification_dup = df_REPET_classification[df_REPET_classification.duplicated(subset=[0,1], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2[(p_repet_gff_filtered_2[0] ==  'pcontig_000')&(p_repet_gff_filtered_2[3] < 14602)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered_2[(p_repet_gff_filtered_2[0] ==  'pcontig_000')&(p_repet_gff_filtered_2[3] < 20000)].sort_values(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_REPET_classification_dup.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "45267875/ genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head 'Pst_104E_v12_p_ctg.REPET.ID_column.cov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RE_id_gff = pybedtools.BedTool(out_dir+'/'+genome+'.REPET.ID_column.gff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repet_gff = 'Pst_104E_v12_p_ctg.REPET.gff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repet_prefix = '.'.join(repet_gff.split('.')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = RE_id_gff.remove_invalid().saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id(_id):\n",
    "    #ClassI are retrotransposon form blast\n",
    "    if 'ClassI:' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #ClassII are DNA_transponson\n",
    "    elif 'ClassII' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #The rest with '_' should be REPET_TEs\n",
    "    elif _id.split('_')[0] in list(code_dict.keys()):\n",
    "        key = code_dict[_id.split('_')[0]].split(' ')[0]\n",
    "        out_path = TE_path_dict[key]\n",
    "    #everything without '_' at the end should be SSR\n",
    "    elif '_' not in _id:\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    out_fn = out_path+'/'+repet_prefix+'.'+_id+'.gff'\n",
    "    result = g.filter(id_filter, _id).saveas(out_fn)\n",
    "    cov_fn = out_fn.replace('gff','cov')\n",
    "    cov = result.genome_coverage(dz=True,g=p_genome_file)\n",
    "    cov.saveas(cov_fn)\n",
    "    #return pybedtools.BedTool(result.fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a loop that takes in the filtered id'ed gff file, filters the file according to the id field. The corresponding bedfile is saved in a specific folder for the type of TE (RNA, DNA, SSR, noCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_id = frequency_of_REs.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is REALLY slow for now. Would need to parallize this step. Look at the pool function of \n",
    "#multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[subset_id(x) for x in _id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_path_list[0].replace('gff','cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_test_id = _id[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = RE_id_gff.remove_invalid().saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in _test_id if '_' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_genome_file = 'Pst_104E_v12_p_ctg.genome_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cov_RE = g.genome_coverage(dz=True,g=p_genome_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cov_RE.saveas('Pst_104E_v12_p_ctg.REPET.ID_column.cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff_filtered[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in p_repet_gff_filtered_2[(p_repet_gff_filtered_2[1] == 'Pst79p_anno_REPET_TE')  ][8].unique() if '_' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in p_repet_gff_filtered_2[(p_repet_gff_filtered_2[1] == 'Pst79p_anno_REPET_tblastx') | (p_repet_gff_filtered_2[1] == 'Pst79p_anno_REPET_blastx') ][8].unique() if '_' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_repet_gff[p_repet_gff[8].str.contains('Copia6-VV_I_')][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
