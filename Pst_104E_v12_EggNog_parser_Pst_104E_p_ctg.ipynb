{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to read in the annotation file of emapper.py and pull out the annotations.\n",
    "This was run like:\n",
    "/home/benjamin/anaconda3/envs/funannotate/eggnog-mapper-0.99.2/emapper.py -i /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly/Pst_104E_v12_h_ctg.anno.protein.fa -d euk --output Pst_104E_v12_h_ctg --cpu 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/protein_annotation/Pst_104E_v12_h_ctg/eggnog-mapper'\n",
    "EGGNOG_BLAST_FILE = 'Pst_104E_v12_h_ctg.emapper.annotations'\n",
    "EGGNOG_DIAMON_FILE = 'Pst_104E_v12_h_ctg_diamond.emapper.annotations'\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "p_genome = 'Pst_104E_v12_h_ctg'\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'protein_annotation',p_genome, 'eggnog-mapper', 'parsed')\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "p_genome = 'Pst_104E_v12_h_ctg'\n",
    "OUT_PATH_P = os.path.join(OUT_PATH, p_genome)\n",
    "if not os.path.exists(OUT_PATH_P):\n",
    "    os.mkdir(OUT_PATH_P)\n",
    "#that is the path for all the proteins without removing the high coverage contigs and the proteins w/ \n",
    "#similarities to TE proteins\n",
    "OUT_PATH_P_ALL = os.path.join(OUT_PATH_P, 'ALL')\n",
    "if not os.path.exists(OUT_PATH_P_ALL):\n",
    "    os.mkdir(OUT_PATH_P_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pull out all proteins that are in the final assembly\n",
    "p_protein_list = []\n",
    "protein_fa_file = [x for x in os.listdir(BASE_A_PATH) if p_genome in x and x.endswith('anno.protein.fa')][0]\n",
    "for protein in SeqIO.parse(os.path.join(BASE_A_PATH, protein_fa_file) , 'fasta'):\n",
    "    p_protein_list.append(protein.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eggnog_blast_header = 'query_name seed_eggNOG_ortholog seed_ortholog_evalue seed_ortholog_score predicted_gene_name \\\n",
    "GO_terms KEGG_pathways Annotation_tax_scope OGs bestOG|evalue|score COG cat eggNOG annot'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query_name',\n",
       " 'seed_eggNOG_ortholog',\n",
       " 'seed_ortholog_evalue',\n",
       " 'seed_ortholog_score',\n",
       " 'predicted_gene_name',\n",
       " 'GO_terms',\n",
       " 'KEGG_pathways',\n",
       " 'Annotation_tax_scope',\n",
       " 'OGs',\n",
       " 'bestOG|evalue|score',\n",
       " 'COG',\n",
       " 'cat',\n",
       " 'eggNOG',\n",
       " 'annot']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggnog_blast_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/protein_annotation/Pst_104E_v12_h_ctg/eggnog-mapper/Pst_104E_v12_h_ctg.emapper.annotations' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-09d76c07a1c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meggnog_blast_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBASE_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEGGNOG_BLAST_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meggnog_blast_header\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/protein_annotation/Pst_104E_v12_h_ctg/eggnog-mapper/Pst_104E_v12_h_ctg.emapper.annotations' does not exist"
     ]
    }
   ],
   "source": [
    "eggnog_blast_df = pd.read_csv(os.path.join(BASE_FOLDER, EGGNOG_BLAST_FILE), sep ='\\t', header=None, names=eggnog_blast_header, skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query_name                                   evm.model.hcontig_010_016.50\n",
       "seed_eggNOG_ortholog                                        5297.EFP85053\n",
       "seed_ortholog_evalue                                                    0\n",
       "seed_ortholog_score                                                  1155\n",
       "predicted_gene_name                                             FG02823.1\n",
       "GO_terms                GO:0003674,GO:0003824,GO:0004620,GO:0004622,GO...\n",
       "KEGG_pathways                                                    map00564\n",
       "Annotation_tax_scope                                            euNOG[57]\n",
       "OGs                                               0XR72@NOG,KOG1325@euNOG\n",
       "bestOG|evalue|score                                KOG1325|2.4e-110|374.0\n",
       "COG                                                                     I\n",
       "cat                                                phospholipase A2 group\n",
       "eggNOG                                                                  0\n",
       "annot                                                                   0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggnog_blast_df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eggnog_blast_df.fillna(0, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query_name', 'seed_eggNOG_ortholog', 'seed_ortholog_evalue',\n",
       "       'seed_ortholog_score', 'predicted_gene_name', 'GO_terms',\n",
       "       'KEGG_pathways', 'Annotation_tax_scope', 'OGs', 'bestOG|evalue|score',\n",
       "       'COG', 'cat', 'eggNOG', 'annot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggnog_blast_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicted_gene_name',\n",
       " 'GO_terms',\n",
       " 'KEGG_pathways',\n",
       " 'Annotation_tax_scope',\n",
       " 'OGs',\n",
       " 'COG',\n",
       " 'cat',\n",
       " 'eggNOG',\n",
       " 'annot']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pick all annotation columns. One at a time and write them out as tab file or annotations files. The later can be used\n",
    "#to annotate gff files using gag.py\n",
    "DBs = [x for x in eggnog_blast_df.columns.tolist()[4:] if x not in ['GO_terms','KEGG_pathways', 'OGs' ] ]\n",
    "eggnog_blast_df['note'] = 'note'\n",
    "for db in DBs:\n",
    "    if len(eggnog_blast_df[eggnog_blast_df[db] !=0]) > 0:\n",
    "        eggnog_blast_df[eggnog_blast_df[db] !=0].loc[:,['query_name',db]]\\\n",
    "        .to_csv(os.path.join(OUT_PATH, db+'_terms.tab'), sep='\\t', header =None, index = None)\n",
    "        eggnog_blast_df[eggnog_blast_df[db] !=0].loc[:,['query_name', 'note', db]]\\\n",
    "        .to_csv(os.path.join(OUT_PATH, 'annotations.' +db+'.txt'), sep='\\t', header =None, index = None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f898e7b97996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mworking_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0meggnog_blast_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GO_terms'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meggnog_blast_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGO_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0meggnog_blast_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meggnog_blast_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GO_terms'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'NaN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2964\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[0;32m   2965\u001b[0m                 name in self._accessors):\n\u001b[1;32m-> 2966\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/benjamin/anaconda3/lib/python3.5/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_make_str_accessor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[1;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m             \u001b[1;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1909\u001b[1;33m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[0;32m   1910\u001b[0m                                  \u001b[1;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m                                  \"pandas\")\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "working_dict = {}\n",
    "eggnog_blast_df['GO_terms'] = eggnog_blast_df.GO_terms.str.split(',')\n",
    "\n",
    "eggnog_blast_df[eggnog_blast_df['GO_terms'] != 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "5      NaN\n",
       "6      NaN\n",
       "7      NaN\n",
       "8      NaN\n",
       "9      NaN\n",
       "10     NaN\n",
       "11     NaN\n",
       "12     NaN\n",
       "13     NaN\n",
       "14     NaN\n",
       "15     NaN\n",
       "16     NaN\n",
       "17     NaN\n",
       "18     NaN\n",
       "19     NaN\n",
       "20     NaN\n",
       "21     NaN\n",
       "22     NaN\n",
       "23     NaN\n",
       "24     NaN\n",
       "25     NaN\n",
       "26     NaN\n",
       "27     NaN\n",
       "28     NaN\n",
       "29     NaN\n",
       "        ..\n",
       "6892   NaN\n",
       "6893   NaN\n",
       "6894   NaN\n",
       "6895   NaN\n",
       "6896   NaN\n",
       "6897   NaN\n",
       "6898   NaN\n",
       "6899   NaN\n",
       "6900   NaN\n",
       "6901   NaN\n",
       "6902   NaN\n",
       "6903   NaN\n",
       "6904   NaN\n",
       "6905   NaN\n",
       "6906   NaN\n",
       "6907   NaN\n",
       "6908   NaN\n",
       "6909   NaN\n",
       "6910   NaN\n",
       "6911   NaN\n",
       "6912   NaN\n",
       "6913   NaN\n",
       "6914   NaN\n",
       "6915   NaN\n",
       "6916   NaN\n",
       "6917   NaN\n",
       "6918   NaN\n",
       "6919   NaN\n",
       "6920   NaN\n",
       "6921   NaN\n",
       "Name: GO_terms, Length: 6922, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggnog_blast_df['GO_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process the pathway files\n",
    "interpro_by_protein_KEGG = interpro_df[interpro_df.Pathway_IDs.str.contains('KEGG' or 'MetaCyc' or 'Reactome').fillna(False)]\n",
    "\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG.groupby('Updated_Protein_ID')\n",
    "\n",
    "#pull out all the KEGG terms and write them out as annotation files \n",
    "interpro_by_protein_KEGG = interpro_by_protein.Pathway_IDs.apply(set)\n",
    "\n",
    "#remove everything without KEGG term attached\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG[~(interpro_by_protein_KEGG == {0})]\n",
    "\n",
    "interpro_by_protein_KEGG_dict = dict(zip(interpro_by_protein_KEGG.index, interpro_by_protein_KEGG))\n",
    "\n",
    "ALL_KEGG_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_KEGG_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_KEGG_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_KEGG_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "KEGG_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_KEGG_LIST]).T\n",
    "KEGG_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "KEGG_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'Pathway_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'Pathway_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "KEGG_df['Transfer_ID'] = 'note'\n",
    "KEGG_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.Pathway_all.txt') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.Pathway.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all the GO terms and write them out as annotation files \n",
    "interpro_by_protein_GO = interpro_by_protein.GO_terms.apply(set)\n",
    "\n",
    "#remove everything without GO term attached\n",
    "interpro_by_protein_GO = interpro_by_protein_GO[~(interpro_by_protein_GO == {0})]\n",
    "\n",
    "interpro_by_protein_GO_dict = dict(zip(interpro_by_protein_GO.index, interpro_by_protein_GO))\n",
    "\n",
    "ALL_GO_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_GO_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_GO_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_GO_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "GO_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_GO_LIST]).T\n",
    "GO_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "GO_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'GO_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'GO_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "GO_df['Transfer_ID'] = 'note'\n",
    "GO_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.GO_all.txt') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.GO.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out other annotations files including busco, dbCAN, merops, swissprot\n",
    "annotation_files = [os.path.join(ANNOTATION_FILE_BASE_PATH, x) for x in os.listdir(ANNOTATION_FILE_BASE_PATH) \\\n",
    "                    if x.startswith('annotations') and (x.endswith('busco.txt') or x.endswith('dbCAN.txt') or x.endswith('merops.txt') or x.endswith('swissprot.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for anno in annotation_files:\n",
    "    _tmp_df = pd.read_csv(anno, header=None, sep='\\t', names=['Protein_ID','Transfer_ID', 'DB_ID'])\n",
    "    anno_file_name = anno.split('/')[-1]\n",
    "    anno_midfix = anno_file_name.split('.')[1]\n",
    "    _tmp_df['Updated_Protein_ID'] = protein_id_conversion(_tmp_df)\n",
    "    #write out filtered down tab file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P, anno_midfix+'_terms.tab'), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].\\\n",
    "    to_csv(os.path.join(OUT_PATH_P, anno_file_name ), sep = '\\t', header =None, index=None)\n",
    "     #write out not down tab file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_midfix+'_terms_all.tab' ), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_file_name.replace('.txt', '_all.txt') ), sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
