{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil, errno\n",
    "from glob import glob as glb\n",
    "\n",
    "def copyanything(src, dest_dir):\n",
    "    for filename in glb(os.path.join(src, '*.*')):\n",
    "        shutil.copy(filename, dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PDF(url):\n",
    "    return HTML('<iframe src=./tmp_figures/%s width=700 height=350></iframe>' % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at getting all the effector candidates from the Pst_104E_genome as defined as the following.\n",
    "EffectorP prediction done by Jana Sperschneider\n",
    "Gene expression cluster analysis done by Jana Sperschneider picking cluster 2, 3 and 8\n",
    "Out of this list two BUSCOs were removed as they are pretty conserved proteins and are simply coming from the upregulated cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define your input folders\n",
    "#define your input folders updated for haplotigs\n",
    "CLUSTER_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/gene_expression/Pst104_p_SecretomeClustering'\n",
    "EFFECTORP_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/Secretomes/EffectorP'\n",
    "GFF_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "PROTEIN_ANNO_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/pa_26062017'\n",
    "OUT_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists'\n",
    "OUT_FOLDER_FIG = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/figures'\n",
    "TMP_FIG_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/downstream_analysis_2017/scripts/tmp_figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(OUT_FOLDER_FIG):\n",
    "    os.mkdir(OUT_FOLDER_FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome = 'Pst_104E_v12_'\n",
    "p_effector_list = []\n",
    "h_effector_list = []\n",
    "p_effector_seq_list = []\n",
    "h_effector_seq_list = []\n",
    "p_effectorp_list = []\n",
    "h_effectorp_list = []\n",
    "p_effectorp_seq_list = []\n",
    "h_effectorp_seq_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define what you want to take clusters are from the expression analysis\n",
    "clusters = [ 2,3,8]\n",
    "clusters_files = [os.path.join(CLUSTER_FOLDER, x) for x in os.listdir(CLUSTER_FOLDER)\\\n",
    "                 if x.startswith('Cluster') and x.endswith('_DEs.fasta') and\\\n",
    "                  any(str(y) in x for y in clusters) ] #fixed to check if any of the clusters are\n",
    "                                    #in the file header\n",
    "effectorp_files = [os.path.join(EFFECTORP_FOLDER, x) for x in os.listdir(EFFECTORP_FOLDER)\\\n",
    "                  if x.endswith('effectors.fasta') and x.startswith(genome)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/gene_expression/Pst104_p_SecretomeClustering/Cluster8_DEs.fasta',\n",
       " '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/gene_expression/Pst104_p_SecretomeClustering/Cluster3_DEs.fasta',\n",
       " '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Pst_104E_genome/gene_expression/Pst104_p_SecretomeClustering/Cluster2_DEs.fasta']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the sequence names into a list from the fasta headers \n",
    "for file in clusters_files:\n",
    "    fh = open(file, 'r')\n",
    "    for seq in SeqIO.parse(fh, 'fasta'):\n",
    "        if 'hcontig' in seq.id:\n",
    "            h_effector_list.append(seq.id)\n",
    "            h_effector_seq_list.append(seq)\n",
    "        if 'pcontig' in seq.id:\n",
    "            p_effector_list.append(seq.id)\n",
    "            p_effector_seq_list.append(seq)\n",
    "    fh.close()\n",
    "\n",
    "for file in effectorp_files:\n",
    "    fh = open(file, 'r')\n",
    "    for seq in SeqIO.parse(fh, 'fasta'):\n",
    "        if 'hcontig' in seq.id and seq.id not in h_effector_list:\n",
    "            h_effector_list.append(seq.id)\n",
    "            h_effector_seq_list.append(seq)\n",
    "        if 'pcontig' in seq.id and seq.id not in p_effector_list:\n",
    "            p_effector_list.append(seq.id)\n",
    "            p_effector_seq_list.append(seq)\n",
    "    fh.close()\n",
    "    \n",
    "for file in effectorp_files:\n",
    "    fh = open(file, 'r')\n",
    "    for seq in SeqIO.parse(fh, 'fasta'):\n",
    "        if 'hcontig' in seq.id:\n",
    "            h_effectorp_list.append(seq.id)\n",
    "            h_effectorp_seq_list.append(seq)\n",
    "        if 'pcontig' in seq.id:\n",
    "            p_effectorp_list.append(seq.id)\n",
    "            p_effectorp_seq_list.append(seq)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the effector file name\n",
    "p_effector_file = os.path.join(OUT_FOLDER, genome + 'p_effector.list')\n",
    "p_effectorp_file = os.path.join(OUT_FOLDER, genome + 'p_effectorp.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get BUSCO list in order to remove the two BUSCOs from the effector candidate list\n",
    "p_busco_file = [os.path.join(PROTEIN_ANNO_FOLDER, x) for x in os.listdir(PROTEIN_ANNO_FOLDER) if x.startswith(genome+'p_ctg') and 'busco' in x][0]\n",
    "p_busco_list = pd.read_csv(p_busco_file, header=None, sep='\\t')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evm.model.pcontig_041.167', 'evm.model.pcontig_042.2']\n",
      "This is the number of effector candidates before removal: 1574\n",
      "This is the number of effector candidates after removal of BUSCOs: 1572\n"
     ]
    }
   ],
   "source": [
    "#write out effectors without BUSCOs\n",
    "effector_busco_overlap = [x for x in p_effector_list if x in p_busco_list]\n",
    "print(effector_busco_overlap)\n",
    "#remove those two from the effector list and update the effectors\n",
    "#one is a peptidase and the other an ER cargo protein both are fairly conserved\n",
    "print(\"This is the number of effector candidates before removal: %i\" % len(p_effector_list))\n",
    "updated_effector_seq_list = []\n",
    "for x in effector_busco_overlap:\n",
    "    p_effector_list.remove(x)\n",
    "for seq in p_effector_seq_list:\n",
    "    if seq.id not in effector_busco_overlap:\n",
    "        updated_effector_seq_list.append(seq)\n",
    "print(\"This is the number of effector candidates after removal of BUSCOs: %i\" % len(p_effector_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evm.model.pcontig_041.167', 'evm.model.pcontig_042.2']\n",
      "This is the number of effector candidates before removal: 1071\n",
      "This is the number of effector candidates after removal of BUSCOs: 1069\n"
     ]
    }
   ],
   "source": [
    "#write out effectorps without BUSCOs\n",
    "effectorp_busco_overlap = [x for x in p_effectorp_list if x in p_busco_list]\n",
    "print(effectorp_busco_overlap)\n",
    "#remove those two from the effector list and update the effectors\n",
    "#one is a peptidase and the other an ER cargo protein both are fairly conserved\n",
    "print(\"This is the number of effector candidates before removal: %i\" % len(p_effectorp_list))\n",
    "updated_effectorp_seq_list = []\n",
    "for x in effectorp_busco_overlap:\n",
    "    p_effectorp_list.remove(x)\n",
    "for seq in p_effectorp_seq_list:\n",
    "    if seq.id not in effectorp_busco_overlap:\n",
    "        updated_effectorp_seq_list.append(seq)\n",
    "print(\"This is the number of effector candidates after removal of BUSCOs: %i\" % len(p_effectorp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out the sets of effector candidates\n",
    "fh = open(p_effector_file, 'w')\n",
    "for ec in set(p_effector_list):\n",
    "    print(ec, file=fh)\n",
    "fh.close()\n",
    "\n",
    "\n",
    "#write out effector fasta files\n",
    "SeqIO.write(updated_effector_seq_list, open(p_effector_file.replace('.list', '.protein.fasta'), 'w'), 'fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out the sets of effector candidates\n",
    "fh = open(p_effectorp_file, 'w')\n",
    "for ec in set(p_effectorp_list):\n",
    "    print(ec, file=fh)\n",
    "fh.close()\n",
    "\n",
    "\n",
    "#write out effector fasta files\n",
    "SeqIO.write(updated_effectorp_seq_list, open(p_effectorp_file.replace('.list', '.protein.fasta'), 'w'), 'fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subset the gff files as well and write those out\n",
    "p_gff_file = [os.path.join(GFF_FOLDER, x) for x in os.listdir(GFF_FOLDER)\\\n",
    "                 if x.startswith(genome+'p_ctg') and x.endswith('anno.gff3') ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get repeat gff files\n",
    "p_repeat_gff_fn = [os.path.join(GFF_FOLDER, x) for x in os.listdir(GFF_FOLDER)\\\n",
    "                 if x.startswith(genome+'p_ctg') and x.endswith('REPET.gff') ][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command line in /home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/TE_analysis the superfamily gff files were sorted as followed and copied over into the lists folder\n",
    "sort Pst_104E_v12_h_ctg.REPET.superfamily.gff -k1,1n -k4,4n > Pst_104E_v12_h_ctg.REPET.sorted.superfamily.gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get repeat gff files\n",
    "p_repeat_superfamily_gff_fn = [os.path.join(OUT_FOLDER, x) for x in os.listdir(OUT_FOLDER)\\\n",
    "                 if x.startswith(genome+'p_ctg') and x.endswith('REPET.sorted.superfamily.gff') ][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gff header \n",
    "gff_header = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now subset the gff files for effectors only\n",
    "p_gff_df = pd.read_csv(p_gff_file, header = None, sep='\\t', names= gff_header)\n",
    "p_gff_df['ID'] = p_gff_df.attributes.str.extract(r'ID=([^;]*);', expand=False)\n",
    "p_gff_df.sort_values(by=['seqid', 'start'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now sort REPET gff and write out again\n",
    "p_repeat_gff_df = pd.read_csv(p_repeat_gff_fn, header=None, sep='\\t', names=gff_header, comment='#')\n",
    "p_repeat_gff_fn = os.path.join(OUT_FOLDER,p_repeat_gff_fn.split('/')[-1] )\n",
    "p_repeat_gff_df.sort_values(by=['seqid', 'start']).to_csv(p_repeat_gff_fn, header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now write out dataframes for p_gff\n",
    "\n",
    "#bed 6 file\n",
    "p_effector_bed_fn = p_effector_file.replace('.list', '.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_effector_bed_fn, header=None, index=None, sep='\\t')\n",
    "    \n",
    "p_effector_gff_fn = p_effector_file.replace('.list', '.gene.gff3')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_effector_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "\n",
    "#bed 6 file no effectors\n",
    "p_noeffector_bed_fn = p_effector_file.replace('p_effector.list', 'p_noeffector.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_noeffector_bed_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "#no effector gff and list\n",
    "p_noeffector_gff_fn = p_effector_file.replace('p_effector.list', 'p_noeffector.gene.gff3')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_noeffector_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "file_name = p_effector_file.replace('p_effector.list', 'p_noeffector.list')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now write out dataframes for p_gff\n",
    "\n",
    "#bed 6 file\n",
    "p_effectorp_bed_fn = p_effectorp_file.replace('.list', '.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_effectorp_bed_fn, header=None, index=None, sep='\\t')\n",
    "    \n",
    "p_effectorp_gff_fn = p_effectorp_file.replace('.list', '.gene.gff3')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_effectorp_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "\n",
    "#bed 6 file no effectors\n",
    "p_noeffectorp_bed_fn = p_effectorp_file.replace('p_effectorp.list', 'p_noeffectorp.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_noeffectorp_bed_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "#no effector gff and list\n",
    "p_noeffectorp_gff_fn = p_effectorp_file.replace('p_effectorp.list', 'p_noeffectorp.gene.gff3')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_noeffectorp_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "file_name = p_effectorp_file.replace('p_effectorp.list', 'p_noeffectorp.list')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out BUSCO for pcontigs\n",
    "file_name = p_effector_file.replace('effector.list', 'busco.list')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')\n",
    "    \n",
    "p_busco_gff_fn = p_effector_file.replace('effector.list', 'busco.gene.gff3')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_busco_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "p_busco_bed_fn = p_effector_file.replace('effector.list', 'busco.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_busco_bed_fn, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out non BUSCO for pcontigs\n",
    "file_name = p_effector_file.replace('effector.list', 'non_busco.list')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))]['ID'].str.replace('TU', 'model')\\\n",
    "    .to_csv(file_name, header=None, index=None, sep='\\t')\n",
    "p_non_busco_gff_fn = p_effector_file.replace('effector.list', 'non_busco.gene.gff3')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))].\\\n",
    "    loc[:,gff_header].to_csv(p_non_busco_gff_fn, header=None, index=None, sep='\\t')\n",
    "\n",
    "p_non_busco_bed_fn = p_effector_file.replace('effector.list', 'non_busco.gene.bed')\n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_non_busco_bed_fn, header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out no busco no effector bed files\n",
    "p_noeffector_nobusco_bed_fn = p_effector_file.replace('effector.list', 'no_busco_no_effector.gene.bed')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))\\\n",
    "         &(~p_gff_df.ID.str.replace('TU', 'model').isin(p_effector_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_noeffector_nobusco_bed_fn, header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out no busco no effector bed files\n",
    "p_noeffectorp_nobusco_bed_fn = p_effectorp_file.replace('effectorp.list', 'no_busco_no_effectorp.gene.bed')    \n",
    "p_gff_df[(p_gff_df.type == 'gene') & (~p_gff_df.ID.str.replace('TU', 'model').isin(p_busco_list))\\\n",
    "         &(~p_gff_df.ID.str.replace('TU', 'model').isin(p_effectorp_list))].\\\n",
    "    loc[:,['seqid', 'start', 'end', 'ID', 'score', 'strand']].to_csv(p_noeffectorp_nobusco_bed_fn, header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran up to here for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances\n",
    "\n",
    "#read in files and generate bedtool objects. Issue might be that same variable are used for the bed files\n",
    "#while those are sometimes gff and sometimes bed. Needs changing\n",
    "p_effector_bed = BedTool(p_effector_gff_fn)\n",
    "p_noeffector_bed = BedTool(p_noeffector_gff_fn)\n",
    "p_busco_bed = BedTool(p_busco_gff_fn)\n",
    "p_repeats_bed = BedTool(p_repeat_superfamily_gff_fn)\n",
    "p_non_busco_bed = BedTool(p_non_busco_bed_fn)\n",
    "\n",
    "\n",
    "#get closest repeat and make a df out of it\n",
    "p_closest_rep_to_eff = p_effector_bed.closest(p_repeats_bed, d=True)\n",
    "p_closest_rep_to_eff_df = p_closest_rep_to_eff.to_dataframe()\n",
    "\n",
    "#here subset the repeat superfamily GFF to filder out smaller repeats if wanted\n",
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily', 'tmpsuperfamily')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "#read this in as repeat_df\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bed closest header when using gff as input files\n",
    "bed_repeat_closest_header = [x +'_gene' for x in gff_header] + [x +'_repeat' for x in gff_header] + ['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Effectors closest Repeat')\n",
    "print(p_effector_bed.closest(p_repeats_bed,d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_effector_bed.closest(p_repeats_bed, d=True, t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Repeat closest effector')\n",
    "print(p_repeats_bed.closest(p_effector_bed,d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_repeats_bed.closest(p_effector_bed, d=True, t='last').to_dataframe().boxplot(column=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('BUSCO distance to closest repeat')\n",
    "print(p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('BUSCO distance to closest repeat')\n",
    "print(p_repeats_bed.closest(p_busco_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_repeats_bed.closest(p_busco_bed, d=True,t='last').to_dataframe().boxplot(column=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('No Effector distance to closest repeat')\n",
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance from TE elements to other elements')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_repeats_bed.reldist(p_effector_bed)['reldist'], p_repeats_bed.reldist(p_effector_bed)['fraction'], label ='effectors')\n",
    "plt.plot(p_repeats_bed.reldist(p_busco_bed)['reldist'], p_repeats_bed.reldist(p_busco_bed)['fraction'], label= 'busco')\n",
    "plt.plot(p_repeats_bed.reldist(p_noeffector_bed)['reldist'], p_repeats_bed.reldist(p_noeffector_bed)['fraction'], label='no_effectors')\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance of other elements to TEs')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_effector_bed.reldist(p_repeats_bed)['reldist'], p_effector_bed.reldist(p_repeats_bed)['fraction'], label ='effectors')\n",
    "plt.plot(p_busco_bed.reldist(p_repeats_bed)['reldist'], p_busco_bed.reldist(p_repeats_bed)['fraction'], label= 'busco')\n",
    "plt.plot(p_noeffector_bed.reldist(p_repeats_bed)['reldist'], p_noeffector_bed.reldist(p_repeats_bed)['fraction'], label='no_effectors')\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some stuff in the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_noeffector_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_effector_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().groupby(17).count()[0].sort_values().tail(10)/len(p_busco_bed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().groupby(17).mean()[18].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now lookine at ClassII:?:? specifically\n",
    "tmp_REPET[(tmp_REPET.distance > 400)&(tmp_REPET.attributes == 'ClassII:?:?')].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Effectors and there closest ClassII:?:? elements')\n",
    "print(p_effector_bed.closest(p_repeats_bed,d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_effector_bed.closest(p_repeats_bed, d=True, t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('ClassII:?:? elements and there closest Effectors ')\n",
    "print(p_repeats_bed.closest(p_effector_bed, d=True, t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_repeats_bed.closest(p_effector_bed, d=True, t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance from ClassII:?:? elements and other elements')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_repeats_bed.reldist(p_effector_bed)['reldist'], p_repeats_bed.reldist(p_effector_bed)['fraction'], label ='effectors')\n",
    "plt.plot(p_repeats_bed.reldist(p_busco_bed)['reldist'], p_repeats_bed.reldist(p_busco_bed)['fraction'], label= 'busco')\n",
    "plt.plot(p_repeats_bed.reldist(p_noeffector_bed)['reldist'], p_repeats_bed.reldist(p_noeffector_bed)['fraction'], label='no_effectors')\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance of other elements to ClassII:?:?')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_effector_bed.reldist(p_repeats_bed)['reldist'], p_effector_bed.reldist(p_repeats_bed)['fraction'], label ='effectors')\n",
    "plt.plot(p_busco_bed.reldist(p_repeats_bed)['reldist'], p_busco_bed.reldist(p_repeats_bed)['fraction'], label= 'busco')\n",
    "plt.plot(p_noeffector_bed.reldist(p_repeats_bed)['reldist'], p_noeffector_bed.reldist(p_repeats_bed)['fraction'], label='no_effectors')\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('BUSCOs distance to closest ClassII:?:?')\n",
    "print(p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('No effectors distance to closest ClassII:?:?')\n",
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('No effectors distance to closest ClassII:?:? while allowing for overlaps')\n",
    "print(p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().iloc[:,18:20].describe())\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().boxplot(column=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at if effectors and buscos are linked or further apart using the redist function\n",
    "print('Relative distance of between BUSCOS and effectors')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_effector_bed.reldist(p_busco_bed)['reldist'], p_effector_bed.reldist(p_busco_bed)['fraction'], label ='Effectors vs. BUSCO')\n",
    "plt.plot(p_busco_bed.reldist(p_effector_bed)['reldist'], p_busco_bed.reldist(p_effector_bed)['fraction'], label= 'BUSCO vs effectors')\n",
    "\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance of between non-effectors and effectors')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_effector_bed.reldist(p_noeffector_bed)['reldist'], p_effector_bed.reldist(p_noeffector_bed)['fraction'], label ='Effectors vs. No effectors')\n",
    "plt.plot(p_noeffector_bed.reldist(p_effector_bed)['reldist'], p_noeffector_bed.reldist(p_effector_bed)['fraction'], label= 'No effectors vs effectors')\n",
    "\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Relative distance of between non-effectors and effectors')\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "plt.plot(p_busco_bed.reldist(p_non_busco_bed)['reldist'], p_busco_bed.reldist(p_non_busco_bed)['fraction'], label ='Effectors vs. No effectors')\n",
    "plt.plot(p_non_busco_bed.reldist(p_busco_bed)['reldist'], p_non_busco_bed.reldist(p_busco_bed)['fraction'], label= 'No effectors vs effectors')\n",
    "\n",
    "plt.ylim(0, 0.05)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#densities without overlaps between repeats and genes\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density')\n",
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density', color='r')\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe().loc[:,18].plot(kind='density', color='g')\n",
    "plt.semilogx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#densities with overlaps between repeats and genes\n",
    "p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density')\n",
    "p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density', color='r')\n",
    "p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe().loc[:,18].plot(kind='density', color='g')\n",
    "plt.semilogx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define repeats\n",
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily', 'tmpsuperfamily')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,gff_header].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summary of closest TEs not allowing for overlaps \n",
    "#####Needs fixing for genes that don't have a nearest neighbou######\n",
    "p_br_closest_df = p_busco_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_br_closest_pt = p_br_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_br_closest_pt['superfamily_%'] = p_br_closest_pt.count_nonzero / p_br_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_br_closest_pt.columns] \n",
    "new_columns = [x+'_busco' for x in p_br_closest_pt.columns]\n",
    "p_br_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_er_closest_df = p_effector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_er_closest_pt = p_er_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_er_closest_pt['superfamily_%'] = p_er_closest_pt.count_nonzero / p_er_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_er_closest_pt.columns] \n",
    "new_columns = [x+'_effector' for x in p_er_closest_pt.columns]\n",
    "p_er_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_ner_closest_df = p_noeffector_bed.closest(p_repeats_bed, d=True,t='last', io=True).to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_ner_closest_pt = p_ner_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_ner_closest_pt['superfamily_%'] = p_ner_closest_pt['count_nonzero'] / p_ner_closest_pt['count_nonzero'].sum() *100\n",
    "old_columns =[x for x in p_ner_closest_pt.columns] \n",
    "new_columns = [x+'_noeffector' for x in p_ner_closest_pt.columns]\n",
    "p_ner_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "repeat_distance_df = pd.concat([p_ner_closest_pt.iloc[:,1:], p_br_closest_pt.iloc[:,1:], p_er_closest_pt.iloc[:,1:]], axis=1)\n",
    "\n",
    "repeat_distance_df[repeat_distance_df['superfamily_%_effector'] >1].sort_values('superfamily_%_effector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summary of closest TEs allowing for overlaps\n",
    "p_br_closest_df = p_busco_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_br_closest_pt = p_br_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_br_closest_pt['superfamily_%'] = p_br_closest_pt.count_nonzero / p_br_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_br_closest_pt.columns] \n",
    "new_columns = [x+'_busco' for x in p_br_closest_pt.columns]\n",
    "p_br_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_er_closest_df = p_effector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_er_closest_pt = p_er_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_er_closest_pt['superfamily_%'] = p_er_closest_pt.count_nonzero / p_er_closest_pt.count_nonzero.sum() *100\n",
    "old_columns =[x for x in p_er_closest_pt.columns] \n",
    "new_columns = [x+'_effector' for x in p_er_closest_pt.columns]\n",
    "p_er_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "p_ner_closest_df = p_noeffector_bed.closest(p_repeats_bed, d=True,t='last').to_dataframe(names = bed_repeat_closest_header)\n",
    "\n",
    "p_ner_closest_pt = p_ner_closest_df.pivot_table(values='distance', index=['attributes_repeat'] ,aggfunc=[ np.count_nonzero, np.mean]).T.unstack().T\n",
    "\n",
    "p_ner_closest_pt['superfamily_%'] = p_ner_closest_pt['count_nonzero'] / p_ner_closest_pt['count_nonzero'].sum() *100\n",
    "old_columns =[x for x in p_ner_closest_pt.columns] \n",
    "new_columns = [x+'_noeffector' for x in p_ner_closest_pt.columns]\n",
    "p_ner_closest_pt.rename(columns=dict(zip(old_columns,new_columns)), inplace = True)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "repeat_distance_df = pd.concat([p_ner_closest_pt.iloc[:,1:], p_br_closest_pt.iloc[:,1:], p_er_closest_pt.iloc[:,1:]], axis=1)\n",
    "\n",
    "repeat_distance_df[repeat_distance_df['superfamily_%_effector'] >1].sort_values('superfamily_%_effector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some sub_sets for randommization to get equal sized groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the size of the subset here\n",
    "sub_set = len(p_busco_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effector_bed = BedTool(p_effector_bed_fn)\n",
    "p_allgene_bed = BedTool(p_gene_bed_fn)\n",
    "p_busco_bed = BedTool(p_busco_bed_fn)\n",
    "p_allall_rand_sub = p_allgene_bed.random_subset(sub_set)\n",
    "p_effector_bed_rand_sub = p_effector_bed.random_subset(sub_set)\n",
    "p_busco_bed_rand_sub = p_busco_bed.random_subset(sub_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_non_busco_non_effector_bed_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get some randomly subsampled beds of non_busco_non_effectors\n",
    "p_non_busco_non_effector_bed = BedTool(p_non_busco_non_effector_bed_fn)\n",
    "p_no_b_no_e_rand_sub = p_non_busco_non_effector_bed.random_subset(sub_set)\n",
    "for n in range(0,10):\n",
    "    fn_n = p_non_busco_non_effector_bed_fn.replace('.gene.bed', '.randsub_%s.gene.bed'%n)\n",
    "    p_no_b_no_e_rand_sub = p_non_busco_non_effector_bed.random_subset(sub_set)\n",
    "    p_no_b_no_e_rand_sub.to_dataframe().to_csv(fn_n, sep='\\t', header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances with nearest gene effectors vs effectors\n",
    "p_eself = p_effector_bed_rand_sub.closest(p_effector_bed_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_eself = p_eself[p_eself > -1]\n",
    "p_eself.name = 'Effectors'\n",
    "p_eall = p_effector_bed_rand_sub.closest(p_allall_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_eall= p_eall[p_eall > -1]\n",
    "print(p_eself.describe())\n",
    "p_eself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the distances with nearest gene all vs all subsampled\n",
    "p_allall = p_allall_rand_sub.closest(p_allall_rand_sub, d=True, N=True).to_dataframe().iloc[:,12]\n",
    "p_allall = p_allall[p_allall > -1]\n",
    "p_allall.name = 'All_genes'\n",
    "print(p_allall.describe())\n",
    "p_allall.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now with buscos\n",
    "p_bself = p_busco_bed_rand_sub.closest(p_busco_bed_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_bself = p_bself[p_bself > -1]\n",
    "p_bself.name = 'BUSCO'\n",
    "print(p_bself.describe())\n",
    "p_bself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#non_effectors\n",
    "p_noeffector_bed= BedTool(p_noeffector_bed_fn)\n",
    "p_noeffector_rand_sub = p_noeffector_bed.random_subset(sub_set)\n",
    "p_neself = p_noeffector_rand_sub.closest(p_noeffector_rand_sub, d=True,  N=True).to_dataframe().iloc[:,12]\n",
    "p_neself = p_neself[p_neself > -1]\n",
    "p_neself.name = 'No_effectors'\n",
    "print(p_neself.describe())\n",
    "p_neself.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look if effectors and BUSCOs are actually linked\n",
    "The question is if effectors are close to buscos than other genes. So do busco and effectors link together.\n",
    "\n",
    "-> are busco more likely closest genes to effectors and vice versa\n",
    "-> are the distance between busco and random genes larger than busco and effectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('effectors distance to closest Busco')\n",
    "p_effector_bed_rand_sub.closest(p_busco_bed_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "effector_busco_c_df = p_effector_bed_rand_sub.closest(p_busco_bed_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "effector_busco_c_df = effector_busco_c_df[effector_busco_c_df>-1]\n",
    "effector_busco_c_df.name = \"Closest Busco to effector\"\n",
    "effector_busco_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Closest effector to busco')\n",
    "p_busco_bed_rand_sub.closest(p_effector_bed_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "busco_effector_c_df = p_busco_bed_rand_sub.closest(p_effector_bed_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "busco_effector_c_df = busco_effector_c_df[busco_effector_c_df>-1]\n",
    "busco_effector_c_df.name = 'Closest effector to busco'\n",
    "busco_effector_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('effectors distance to closest rand')\n",
    "p_effector_bed_rand_sub.closest(p_allall_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "effector_randsubset_c_df = p_effector_bed_rand_sub.closest(p_allall_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "effector_randsubset_c_df = effector_randsubset_c_df[effector_randsubset_c_df>-1]\n",
    "effector_randsubset_c_df.name =  \"Closest randsubset to effector\"\n",
    "effector_randsubset_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('busco distance to closest rand')\n",
    "p_busco_bed_rand_sub.closest(p_allall_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "busco_rand_sub_c_df = p_busco_bed_rand_sub.closest(p_allall_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "busco_rand_sub_c_df = busco_rand_sub_c_df[busco_rand_sub_c_df>-1]\n",
    "busco_rand_sub_c_df.name = \"Closest rand sub to BUSCO\"\n",
    "busco_rand_sub_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('rand to closest busco')\n",
    "p_allall_rand_sub.closest(p_busco_bed_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "rand_sub_busco_c_df = p_allall_rand_sub.closest(p_busco_bed_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "rand_sub_busco_c_df = rand_sub_busco_c_df[rand_sub_busco_c_df>-1]\n",
    "rand_sub_busco_c_df.name = 'Closest BUSCO to rand subset'\n",
    "rand_sub_busco_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Rand to closest effector')\n",
    "p_allall_rand_sub.closest(p_effector_bed_rand_sub, d=True,t='last', io=True).to_dataframe().boxplot(column=12)\n",
    "rand_subset_effector_c_df = p_allall_rand_sub.closest(p_effector_bed_rand_sub, d=True,t='last', io=True).to_dataframe().iloc[:,12]\n",
    "rand_subset_effector_c_df = rand_subset_effector_c_df[rand_subset_effector_c_df>-1]\n",
    "rand_subset_effector_c_df.name ='Closest effector to rand subset'\n",
    "rand_subset_effector_c_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all against others both ways to see if effectors are closer to buscos compared to random subset\n",
    "all_vs_others_c_df = \\\n",
    " pd.concat([busco_effector_c_df,rand_subset_effector_c_df,effector_busco_c_df,rand_sub_busco_c_df,  \\\n",
    "             effector_randsubset_c_df, busco_rand_sub_c_df ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "sns.violinplot(data=all_vs_others_c_df)\n",
    "plt.xticks(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function that subsets a dataframe to the inner quantil residual columnwise\n",
    "def quant_cut_df(dataframe):\n",
    "    nn_df = dataframe.copy()\n",
    "    iqr_df_low = nn_df.apply(lambda x: x.quantile(0.25) - 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "    iqr_df_low.name ='low'\n",
    "    iqr_df_high = nn_df.apply(lambda x: x.quantile(0.75) + 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "    iqr_df_high.name = 'high'\n",
    "\n",
    "    iqr_df = pd.concat([iqr_df_low, iqr_df_high], axis=1).T\n",
    "\n",
    "    iqr_nn_df = nn_df.apply(lambda x: x[(x > iqr_df.loc['low', x.name]) & (x  < iqr_df.loc['high', x.name])], axis=0)\n",
    "    return iqr_nn_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the violine plots for distances once teh iqr is present only\n",
    "all_vs_others_iqr_df = quant_cut_df(all_vs_others_c_df)\n",
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "sns.violinplot(data=all_vs_others_iqr_df)\n",
    "plt.xticks(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vs_others_iqr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do some stats on it look first into ranksum test\n",
    "scipy.stats.ranksums(all_vs_others_c_df['Closest effector to busco'], all_vs_others_c_df['Closest effector to rand subset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.ranksums(all_vs_others_c_df['Closest Busco to effector'], all_vs_others_c_df['Closest BUSCO to rand subset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(all_vs_others_c_df['Closest Busco to effector'], all_vs_others_c_df['Closest BUSCO to rand subset'],use_continuity=True, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(all_vs_others_c_df['Closest effector to busco'], all_vs_others_c_df['Closest effector to rand subset'],use_continuity=True, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vs_others_iqr_melt = all_vs_others_iqr_df.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = all_vs_others_iqr_melt\\\n",
    "    [all_vs_others_iqr_melt.variable.isin(all_vs_others_iqr_df.iloc[:,[0,1,2,3]].columns)].copy()\n",
    "#do a boxplot and swarmplot on the same data\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "#ax.set_xscale(\"log\")\n",
    "sns.violinplot(x=\"value\", y=\"variable\", data=df, cut=0,\n",
    "          whis=np.inf)\n",
    "plt.setp(ax.artists, alpha=.01)\n",
    "sns.swarmplot(x=\"value\", y=\"variable\", data=df,\n",
    "              size=2, color=\".3\", linewidth=0)\n",
    "plt.xlim(0, 120000)\n",
    "plt.ylabel(\"Comparisons\")\n",
    "plt.xlabel('Distance in bp')\n",
    "ax.text(118000, 0.5, '*\\n*\\n*', color='k')\n",
    "ax.plot([117000, 117000],[-0.1, 0.8], color ='k' )\n",
    "ax.text(118000, 2.5, '*\\n*\\n*', color='k')\n",
    "ax.plot([117000, 117000],[1.9, 2.8], color ='k' )\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do a boxplot on the same data using own bining\n",
    "bins = [x for x in range(0, int(all_vs_others_iqr_df.max().max())+10000,2000 )]\n",
    "all_vs_others_iqr_melt['bins'] = pd.cut(all_vs_others_iqr_melt.value, bins)\n",
    "all_vs_others_iqr_hist = all_vs_others_iqr_melt.groupby(by=['variable', 'bins']).count().unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vs_others_iqr_hist['bins'] = all_vs_others_iqr_hist.index.get_level_values(1)\n",
    "\n",
    "all_vs_others_iqr_hist['bins_left'] = all_vs_others_iqr_hist['bins'].apply(lambda x: x.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = all_vs_others_iqr_hist.copy()\n",
    "_max = all_vs_others_iqr_df.max().max()\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,15), sharex='all', sharey='all')\n",
    "for axes, data in zip(ax.flat,  df.iloc[:,[1,0,2,3]].columns ):\n",
    "    axes.bar(left=  df['bins_left'],height=df.loc[:,data],\\\n",
    "            color='k',width=1000)\n",
    "    axes.set_title(data)\n",
    "    \n",
    "ax[1,0].set_xlabel('Distance to nearest neighbour')\n",
    "ax[1,1].set_xlabel('Distance to nearest neighbour')\n",
    "ax[0,0].set_ylabel('Frequency')\n",
    "ax[1,0].set_ylabel('Frequency')\n",
    "plt.xlim(-500, _max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_vs_others_iqr_hist.cumsum(axis=0)['Closest Busco to effector'] - all_vs_others_iqr_hist.cumsum(axis=0)['Closest BUSCO to rand subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_vs_others_iqr_hist.cumsum(axis=0)['Closest effector to busco'] - all_vs_others_iqr_hist.cumsum(axis=0)['Closest effector to rand subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do a boxplot bin the data into same intervals for all and make new data frame out of it\n",
    "all_vs_others_c_df_melt = all_vs_others_c_df.melt()\n",
    "bins = [x for x in range(0, int(all_vs_others_c_df_melt.value.max())+10000,2000 )]\n",
    "all_vs_others_c_df_melt['bins'] = pd.cut(all_vs_others_c_df_melt.value, bins)\n",
    "all_vs_others_c_df_hist = all_vs_others_c_df_melt.groupby(by=['variable', 'bins']).count().unstack().T\n",
    "all_vs_others_c_df_hist['bins'] = all_vs_others_c_df_hist.index.get_level_values(1)\n",
    "all_vs_others_c_df_hist['bins_left'] = all_vs_others_c_df_hist['bins'].apply(lambda x: x.left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = all_vs_others_c_df_hist.copy()\n",
    "_max = all_vs_others_c_df_melt.value.max()\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,12), sharex='all', sharey='all')\n",
    "for axes, data in zip(ax.flat,  df.iloc[:,[1,0,2,3]].columns ):\n",
    "    axes.bar(left=  df['bins_left'],height=df.loc[:,data],\\\n",
    "            color='k',width=2000)\n",
    "    axes.set_title(data)\n",
    "    \n",
    "ax[1,0].set_xlabel('Distance to nearest neighbour')\n",
    "ax[1,1].set_xlabel('Distance to nearest neighbour')\n",
    "ax[0,0].set_ylabel('Frequency')\n",
    "ax[1,0].set_ylabel('Frequency')\n",
    "plt.xlim(-500, _max)\n",
    "#all_vs_others_iqr_df.hist(bins=30, figsize=(15,10), sharey='All', sharex=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat Pst_104E_v12_ph_ctg.no_alleles_postQC.txt | xargs -I {} grep \"{}\" ../../enrichment_analysis/lists/Pst_104E_v12_p_effector.list > ../../enrichment_analysis/lists/Pst_104E_v12_p_effector.noalleles.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls {OUT_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if effectors without alleles look any different.\n",
    "orphan_effectors_list = pd.read_csv(os.path.join(OUT_FOLDER,'Pst_104E_v12_p_Cluster8_UnderDiversifyingSelection.list')\\\n",
    "                                   , sep='\\t', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "effector_list = pd.read_csv(os.path.join(OUT_FOLDER,'Pst_104E_v12_p_effector.list')\\\n",
    "                                   , sep='\\t', header=None)[0].tolist()\n",
    "busco_list = pd.read_csv(os.path.join(OUT_FOLDER,'Pst_104E_v12_p_busco.list')\\\n",
    "                                   , sep='\\t', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in effector_list:\n",
    "    if x in busco_list:\n",
    "        count = count +1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(set(effector_list) -set(busco_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df  = p_effector_bed_rand_sub.closest(p_busco_bed_rand_sub, d=True,t='last', io=True).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[test_df[3].str.replace('TU', 'model').isin(orphan_effectors_list)].loc[:,12].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.loc[:,12].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No look a bit more into the distribution of the nearest neighbour distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself[p_bself < 10000], bins=20, rug = True, color='g',label='BUSCO')\n",
    "sns.distplot(p_eself[p_eself < 10000], bins=20, rug = True, color='red',label = 'effector')\n",
    "sns.distplot(p_neself[p_neself <10000], bins=20, rug=True, color='yellow', label ='not_effectors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself[p_bself < 200000], bins=20, color='g' ,label='BUSCO')\n",
    "sns.distplot(p_eself[p_eself < 200000], bins=20,  color='red',label = 'effector')\n",
    "sns.distplot(p_neself[p_neself <200000], bins=20,  color='yellow', label ='not_effectors', axlabel='Distance to closest neighbour [bp]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(p_bself, bins=20,color='g',  label='BUSCO')\n",
    "sns.distplot(p_eself, bins=20,  color='red',label = 'effector')\n",
    "sns.distplot(p_allall, bins=20,  color='b',label = 'all')\n",
    "sns.distplot(p_neself, bins=20,  color='yellow', label ='not_effectors', axlabel='Distance to closest neighbour [bp]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now make a nearest neightbour dataframe\n",
    "nn_df = pd.concat([p_allall, p_bself, p_eself], names=['All_genes', 'BUSCO', 'effectors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=nn_df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOW FILTER BY QUANTIELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low = 0\n",
    "high = 0.8\n",
    "quant_df = nn_df.quantile([low,high])\n",
    "\n",
    "qfilt_nn_df = nn_df.apply(lambda x: x[(x > quant_df.loc[low, x.name]) & (x  < quant_df.loc[high, x.name])], axis=0)\n",
    "\n",
    "sns.violinplot(data=qfilt_nn_df , palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now filter on IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iqr_df_low = nn_df.apply(lambda x: x.quantile(0.25) - 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "iqr_df_low.name ='low'\n",
    "iqr_df_high = nn_df.apply(lambda x: x.quantile(0.75) + 1.5*(x.quantile(0.75) - x.quantile(0.25)) )\n",
    "iqr_df_high.name = 'high'\n",
    "\n",
    "iqr_df = pd.concat([iqr_df_low, iqr_df_high], axis=1).T\n",
    "\n",
    "iqr_nn_df = nn_df.apply(lambda x: x[(x > iqr_df.loc['low', x.name]) & (x  < iqr_df.loc['high', x.name])], axis=0)\n",
    "plt.title('Violine plot of nearest neighbour in the same category')\n",
    "sns.violinplot(data=iqr_nn_df  , palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_bself[p_bself < 20000].plot(kind='density')\n",
    "p_eself[p_eself < 20000].plot(kind='density', color='g')\n",
    "p_neself[p_neself < 20000].plot(kind='density', color='r')\n",
    "p_eall[p_eall < 20000].plot(kind='density', color='y')\n",
    "#plt.semilogx()\n",
    "print(len(p_bself[p_bself < 20000]), len(p_eself[p_eself < 20000]), len(p_neself[p_neself < 20000]), len(p_eall[p_eall < 20000]))\n",
    "plt.xlim(0, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_eall[p_eall].plot(kind='hist', bins=20, normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_eself[p_eself].plot(kind='hist', bins=20, normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_bself[p_bself ].plot(kind='hist', bins=20,normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_neself[p_neself ].plot(kind='hist',bins=20,normed=True)\n",
    "plt.ylim(0, 0.00020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there seems to be no clear link between effector candidates and closest neighbour in terms of TEs in general. They all have the same distance in general.\n",
    "Maybe Gypsy and ClassII:?:? should be looked at more carefully. Those are depleted and enriched in busco and effector genes. In general there seems to be a trend towards ClassII elements compared to ClassI in effector candidates.\n",
    "This changes when for allowing for overlaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that effectors are closer together than noneffector genes. Buscos also seem to cluster a bit. Let's see if we can visualize the location of genes on certain contigs vs repeats and such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start with getting effectors per contig divided by length divded by # of overall genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get effectors per contig\n",
    "effector_bdf = pd.read_csv(p_effector_bed_fn, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_effectors_per_contig  = effector_bdf.groupby(0).count()[1]\n",
    "p_effectors_per_contig.name = 'effectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all others counts per contig\n",
    "p_all_genes_per_contig = pd.read_csv(p_gene_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_all_genes_per_contig.name = 'all_genes'\n",
    "p_noeffectors_per_contig = pd.read_csv(p_noeffector_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_noeffectors_per_contig.name = 'no_effectors'\n",
    "p_busco_per_contig = pd.read_csv(p_busco_bed_fn, header=None, sep='\\t').groupby(0).count()[1]\n",
    "p_busco_per_contig.name = 'buscos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the genome file that contains the length of each contig in the second column\n",
    "p_contig_length = pd.read_csv(os.path.join(GFF_FOLDER, 'Pst_104E_v12_p_ctg.genome_file'), header = None,\\\n",
    "                          names=['contig' , 'length'], sep='\\t').sort_values('contig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_contig_length.index = p_contig_length.contig\n",
    "\n",
    "p_contig_length = p_contig_length.loc[:, 'length']\n",
    "\n",
    "gene_dis_per_contig = pd.concat([p_contig_length,p_all_genes_per_contig,p_noeffectors_per_contig,p_busco_per_contig,  p_effectors_per_contig ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill nan with 0s\n",
    "gene_dis_per_contig.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig.effectors.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chisquare for genes per contig vs bases per contig\n",
    "chisquare(gene_dis_per_contig.length.values/gene_dis_per_contig.length.sum()\\\n",
    "          , gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chisquare(gene_dis_per_contig.buscos.values/gene_dis_per_contig.buscos.sum()\\\n",
    "          , gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the % of each category that are on a specific contig\n",
    "gene_dis_per_contig['%busco'] = gene_dis_per_contig.buscos.values/gene_dis_per_contig.buscos.sum() *100\n",
    "gene_dis_per_contig['%effector'] = gene_dis_per_contig.effectors.values/gene_dis_per_contig.effectors.sum() *100\n",
    "gene_dis_per_contig['%all_genes'] = gene_dis_per_contig.all_genes.values/gene_dis_per_contig.all_genes.sum() *100\n",
    "gene_dis_per_contig['%no_effector'] = gene_dis_per_contig.no_effectors.values/gene_dis_per_contig.no_effectors.sum() *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not sure why this isn't working\n",
    "chisquare(gene_dis_per_contig['%effector'], f_exp = gene_dis_per_contig['%all_genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a look at the different percentages\n",
    "gene_dis_per_contig.loc[:,['%effector', '%all_genes','%no_effector' ,'%busco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#contigs which % effectors is more than % of all genes or of buscos\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%effector'] > gene_dis_per_contig['%busco'])].loc[:,['effectors', '%effector', '%all_genes']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#contigs which % effectors is more than % of all genes or of buscos\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%effector'] > gene_dis_per_contig['%busco'])].loc[:,['effectors', '%effector', '%all_genes', '%busco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "setwd(\"/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/enrichment_analysis/lists\")\n",
    "getwd()\n",
    "busco_bed <- import(\"Pst_104E_v12_p_busco.gene.bed\", format ='bed')\n",
    "effector_bed <- import(\"Pst_104E_v12_p_effector.gene.bed\", format='bed')\n",
    "no_effector_bed <- import(\"Pst_104E_v12_p_effectorp_noeffector.gene.bed\", format='bed')\n",
    "#Pst_104E_seqinfo <- import(\"../../../032017_assembly/Pst_104E_v12_p_ctg.genome_file\", as = \"Rle\")\n",
    "#Pst_104E_seqinfo\n",
    "#effector_bed\n",
    "pn.area <- 100\n",
    "pn.dist <- 100\n",
    "pn.jacc <- 100\n",
    "effector_to_busco_bed <- GenometriCorr:::GenometriCorrelation(effector_bed, busco_bed,  chromosomes.to.proceed = c(\"pcontig_001\"), ecdf.area.permut.number = pn.area,mean.distance.permut.number = pn.dist,jaccard.measure.permut.number = pn.jacc,keep.distributions = TRUE, showProgressBar = FALSE)\n",
    "print(effector_to_busco_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "GenometriCorr:::graphical.report(effector_to_busco_bed, pdffile = \"../figures/Pst_104E_p_effector_to_busco_bed_pcontig_001.pdf\",  show.all = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this moves the file to a folder were jupyter can access it for displaying.\n",
    "copyanything(OUT_FOLDER_FIG, TMP_FIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDF('Pst_104E_p_effector_to_no_effector.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDF('Pst_104E_p_effector_to_busco.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDF('Pst_104E_p_effector_to_busco_vis.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDF('Pst_104E_p_effector_to_no_effector_vis.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#effectors per contig > than expected 1.5 increase?\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes']) > 1.5].loc[:,['effectors', '%effector', 'all_genes','%all_genes']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%effector'] > gene_dis_per_contig['%busco'])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) &\\\n",
    "                    (gene_dis_per_contig['%all_genes'] > gene_dis_per_contig['%busco'])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] > gene_dis_per_contig['%all_genes'])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum off all effectors on enriched? contigs\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%effector'] > gene_dis_per_contig['%all_genes']) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.2) & (gene_dis_per_contig['%busco'] > 0.5 )\\\n",
    "                    ].loc[:,['buscos', '%busco', '%all_genes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.2) \\\n",
    "                    ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.1) & \\\n",
    "                   (gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes'] < 0.9) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%all_genes'] > 1.0000001) & \\\n",
    "                   (gene_dis_per_contig['%effector'] / gene_dis_per_contig['%all_genes'] < 0.9999) ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enriched for effectors relative to busco and all genes. Seems to be the case that their might be contigs\n",
    "#with less BUSCOs and more effectors\n",
    "gene_dis_per_contig[(gene_dis_per_contig['%busco'] / gene_dis_per_contig['%effector'] < 1) & \\\n",
    "                    (gene_dis_per_contig['%all_genes'] / gene_dis_per_contig['%effector'] < 1) ].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get closest features genes vs. TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_REPET = pd.read_csv(p_repeat_superfamily_gff_fn, header=None, sep='\\t', names=gff_header)\n",
    "tmp_REPET['distance'] = tmp_REPET.end - tmp_REPET.start\n",
    "\n",
    "tmp_fn = p_repeat_superfamily_gff_fn.replace('superfamily.gff', 'tmpsuperfamily.bed')\n",
    "tmp_REPET[tmp_REPET.distance > 400].loc[:,['seqid', 'start', 'end', 'attributes', 'score', 'strand']].to_csv(tmp_fn, header=None, sep='\\t', index=None)\n",
    "\n",
    "p_repeats_bed = BedTool(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df = p_effector_bed.closest( [p_repeats_bed.fn,p_allgene_bed.fn] , mdb='all', d=True, N=True).to_dataframe()\n",
    "\n",
    "tmp_df.rename(columns={10: 'ID'}, inplace=True)\n",
    "\n",
    "print('Per of effectors having genes as closest feature %f2' % (tmp_df[tmp_df.ID.str.contains('evm')][0].count()/len(p_effector_bed)*100))\n",
    "\n",
    "print('Per of effectors having TE as closest %f2' % (tmp_df[~tmp_df.ID.str.contains('evm')][0].count()/len(p_effector_bed)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df = p_allgene_bed.closest( [p_repeats_bed.fn,p_allgene_bed.fn] , mdb='all', d=True, N=True).to_dataframe()\n",
    "\n",
    "tmp_df.rename(columns={10: 'ID'}, inplace=True)\n",
    "\n",
    "print('Per of genes having genes as closest feature %f2' % (tmp_df[tmp_df.ID.str.contains('evm')][0].count()/len(p_allgene_bed)*100))\n",
    "\n",
    "print('Per of genes having TE as closest %f2' % (tmp_df[~tmp_df.ID.str.contains('evm')][0].count()/len(p_allgene_bed)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 5 and 3 prime distances of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now get the 3 prime distante to genes using the D='a' and iu flag in bedtools\n",
    "g_to_g_3 = p_allgene_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "\n",
    "\n",
    "g_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#now get the 5 prime distante to genes using the D='a' and id flag in bedtools\n",
    "g_to_g_5 = p_allgene_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "g_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "g_to_g_merged = g_to_g_3.merge(g_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account. Filter out everythign that has a 5' distance of -1 meaning nothing\n",
    "#and is at the begining of the contig .1 and at the 3' end drop everything that has a negative distance meaning no 3' neighbour\n",
    "\n",
    "g_to_g_merged = g_to_g_merged[ (g_to_g_merged['5_target'] !='.') &(g_to_g_merged['3_target'] !='.') ]\n",
    "\n",
    "\n",
    "g_to_g_merged['5_distance'] = abs(g_to_g_merged['5_distance'])\n",
    "g_to_g_merged['5_distance_log10'] = np.log10(g_to_g_merged['5_distance'])\n",
    "g_to_g_merged['3_distance_log10'] = np.log10(g_to_g_merged['3_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\")\n",
    "\n",
    "\n",
    "\n",
    "#do the same for effectors\n",
    "#now for effectors \n",
    "#getting 5' and 3' distance\n",
    "e_to_g_3 = p_effector_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "e_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "e_to_g_5 = p_effector_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "e_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#merging them\n",
    "e_to_g_merged = e_to_g_3.merge(g_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges\n",
    "e_to_g_merged = e_to_g_merged[((e_to_g_merged['5_target'] != '.') & ((e_to_g_merged['3_target'] != '.'))) ]\n",
    "e_to_g_merged['5_distance'] = abs(e_to_g_merged['5_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\")\n",
    "\n",
    "\n",
    "#now for busco\n",
    "b_to_g_3 = p_busco_bed.closest( p_allgene_bed.fn ,  N=True, iu=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "b_to_g_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "b_to_g_5 = p_busco_bed.closest( p_allgene_bed.fn ,  N=True, id=True, D='a' ).to_dataframe().iloc[:,[0, 3, 9,12]]\n",
    "b_to_g_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "b_to_g_merged = b_to_g_3.merge(b_to_g_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges see above for details\n",
    "b_to_g_merged = b_to_g_merged[((b_to_g_merged['5_target'] !='.') & (b_to_g_merged['3_target'] !='.')) ]\n",
    "b_to_g_merged['5_distance'] = abs(b_to_g_merged['5_distance'])\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged, kind=\"kde\")\n",
    "\n",
    "#now start plotting stuff\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\", color='r', xlim=10000, ylim=10000)\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\", xlim=10000, ylim=10000)\n",
    "\n",
    "\n",
    "#subset everything by fixed numbers maybe to IQR or such in future\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged[(e_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (e_to_g_merged['3_distance'] < 10000)], kind=\"hex\", color='r',xlim=[0,10000], ylim=[0,10000],\\\n",
    "             marginal_kws=dict(bins=30))\n",
    "\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged[(b_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (b_to_g_merged['3_distance'] < 10000)], kind=\"hex\",color='g', xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged[(g_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (g_to_g_merged['3_distance'] < 10000)], kind=\"hex\", xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the distance to the closest gene of the same group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the 3 prime distante to genes using the D='a' and iu flag in bedtools\n",
    "p_allall_rand_sub = p_allgene_bed.random_subset(sub_set)\n",
    "p_effector_bed_rand_sub = p_effector_bed.random_subset(sub_set)\n",
    "p_busco_bed_rand_sub = p_busco_bed.random_subset(sub_set)\n",
    "\n",
    "all_all_rand_3 = p_allall_rand_sub.closest( p_allall_rand_sub ,  N=True, iu=True, D='a' ).to_dataframe()\n",
    "\n",
    "\n",
    "all_all_rand_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#now get the 5 prime distante to genes using the D='a' and id flag in bedtools\n",
    "all_all_rand_5 = p_allall_rand_sub.closest( p_allall_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe()\n",
    "all_all_rand_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "all_all_rand_merged = all_all_rand_3.merge(all_all_rand_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account. Filter out everythign that has a 5' distance of -1 meaning nothing\n",
    "#and is at the begining of the contig .1 <- the .1 was no appropriate here as the random subsampling can lead\n",
    "#to alternative first gene models selected on the respective contig\n",
    "#extended the initial df of closest to include also queyr and target. Now filtering on no target ='.' possible\n",
    "\n",
    "all_all_rand_merged = all_all_rand_merged[((all_all_rand_merged['5_target'] != '.')&(all_all_rand_merged['3_target'] != '.')  ) ]\n",
    "\n",
    "\n",
    "\n",
    "all_all_rand_merged['5_distance'] = abs(all_all_rand_merged['5_distance'])\n",
    "all_all_rand_merged['5_distance_log10'] = np.log10(all_all_rand_merged['5_distance'])\n",
    "all_all_rand_merged['3_distance_log10'] = np.log10(all_all_rand_merged['3_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=all_all_rand_merged, kind=\"kde\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#do the same for effectors\n",
    "#now for effectors \n",
    "#getting 5' and 3' distance\n",
    "e_to_e_sub_3 = p_effector_bed_rand_sub.closest( p_effector_bed_rand_sub ,  N=True, iu=True, D='a' ).to_dataframe()\n",
    "e_to_e_sub_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "e_to_e_sub_5 = p_effector_bed_rand_sub.closest( p_effector_bed_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe()\n",
    "e_to_e_sub_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "\n",
    "#merging them\n",
    "e_to_e_sub_merged = e_to_e_sub_3.merge(e_to_e_sub_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges\n",
    "e_to_e_sub_merged = e_to_e_sub_merged [((e_to_e_sub_merged ['5_target'] != '.') & (e_to_e_sub_merged ['3_target'] != '.') )  ]\n",
    "e_to_e_sub_merged ['5_distance'] = abs(e_to_e_sub_merged ['5_distance'])\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_e_sub_merged , kind=\"kde\", color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_busco_bed_rand_sub.closest( p_busco_bed_rand_sub.fn ,  N=True, iu=True, D='a' ).to_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#now for busco\n",
    "p_busco_bed_rand_sub_3 = p_busco_bed_rand_sub.closest( p_busco_bed_rand_sub.fn ,  N=True, iu=True, D='a' ).to_dataframe()\n",
    "p_busco_bed_rand_sub_3.rename(columns={12:'3_distance', 3:'query', 9:'3_target', 0:'contig'}, inplace=True)\n",
    "p_busco_bed_rand_sub_5 = p_busco_bed_rand_sub.closest( p_busco_bed_rand_sub.fn ,  N=True, id=True, D='a' ).to_dataframe()\n",
    "p_busco_bed_rand_sub_5.rename(columns={12:'5_distance', 3:'query', 9:'5_target', 0:'contig'}, inplace=True)\n",
    "p_busco_bed_rand_sub_merged = p_busco_bed_rand_sub_3.merge(p_busco_bed_rand_sub_5, on=['query', 'contig'])\n",
    "\n",
    "#needs to be fixed to take boundaries into account\n",
    "#remove genes on the edges see above for details\n",
    "p_busco_bed_rand_sub_merged = p_busco_bed_rand_sub_merged[((p_busco_bed_rand_sub_merged['5_target'] != '.') & (p_busco_bed_rand_sub_merged['5_target'] != '.') )]\n",
    "p_busco_bed_rand_sub_merged['5_distance'] = abs(p_busco_bed_rand_sub_merged['5_distance'])\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=p_busco_bed_rand_sub_merged, kind=\"kde\" ,color = 'green')\n",
    "\n",
    "#now start plotting stuff\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged, kind=\"kde\", color='r', xlim=10000, ylim=10000)\n",
    "#sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged, kind=\"kde\", xlim=10000, ylim=10000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some more plotting for when subsetting the dataframe to exclude outliers\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=p_busco_bed_rand_sub_merged[(p_busco_bed_rand_sub_merged['5_distance'] < 20000)&\\\n",
    "                                                                              (p_busco_bed_rand_sub_merged['3_distance'] < 20000)],\\\n",
    "              kind=\"kde\" ,color = 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some more plotting for when subsetting the dataframe to exclude outliers\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_e_sub_merged[(e_to_e_sub_merged['5_distance'] < 20000)&\\\n",
    "                                                                              (e_to_e_sub_merged['3_distance'] < 20000)],\\\n",
    "              kind=\"kde\" ,color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking more into the distance distribution between effectors use the index for this purpose and groupby or filteirng by \n",
    "#contig\n",
    "#getting 5' and 3' distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting 5' and 3' distance\n",
    "e_to_e_sub_distance = e_to_e_sub_3.merge(e_to_e_sub_5, on = ['query','contig'])\n",
    "\n",
    "#convert negative -1 from bedtools closest to nan and make values absolute\n",
    "tmp_index = e_to_e_sub_distance[e_to_e_sub_distance['5_target'] == '.'].index.tolist()\n",
    "e_to_e_sub_distance.loc[tmp_index, '5_distance'] = np.nan\n",
    "e_to_e_sub_distance['5_distance'] = abs(e_to_e_sub_distance['5_distance'])\n",
    "e_to_e_sub_3_distance['5_distance'].fillna(-1) \n",
    "#convert -1 from bedtools closest to nan in 3_distance\n",
    "tmp_index = e_to_e_sub_distance[e_to_e_sub_distance['3_target'] == '.'].index.tolist()\n",
    "e_to_e_sub_distance.loc[tmp_index, '3_distance'] = -1\n",
    "\n",
    "\n",
    "\n",
    "#now subset the dataframe for a fixed distance \n",
    "max_distance = 15000\n",
    "#subset the df and get the index first by distance and than by linkage (remember everything at the edges got a  -1 as distance)\n",
    "e_to_e_less_d_df = e_to_e_sub_distance[\\\n",
    "                        ((e_to_e_sub_distance['3_distance'] <max_distance)&(e_to_e_sub_distance['3_distance'] > - 1)) \\\n",
    "                                       | \n",
    "                        ((e_to_e_sub_distance['5_distance'] <max_distance) &(e_to_e_sub_distance['5_distance'] > -1))  ]\n",
    "\n",
    "#everything at the edges got a  -1 as distance\n",
    "\n",
    "\n",
    "#get the max distance of two consective genes in teh e_to_e_less_d_df. It could be to have A-B close and C-D close but not B-C currently\n",
    "#this would not have gotten caught.\n",
    "\n",
    "e_to_e_less_d_df['next_distance'] = abs(e_to_e_less_d_df.shift(-1)['1_x'] - e_to_e_less_d_df['2_x'])\n",
    "\n",
    "#now set everything that is not on consecutive contigs max_distance +1\n",
    "nex_contig_index = e_to_e_less_d_df[e_to_e_less_d_df.shift(-1)['contig'] != e_to_e_less_d_df['contig']].index.values\n",
    "\n",
    "e_to_e_less_d_df.loc[nex_contig_index, 'next_distance'] = max_distance +1\n",
    "\n",
    "#get the index values and not the series\n",
    "e_to_e_less_d_df_index = e_to_e_less_d_df.index.values\n",
    "\n",
    "#transfer the next_distance of the linked once the main datframe and make everything else max_distance +1\n",
    "\n",
    "e_to_e_sub_distance['next_linked_distance'] = max_distance +1\n",
    "\n",
    "e_to_e_sub_distance.loc[e_to_e_less_d_df_index, 'next_linked_distance'] = e_to_e_less_d_df.next_distance\n",
    "\n",
    "\n",
    "#introduce new column 'linked' and make this 1 were the genes are linked (e.g. less than max distance apart)\n",
    "e_to_e_sub_distance['linked'] =0\n",
    "e_to_e_sub_distance.loc[e_to_e_less_d_df_index, 'linked']  = 1\n",
    "#get a new columns linkage_group that is 0 for now\n",
    "e_to_e_sub_distance['linkage_group'] = 0\n",
    "\n",
    "#get linkage groups first filtered by consecutive index\n",
    "tmp_linkage_groups = ((e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].linked \\\n",
    "                      != e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].linked.index.to_series().diff().eq(1))).cumsum()\\\n",
    "#this also adds together genes that are not really linked because they are on a different contig or A-B close and C-D close but not B-C\n",
    "e_to_e_sub_distance.loc[e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].index, 'tmp_lg']  = tmp_linkage_groups\n",
    "\n",
    "test = e_to_e_sub_distance[e_to_e_sub_distance.linked == 1]\n",
    "#the indexes are consectutive as indicated by the tmp linkage_group\n",
    "unlinked_lg_index = test[(test.tmp_lg.shift(-1) == test.tmp_lg)][(test[(test.tmp_lg.shift(-1) == test.tmp_lg)]\\\n",
    "                                              ['next_linked_distance'] > max_distance)]\n",
    "unlinked_lg_index = (test[(test.tmp_lg.shift(-1) == test.tmp_lg)]\\\n",
    "                                              ['next_linked_distance'] > max_distance)\n",
    "#combine this remove unlinked_lg_indexs from initial linkage group by making everything Flase that is not linked.\n",
    "tmp_linkage_groups = ((e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].linked \\\n",
    "                      != e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].linked.index.to_series().diff().eq(1))\\\n",
    "| unlinked_lg_index.shift(1)).cumsum()\n",
    "e_to_e_sub_distance.loc[e_to_e_sub_distance[e_to_e_sub_distance.linked == 1].index, 'linkage_group']  = tmp_linkage_groups\n",
    "#now loop over the contigs and connect the consecutive linked effectors (e.g. linked == 1) with a cumsum \n",
    "#for contig in e_to_e_sub_distance['contig'].unique():\n",
    "   # tmp_df = e_to_e_sub_distance[e_to_e_sub_distance.contig == contig]\n",
    "    #check were the index difference is not one and add it up\n",
    "    #tmp_linkage_groups = (tmp_df[tmp_df.linked == 1].linked != tmp_df[tmp_df.linked == 1].linked.index.to_series().diff().eq(1)).cumsum() \n",
    "    # e_to_e_sub_distance.loc[tmp_df[tmp_df.linked == 1].index, 'linkage_group'] =  tmp_linkage_groups\n",
    "    #print(contig)\n",
    "#e_to_e_sub_distance = e_to_e_sub_distance.loc[:,['contig', 'query', '3_target',\\\n",
    "                                        # '3_distance', '5_target', '5_distance', 'linked', 'linkage_group', 'next_linked_distance']]\n",
    "\n",
    "\n",
    "e_to_e_sub_distance = e_to_e_sub_distance.loc[:,[ 'query', '3_target',\\\n",
    "                                         '5_target',  'linked', 'linkage_group', 'next_linked_distance']]\n",
    "e_to_e_sub_distance['lg_freq'] = e_to_e_sub_distance.groupby('linkage_group')['linkage_group'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#makeing a function out of 5' and 3' distance bining\n",
    "def _5_to_3_chains(_5_prime_df, _3_prime_df, max_distance=15000, label=''):\n",
    "    \"\"\"This function takes two dataframes one from _5_prime_ nearest neighbour and one from\n",
    "    _3_prime_nearest neighbour. max_distance and label for the df columns can be added as well.\n",
    "    Those should be generated with pybedtools and converted to dataframe\n",
    "    without subsetting and with selecting the distance.\n",
    "    Columns should be renamed as\n",
    "    12:'3_distance', 3:'query', 9:'3_target', 0:'contig' for _3_prime\n",
    "    and\n",
    "    12:'5_distance', 3:'query', 9:'5_target', 0:'contig' for _5_prime\n",
    "    The output will be new dataframe that contains the merged dataframes, the linked information, the linkage group,\n",
    "    and the frequency of each linkage group = group member count.\n",
    "    And a dataframe that summarizes the bin size, number within each bin and number of each bin.\n",
    "    member_count_label\tbin_size_label\tnumber_of_bins_label\n",
    "    \"\"\"\n",
    "    five_df = _5_prime_df.copy()\n",
    "    three_df = _3_prime_df.copy()\n",
    "    max_distance = max_distance\n",
    "    \n",
    "    #getting 5' and 3' distance\n",
    "    distance_df = three_df.merge(five_df, on = ['query','contig'])\n",
    "\n",
    "    #convert negative -1 from bedtools closest to nan and make values absolute\n",
    "    tmp_index = distance_df[distance_df['5_target'] == '.'].index\n",
    "    distance_df.loc[tmp_index, '5_distance'] = np.nan\n",
    "    distance_df['5_distance'] = abs(distance_df['5_distance'])\n",
    "    distance_df['5_distance'].fillna(-1, inplace = True) \n",
    "    #convert -1 from bedtools closest to nan in 3_distance\n",
    "    tmp_index = distance_df[distance_df['3_target'] == '.'].index\n",
    "    distance_df.loc[tmp_index, '3_distance'] = -1\n",
    "\n",
    "    #subset the df and get the index first by distance and than by linkage (remember everything at the edges got a  -1 as distance)\n",
    "    sub_distance_df = distance_df[\\\n",
    "                            ((distance_df['3_distance'] <max_distance)&(distance_df['3_distance'] > - 1)) \\\n",
    "                                           | \n",
    "                            ((distance_df['5_distance'] <max_distance) &(distance_df['5_distance'] > -1))  ]\n",
    "\n",
    "    #get the max distance of two consective genes in teh distance_df. It could be to have A-B close and C-D close but not B-C currently\n",
    "    #this would not have gotten caught. #to be illustrated\n",
    "\n",
    "    sub_distance_df['next_distance'] = abs(sub_distance_df.shift(-1)['1_x'] - sub_distance_df['2_x'])\n",
    "\n",
    "    #now set the distance to the next gene to max_distance +1 if the next contig is different\n",
    "    #from the current one\n",
    "    next_contig_index = sub_distance_df[sub_distance_df.shift(-1)['contig'] != sub_distance_df['contig']].index.values\n",
    "\n",
    "    sub_distance_df.loc[next_contig_index, 'next_distance'] = max_distance +1\n",
    "\n",
    "    #get the index values and not the series\n",
    "    sub_distance_df_index = sub_distance_df.index.values\n",
    "\n",
    "    #transfer the next_distance of the linked once the main datframe and make everything else max_distance +1\n",
    "\n",
    "    distance_df['next_linked_distance'] = max_distance +1\n",
    "\n",
    "    distance_df.loc[sub_distance_df_index, 'next_linked_distance'] = sub_distance_df.next_distance\n",
    "\n",
    "\n",
    "    #introduce new column 'linked' and make this 1 were the genes are linked (e.g. less than max distance apart)\n",
    "    distance_df['linked'] =0\n",
    "    distance_df.loc[sub_distance_df_index, 'linked']  = 1\n",
    "    #get a new columns linkage_group that is 0 for now\n",
    "    distance_df['linkage_group'] = 0\n",
    "\n",
    "    #get linkage groups first filtered by consecutive index\n",
    "    tmp_linkage_groups = ((distance_df[distance_df.linked == 1].linked \\\n",
    "                          != distance_df[distance_df.linked == 1].linked.index.to_series().diff().eq(1))).cumsum()\\\n",
    "    \n",
    "    #this also adds together genes that are not really linked because they are on a different contig or A-B close and\n",
    "    #C-D close but not B-C. We need to take care of this later on using the next_linked_distance column\n",
    "    distance_df.loc[distance_df[distance_df.linked == 1].index, 'tmp_lg']  = tmp_linkage_groups\n",
    "    \n",
    "    #generate a new sub_distance_df that has all colmuns as the main distance df\n",
    "    sub_distance_df = distance_df[distance_df.linked == 1]\n",
    "    \n",
    "    #the indexes are consectutive as indicated by the tmp linkage_group. \n",
    "    #now identify where linked sequences are separated by more than the max_distance. This includes intercontigs breaks.\n",
    "    \n",
    "    unlinked_lg_index = (sub_distance_df[(sub_distance_df.tmp_lg.shift(-1) == sub_distance_df.tmp_lg)]\\\n",
    "                                                  ['next_linked_distance'] > max_distance)\n",
    "    \n",
    "    #combine this remove unlinked_lg_indexs from initial linkage group by making everything Flase that is not linked.\n",
    "    #this requires to 'add' the unlinked_lg_index boolean array to the consecutive boolean array using an or |\n",
    "    #meaning only the Trues are transfered and this needs to be shiffted one downward (could have also done previous distance and not\n",
    "    #next)\n",
    "    \n",
    "    tmp_linkage_groups = ((distance_df[distance_df.linked == 1].linked \\\n",
    "                          != distance_df[distance_df.linked == 1].linked.index.to_series().diff().eq(1))\\\n",
    "    | unlinked_lg_index.shift(1)).cumsum()\n",
    "    \n",
    "    distance_df.loc[distance_df[distance_df.linked == 1].index, 'linkage_group']  = tmp_linkage_groups\n",
    "    \n",
    "    distance_df = distance_df.loc[:,['contig', 'query', '3_target',\\\n",
    "                                            '3_distance', '5_target', '5_distance', 'linked', 'linkage_group']]\n",
    "    #add a frequency columns to the dataframe\n",
    "    distance_df['lg_freq'] = distance_df.groupby('linkage_group')['linkage_group'].transform('count')\n",
    "    \n",
    "    #now make a bin count dataframe\n",
    "    \n",
    "    #get the counts for each lg_freq == total number of genes in a bin of size lg_freq\n",
    "    bins = distance_df[distance_df.linked !=0 ].groupby('lg_freq').count()\n",
    "    \n",
    "    #now get unlinked total number of genes ina bin size of 1\n",
    "    bin_one = distance_df[distance_df.linked ==0 ].groupby('lg_freq').count().reset_index(drop= True)\n",
    "\n",
    "    bin_one.index = [1] \n",
    "    #combine both\n",
    "    all_bins = bins.append(bin_one)\n",
    "    #use the index which represents the bin size\n",
    "    all_bins['bin_size'] = all_bins.index\n",
    "    \n",
    "    all_bins = all_bins.sort_values('bin_size').reset_index(drop=True).loc[:, ['linked', 'bin_size']]\n",
    "\n",
    "    all_bins.rename(columns={'linked': 'member_count'}, inplace=True)\n",
    "\n",
    "    all_bins['number_of_bins'] = all_bins['member_count'] / all_bins['bin_size']\n",
    "\n",
    "    #new_cnames = ['%s_%s' % (x,label) for x in all_bins.columns]\n",
    "\n",
    "    #all_bins.rename(columns=dict(zip(all_bins.columns, new_cnames)), inplace=True)\n",
    "    \n",
    "    all_bins['label'] = label\n",
    "    \n",
    "    #all_bins['bin_size'] = all_bins['bin_size_' + label]\n",
    "    return distance_df, all_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_distance = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_effector_df, bin_effector_df = _5_to_3_chains(e_to_e_sub_5,e_to_e_sub_3,max_distance=max_distance, label='effector') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_busco_df, bin_busco_df = _5_to_3_chains(p_busco_bed_rand_sub_5,p_busco_bed_rand_sub_3,max_distance=max_distance, label='busco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_all_gene_df, bin_all_gene_df = _5_to_3_chains(all_all_rand_5,all_all_rand_3,max_distance=max_distance, label = 'all_genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_bining_df = pd.concat([bin_effector_df,bin_busco_df,bin_all_gene_df ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set yourself up for the plots\n",
    "overall_bining_df['member_count_log'] = np.log2(overall_bining_df.member_count)\n",
    "\n",
    "conversion_dict = dict(zip(overall_bining_df.label.unique(), range(1,4)))\n",
    "conversion_dict_color = dict(zip(overall_bining_df.label.unique(), ['r', 'g', 'b']))\n",
    "\n",
    "#get the data labels and the color labels\n",
    "overall_bining_df['number_labels'] = overall_bining_df.label.apply(lambda x: conversion_dict[x])\n",
    "overall_bining_df['color_labels'] = overall_bining_df.label.apply(lambda x: conversion_dict_color[x])\n",
    "\n",
    "#set the overall sns style\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "#start the figure\n",
    "fig, ax = plt.subplots(1,1)\n",
    "title = \"Linkage of genes with a maximum distance of %i\" % max_distance\n",
    "#fill the figure with a scatter plot\n",
    "ax.scatter(overall_bining_df.bin_size, overall_bining_df.number_labels, s=overall_bining_df.member_count, \\\n",
    "           color =overall_bining_df['color_labels'] )\n",
    "#add the labels\n",
    "for label, x, y in zip(overall_bining_df.member_count,overall_bining_df.bin_size, overall_bining_df.number_labels ):\n",
    "    plt.annotate(label, xy =(x+0.25,y))\n",
    "plt.xlabel('bin size')\n",
    "ax.set_yticks(range(1,4))\n",
    "ax.set_yticklabels(overall_bining_df.label.unique())\n",
    "plt.title(title)\n",
    "out_file_name = \"_\".join(title.split(' '))\n",
    "fig.savefig(os.path.join(OUT_FOLDER_FIG, out_file_name+'.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#subset everything by fixed numbers maybe to IQR or such in future\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=e_to_g_merged[(e_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (e_to_g_merged['3_distance'] < 10000)], kind=\"hex\", color='r',xlim=[0,10000], ylim=[0,10000],\\\n",
    "             marginal_kws=dict(bins=30))\n",
    "\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=b_to_g_merged[(b_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (b_to_g_merged['3_distance'] < 10000)], kind=\"hex\",color='g', xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "\n",
    "sns.jointplot(x='3_distance', y='5_distance', data=g_to_g_merged[(g_to_g_merged['5_distance'] < 10000) &\\\n",
    "        (g_to_g_merged['3_distance'] < 10000)], kind=\"hex\", xlim=[0,10000], ylim=[0,10000],\\\n",
    "              marginal_kws=dict(bins=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at allele analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_QC_fn = os.path.join('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis/alleles'\\\n",
    "                           , 'Pst_104E_v12_p_ctg.h_contig_overlap.Qcov80.PctID70.alleles')\n",
    "\n",
    "allele_blast_df_fn = os.path.join('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/allele_analysis' ,'Pst_104E_v12_p_ctg.Pst_104E_v12_h_ctg.0.001.blastp.outfmt6.allele_analysis')\n",
    "\n",
    "alleles_df = pd.read_csv(allele_QC_fn, header=None, sep = '\\t', names=['p_protein', 'h_protein'])\n",
    "alleles_df['match'] = alleles_df.p_protein + alleles_df.h_protein\n",
    "\n",
    "allele_blast_df = pd.read_csv(allele_blast_df_fn, sep='\\t')\n",
    "allele_blast_df['match'] = allele_blast_df.Query + allele_blast_df.Target\n",
    "\n",
    "allele_blast_df = allele_blast_df[(allele_blast_df.match.isin(alleles_df.match))]\n",
    "\n",
    "len(allele_blast_df)\n",
    "\n",
    "allele_blast_df.head()\n",
    "\n",
    "allele_blast_df[(allele_blast_df.Query.isin(p_effector_list))]['PctID'].mean()\n",
    "\n",
    "allele_blast_df[~(allele_blast_df.Query.isin(p_effector_list))]['PctID'].mean()\n",
    "\n",
    "print(len(allele_blast_df[(allele_blast_df.Query.isin(p_effector_list))])/len(p_effector_list))\n",
    "\n",
    "print(len(allele_blast_df)/len(p_allgene_bed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
