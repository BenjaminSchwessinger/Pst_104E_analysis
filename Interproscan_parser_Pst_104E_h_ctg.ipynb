{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to read in the .tsv file of interproscan and pull out the following when having run interproscan with the following option.\n",
    "This was run like:\n",
    "$INTPRO/interproscan.sh -i ../../../v91_cns_gcoords_curs_ph_ctg_p_ctg.evm.all.protein.fa -iprlookup -goterms -pa\n",
    "and produced following file\n",
    "v91_cns_gcoords_curs_ph_ctg_p_ctg.evm.all.protein.intpro.fa.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/funnotate/Pst_79a/intpro'\n",
    "INTERPRO_TSV_FILE = 'v91_cns_gcoords_cursf_ph_ctg_a_ctg.evm.all.protein.intpro.fa.tsv'\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "ANNOTATION_FILE_BASE_PATH ='/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/funnotate/Pst_79a/fun-out/annotate_misc'\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'protein_annotation')\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_genome = 'Pst_104E_v12_h_ctg'\n",
    "OUT_PATH_P = os.path.join(OUT_PATH, p_genome)\n",
    "if not os.path.exists(OUT_PATH_P):\n",
    "    os.mkdir(OUT_PATH_P)\n",
    "#that is the path for all the proteins without removing the high coverage contigs and the proteins w/ \n",
    "#similarities to TE proteins\n",
    "OUT_PATH_P_ALL = os.path.join(OUT_PATH_P, 'ALL')\n",
    "if not os.path.exists(OUT_PATH_P_ALL):\n",
    "    os.mkdir(OUT_PATH_P_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all proteins that are in the final assembly\n",
    "p_protein_list = []\n",
    "protein_fa_file = [x for x in os.listdir(BASE_A_PATH) if p_genome in x and x.endswith('anno.protein.fa')][0]\n",
    "for protein in SeqIO.parse(os.path.join(BASE_A_PATH, protein_fa_file) , 'fasta'):\n",
    "    p_protein_list.append(protein.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpro_header = ['Protein_ID' , 'MD5', 'Length', 'DB', 'DB_accession', 'DB_description', 'Start_position', 'Stop_position', \\\n",
    "                  'e-value', 'Match Status', 'date', 'InterPro_ID', 'InterPro_description','GO_terms', 'Pathway_IDs' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_df = pd.read_csv(os.path.join(BASE_FOLDER, INTERPRO_TSV_FILE), sep ='\\t', header=None, names=interpro_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename protein names depending on the genome h or p\n",
    "def protein_id_conversion(old_protein_df):\n",
    "    '''Function that converts a old protein ID from v91 version to Pst_104E_v12 version. \n",
    "    E.g. \tevm.model.000004F_quiver.189 to evm.model.pcontig_004.189.\n",
    "    Input is a pandas series and output is a pandas series of same length.\n",
    "    '''\n",
    "    if p_genome.endswith('p_ctg'):\n",
    "        rename_df = old_protein_df.Protein_ID.str.extract(r'000([0-9]*)F_quiver.([0-9]*)')\n",
    "        rename_df['Updated_Protein_ID'] = 'evm.model.pcontig_' + rename_df[0] + '.' + rename_df[1]\n",
    "    elif p_genome.endswith('h_ctg'):\n",
    "        rename_df = old_protein_df.Protein_ID.str.extract(r'000([0-9]*)F_q?u?i?v?e?r?_?0?0?0?([0-9]*)F?_quiver.([0-9]*)')\n",
    "        \n",
    "        rename_df['Updated_Protein_ID'] = 'evm.model.hcontig_' + rename_df[0] + '_' + rename_df[1] +'.' + rename_df[2]\n",
    "    return rename_df['Updated_Protein_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "interpro_df['Updated_Protein_ID'] = protein_id_conversion(interpro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Length</th>\n",
       "      <th>DB</th>\n",
       "      <th>DB_accession</th>\n",
       "      <th>DB_description</th>\n",
       "      <th>Start_position</th>\n",
       "      <th>Stop_position</th>\n",
       "      <th>e-value</th>\n",
       "      <th>Match Status</th>\n",
       "      <th>date</th>\n",
       "      <th>InterPro_ID</th>\n",
       "      <th>InterPro_description</th>\n",
       "      <th>GO_terms</th>\n",
       "      <th>Pathway_IDs</th>\n",
       "      <th>Updated_Protein_ID</th>\n",
       "      <th>Dbxref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evm.model.000014F_quiver_000117F_quiver.28</td>\n",
       "      <td>f7d31a00c92d480a23f48a3138c52642</td>\n",
       "      <td>308</td>\n",
       "      <td>TMHMM</td>\n",
       "      <td>TMhelix</td>\n",
       "      <td>Region of a membrane-bound protein predicted t...</td>\n",
       "      <td>235</td>\n",
       "      <td>257</td>\n",
       "      <td>-</td>\n",
       "      <td>T</td>\n",
       "      <td>19-11-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evm.model.hcontig_014_117.28</td>\n",
       "      <td>Dbxref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evm.model.000014F_quiver_000117F_quiver.28</td>\n",
       "      <td>f7d31a00c92d480a23f48a3138c52642</td>\n",
       "      <td>308</td>\n",
       "      <td>MobiDBLite</td>\n",
       "      <td>mobidb-lite</td>\n",
       "      <td>consensus disorder prediction</td>\n",
       "      <td>285</td>\n",
       "      <td>308</td>\n",
       "      <td>-</td>\n",
       "      <td>T</td>\n",
       "      <td>19-11-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evm.model.hcontig_014_117.28</td>\n",
       "      <td>Dbxref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evm.model.000003F_002_quiver.160</td>\n",
       "      <td>9c25d3497e14151d2c486b5d57addc34</td>\n",
       "      <td>181</td>\n",
       "      <td>PANTHER</td>\n",
       "      <td>PTHR33069:SF3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>175</td>\n",
       "      <td>3.5E-38</td>\n",
       "      <td>T</td>\n",
       "      <td>19-11-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evm.model.hcontig_003_2.160</td>\n",
       "      <td>Dbxref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evm.model.000003F_002_quiver.160</td>\n",
       "      <td>9c25d3497e14151d2c486b5d57addc34</td>\n",
       "      <td>181</td>\n",
       "      <td>PANTHER</td>\n",
       "      <td>PTHR33069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>175</td>\n",
       "      <td>3.5E-38</td>\n",
       "      <td>T</td>\n",
       "      <td>19-11-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evm.model.hcontig_003_2.160</td>\n",
       "      <td>Dbxref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evm.model.000055F_012_quiver.53</td>\n",
       "      <td>924e1702ee24a994dc950eb4560364d8</td>\n",
       "      <td>151</td>\n",
       "      <td>CDD</td>\n",
       "      <td>cd04413</td>\n",
       "      <td>NDPk_I</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2.89677E-86</td>\n",
       "      <td>T</td>\n",
       "      <td>19-11-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evm.model.hcontig_055_12.53</td>\n",
       "      <td>Dbxref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Protein_ID  \\\n",
       "0  evm.model.000014F_quiver_000117F_quiver.28   \n",
       "1  evm.model.000014F_quiver_000117F_quiver.28   \n",
       "2            evm.model.000003F_002_quiver.160   \n",
       "3            evm.model.000003F_002_quiver.160   \n",
       "4             evm.model.000055F_012_quiver.53   \n",
       "\n",
       "                                MD5  Length          DB   DB_accession  \\\n",
       "0  f7d31a00c92d480a23f48a3138c52642     308       TMHMM        TMhelix   \n",
       "1  f7d31a00c92d480a23f48a3138c52642     308  MobiDBLite    mobidb-lite   \n",
       "2  9c25d3497e14151d2c486b5d57addc34     181     PANTHER  PTHR33069:SF3   \n",
       "3  9c25d3497e14151d2c486b5d57addc34     181     PANTHER      PTHR33069   \n",
       "4  924e1702ee24a994dc950eb4560364d8     151         CDD        cd04413   \n",
       "\n",
       "                                      DB_description  Start_position  \\\n",
       "0  Region of a membrane-bound protein predicted t...             235   \n",
       "1                      consensus disorder prediction             285   \n",
       "2                                                NaN              20   \n",
       "3                                                NaN              20   \n",
       "4                                             NDPk_I               5   \n",
       "\n",
       "   Stop_position      e-value Match Status        date InterPro_ID  \\\n",
       "0            257            -            T  19-11-2016           0   \n",
       "1            308            -            T  19-11-2016           0   \n",
       "2            175      3.5E-38            T  19-11-2016           0   \n",
       "3            175      3.5E-38            T  19-11-2016           0   \n",
       "4            134  2.89677E-86            T  19-11-2016           0   \n",
       "\n",
       "  InterPro_description GO_terms Pathway_IDs            Updated_Protein_ID  \\\n",
       "0                  NaN        0           0  evm.model.hcontig_014_117.28   \n",
       "1                  NaN        0           0  evm.model.hcontig_014_117.28   \n",
       "2                  NaN        0           0   evm.model.hcontig_003_2.160   \n",
       "3                  NaN        0           0   evm.model.hcontig_003_2.160   \n",
       "4                  NaN        0           0   evm.model.hcontig_055_12.53   \n",
       "\n",
       "   Dbxref  \n",
       "0  Dbxref  \n",
       "1  Dbxref  \n",
       "2  Dbxref  \n",
       "3  Dbxref  \n",
       "4  Dbxref  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_df.GO_terms.fillna(0, inplace = True)\n",
    "interpro_df.Pathway_IDs.fillna(0, inplace =True)\n",
    "interpro_df.InterPro_ID.fillna(0,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_by_protein = interpro_df.groupby('Updated_Protein_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBs = interpro_df.DB.unique()\n",
    "interpro_df['Dbxref'] = 'Dbxref'\n",
    "for db in DBs:\n",
    "    interpro_df[(interpro_df.DB == db) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P, db+'_terms.tab'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Dbxref','DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P, 'annotations.' +db+'.txt'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) ].loc[:,['Updated_Protein_ID', 'DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P_ALL, db+'_terms_all.tab'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) ].loc[:,['Updated_Protein_ID', 'Dbxref','DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.' +db+'_all.txt'), sep='\\t', header =None, index = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write out the interpro domains\n",
    "interpro_df['InterPro'] = 'InterPro'\n",
    "interpro_df[(interpro_df.InterPro_ID != 0) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'InterPro_ID']].to_csv(os.path.join(OUT_PATH_P, 'iprscan_terms.tab'), sep='\\t', header =None, index = None)\n",
    "interpro_df[interpro_df.InterPro_ID != 0].loc[:,['Updated_Protein_ID', 'InterPro_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'iprscan_terms_all.tab'), sep='\\t', header =None, index = None)\n",
    "#write out annotations\n",
    "interpro_df[(interpro_df.InterPro_ID != 0) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))]\\\n",
    ".loc[:,['Updated_Protein_ID', 'InterPro','InterPro_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.iprscan.txt'), sep='\\t', header =None, index = None)\n",
    "#write out annotations for all proteins\n",
    "interpro_df[interpro_df.InterPro_ID != 0].loc[:,['Updated_Protein_ID', 'InterPro','InterPro_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.iprscan_all.tab'), sep='\\t', header =None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process the pathway files\n",
    "interpro_by_protein_KEGG = interpro_df[interpro_df.Pathway_IDs.str.contains('KEGG' or 'MetaCyc' or 'Reactome').fillna(False)]\n",
    "\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG.groupby('Updated_Protein_ID')\n",
    "\n",
    "#pull out all the KEGG terms and write them out as annotation files \n",
    "interpro_by_protein_KEGG = interpro_by_protein.Pathway_IDs.apply(set)\n",
    "\n",
    "#remove everything without KEGG term attached\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG[~(interpro_by_protein_KEGG == {0})]\n",
    "\n",
    "interpro_by_protein_KEGG_dict = dict(zip(interpro_by_protein_KEGG.index, interpro_by_protein_KEGG))\n",
    "\n",
    "ALL_KEGG_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_KEGG_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_KEGG_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_KEGG_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "KEGG_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_KEGG_LIST]).T\n",
    "KEGG_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "KEGG_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'Pathway_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'Pathway_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "KEGG_df['Transfer_ID'] = 'note'\n",
    "KEGG_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.Pathway_all.txt') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.Pathway.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all the GO terms and write them out as annotation files \n",
    "interpro_by_protein_GO = interpro_by_protein.GO_terms.apply(set)\n",
    "\n",
    "#remove everything without GO term attached\n",
    "interpro_by_protein_GO = interpro_by_protein_GO[~(interpro_by_protein_GO == {0})]\n",
    "\n",
    "interpro_by_protein_GO_dict = dict(zip(interpro_by_protein_GO.index, interpro_by_protein_GO))\n",
    "\n",
    "ALL_GO_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_GO_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_GO_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_GO_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "GO_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_GO_LIST]).T\n",
    "GO_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "GO_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'GO_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'GO_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "GO_df['Transfer_ID'] = 'note'\n",
    "GO_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.GO_all.txt') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.GO.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out other annotations files including busco, dbCAN, merops, swissprot\n",
    "annotation_files = [os.path.join(ANNOTATION_FILE_BASE_PATH, x) for x in os.listdir(ANNOTATION_FILE_BASE_PATH) \\\n",
    "                    if x.startswith('annotations') and (x.endswith('busco.txt') or x.endswith('dbCAN.txt') or x.endswith('merops.txt') or x.endswith('swissprot.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "for anno in annotation_files:\n",
    "    _tmp_df = pd.read_csv(anno, header=None, sep='\\t', names=['Protein_ID','Transfer_ID', 'DB_ID'])\n",
    "    anno_file_name = anno.split('/')[-1]\n",
    "    anno_midfix = anno_file_name.split('.')[1]\n",
    "    _tmp_df['Updated_Protein_ID'] = protein_id_conversion(_tmp_df)\n",
    "    #write out filtered down tab file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P, anno_midfix+'_terms.tab'), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].\\\n",
    "    to_csv(os.path.join(OUT_PATH_P, anno_file_name ), sep = '\\t', header =None, index=None)\n",
    "     #write out not down tab file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_midfix+'_terms_all.tab' ), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_file_name.replace('.txt', '_all.txt') ), sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
