{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to read in the .tsv file of interproscan and pull out the following when having run interproscan with the following option.\n",
    "This was run like:\n",
    "$INTPRO/interproscan.sh -i ../../../v91_cns_gcoords_curs_ph_ctg_p_ctg.evm.all.protein.fa -iprlookup -goterms -pa\n",
    "and produced following file\n",
    "v91_cns_gcoords_curs_ph_ctg_p_ctg.evm.all.protein.intpro.fa.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_FOLDER = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/funnotate/Pst_79a/intpro'\n",
    "INTERPRO_TSV_FILE = 'v91_cns_gcoords_cursf_ph_ctg_a_ctg.evm.all.protein.intpro.fa.tsv'\n",
    "BASE_AA_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12'\n",
    "BASE_A_PATH = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/032017_assembly'\n",
    "ANNOTATION_FILE_BASE_PATH ='/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/funnotate/Pst_79a/fun-out/annotate_misc'\n",
    "OUT_PATH = os.path.join(BASE_AA_PATH, 'protein_annotation')\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_genome = 'Pst_104E_v12_h_ctg'\n",
    "OUT_PATH_P = os.path.join(OUT_PATH, p_genome)\n",
    "if not os.path.exists(OUT_PATH_P):\n",
    "    os.mkdir(OUT_PATH_P)\n",
    "#that is the path for all the proteins without removing the high coverage contigs and the proteins w/ \n",
    "#similarities to TE proteins\n",
    "OUT_PATH_P_ALL = os.path.join(OUT_PATH_P, 'ALL')\n",
    "if not os.path.exists(OUT_PATH_P_ALL):\n",
    "    os.mkdir(OUT_PATH_P_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all proteins that are in the final assembly\n",
    "p_protein_list = []\n",
    "protein_fa_file = [x for x in os.listdir(BASE_A_PATH) if p_genome in x and x.endswith('anno.protein.fa')][0]\n",
    "for protein in SeqIO.parse(os.path.join(BASE_A_PATH, protein_fa_file) , 'fasta'):\n",
    "    p_protein_list.append(protein.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpro_header = ['Protein_ID' , 'MD5', 'Length', 'DB', 'DB_accession', 'DB_description', 'Start_position', 'Stop_position', \\\n",
    "                  'e-value', 'Match Status', 'date', 'InterPro_ID', 'InterPro_description','GO_terms', 'Pathway_IDs' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_df = pd.read_csv(os.path.join(BASE_FOLDER, INTERPRO_TSV_FILE), sep ='\\t', header=None, names=interpro_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename protein names depending on the genome h or p\n",
    "def protein_id_conversion(old_protein_df):\n",
    "    '''Function that converts a old protein ID from v91 version to Pst_104E_v12 version. \n",
    "    E.g. \tevm.model.000004F_quiver.189 to evm.model.pcontig_004.189.\n",
    "    Input is a pandas series and output is a pandas series of same length.\n",
    "    '''\n",
    "    if p_genome.endswith('p_ctg'):\n",
    "        rename_df = old_protein_df.Protein_ID.str.extract(r'000([0-9]*)F_quiver.([0-9]*)')\n",
    "        rename_df['Updated_Protein_ID'] = 'evm.model.pcontig_' + rename_df[0] + '.' + rename_df[1]\n",
    "    elif p_genome.endswith('h_ctg'):\n",
    "        rename_df = old_protein_df.Protein_ID.str.extract(r'000([0-9]*)F_q?u?i?v?e?r?_?0?0?0?([0-9]*)F?_quiver.([0-9]*)')\n",
    "        \n",
    "        rename_df['Updated_Protein_ID'] = 'evm.model.pcontig_' + rename_df[0] + '_' + rename_df[1] +'.' + rename_df[2]\n",
    "    return rename_df['Updated_Protein_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "interpro_df['Updated_Protein_ID'] = protein_id_conversion(interpro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_df.GO_terms.fillna(0, inplace = True)\n",
    "interpro_df.Pathway_IDs.fillna(0, inplace =True)\n",
    "interpro_df.InterPro_ID.fillna(0,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpro_by_protein = interpro_df.groupby('Updated_Protein_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBs = interpro_df.DB.unique()\n",
    "interpro_df['Dbxref'] = 'Dbxref'\n",
    "for db in DBs:\n",
    "    interpro_df[(interpro_df.DB == db) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P, db+'_terms.tab'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Dbxref','DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P, 'annotations.' +db+'.txt'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) ].loc[:,['Updated_Protein_ID', 'DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P_ALL, db+'_terms_all.tab'), sep='\\t', header =None, index = None)\n",
    "    interpro_df[(interpro_df.DB == db) ].loc[:,['Updated_Protein_ID', 'Dbxref','DB']]\\\n",
    "    .to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.' +db+'_all.txt'), sep='\\t', header =None, index = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write out the interpro domains\n",
    "interpro_df['InterPro'] = 'InterPro'\n",
    "interpro_df[(interpro_df.InterPro_ID != 0) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'InterPro_ID']].to_csv(os.path.join(OUT_PATH_P, 'iprscan_terms.tab'), sep='\\t', header =None, index = None)\n",
    "interpro_df[interpro_df.InterPro_ID != 0].loc[:,['Updated_Protein_ID', 'InterPro_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'iprscan_terms_all.tab'), sep='\\t', header =None, index = None)\n",
    "#write out annotations\n",
    "interpro_df[(interpro_df.InterPro_ID != 0) & (interpro_df.Updated_Protein_ID.isin(p_protein_list))]\\\n",
    ".loc[:,['Updated_Protein_ID', 'InterPro','InterPro_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.iprscan.txt'), sep='\\t', header =None, index = None)\n",
    "#write out annotations for all proteins\n",
    "interpro_df[interpro_df.InterPro_ID != 0].loc[:,['Updated_Protein_ID', 'InterPro','InterPro_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.iprscan_all.tab'), sep='\\t', header =None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process the pathway files\n",
    "interpro_by_protein_KEGG = interpro_df[interpro_df.Pathway_IDs.str.contains('KEGG' or 'MetaCyc' or 'Reactome').fillna(False)]\n",
    "\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG.groupby('Updated_Protein_ID')\n",
    "\n",
    "#pull out all the KEGG terms and write them out as annotation files \n",
    "interpro_by_protein_KEGG = interpro_by_protein.Pathway_IDs.apply(set)\n",
    "\n",
    "#remove everything without KEGG term attached\n",
    "interpro_by_protein_KEGG = interpro_by_protein_KEGG[~(interpro_by_protein_KEGG == {0})]\n",
    "\n",
    "interpro_by_protein_KEGG_dict = dict(zip(interpro_by_protein_KEGG.index, interpro_by_protein_KEGG))\n",
    "\n",
    "ALL_KEGG_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_KEGG_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_KEGG_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_KEGG_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "KEGG_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_KEGG_LIST]).T\n",
    "KEGG_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "KEGG_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'Pathway_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'Pathway_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "KEGG_df['Transfer_ID'] = 'note'\n",
    "KEGG_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.Pathway_all.txt') , sep = '\\t', header =None, index=None)\n",
    "KEGG_df[KEGG_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.Pathway.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out all the GO terms and write them out as annotation files \n",
    "interpro_by_protein_GO = interpro_by_protein.GO_terms.apply(set)\n",
    "\n",
    "#remove everything without GO term attached\n",
    "interpro_by_protein_GO = interpro_by_protein_GO[~(interpro_by_protein_GO == {0})]\n",
    "\n",
    "interpro_by_protein_GO_dict = dict(zip(interpro_by_protein_GO.index, interpro_by_protein_GO))\n",
    "\n",
    "ALL_GO_LIST = []\n",
    "ALL_PROTEIN_INDEX_LIST = []\n",
    "for key in list(interpro_by_protein_GO_dict.keys()):\n",
    "    _tmp_list = list(interpro_by_protein_GO_dict[key])\n",
    "    #remove 0 \n",
    "    _tmp_list = [x for x in _tmp_list if x != 0]\n",
    "    new_value = []\n",
    "    for x in _tmp_list: \n",
    "        if '|' in x:\n",
    "            _list = x.split('|')\n",
    "            for y in _list:\n",
    "                new_value.append(y)\n",
    "        else:\n",
    "            new_value.append(x)\n",
    "    new_value = list(set(new_value))\n",
    "    new_index = [key]*len(new_value)\n",
    "    ALL_GO_LIST += new_value\n",
    "    ALL_PROTEIN_INDEX_LIST += new_index\n",
    "\n",
    "\n",
    "GO_df = pd.DataFrame([ALL_PROTEIN_INDEX_LIST, ALL_GO_LIST]).T\n",
    "GO_df.rename(columns={0:'Updated_Protein_ID', 1:'DB_ID'}, inplace=True)\n",
    "\n",
    "GO_df.to_csv(os.path.join(OUT_PATH_P_ALL, 'GO_terms_ipr_all.tab') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].to_csv(os.path.join(OUT_PATH_P, 'GO_terms_ipr.tab') , sep = '\\t', header =None, index=None)\n",
    "#write out annotations\n",
    "GO_df['Transfer_ID'] = 'note'\n",
    "GO_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, 'annotations.GO_all.txt') , sep = '\\t', header =None, index=None)\n",
    "GO_df[GO_df.Updated_Protein_ID.isin(p_protein_list)].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P, 'annotations.GO.txt') , sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out other annotations files including busco, dbCAN, merops, swissprot\n",
    "annotation_files = [os.path.join(ANNOTATION_FILE_BASE_PATH, x) for x in os.listdir(ANNOTATION_FILE_BASE_PATH) \\\n",
    "                    if x.startswith('annotations') and (x.endswith('busco.txt') or x.endswith('dbCAN.txt') or x.endswith('merops.txt') or x.endswith('swissprot.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "for anno in annotation_files:\n",
    "    _tmp_df = pd.read_csv(anno, header=None, sep='\\t', names=['Protein_ID','Transfer_ID', 'DB_ID'])\n",
    "    anno_file_name = anno.split('/')[-1]\n",
    "    anno_midfix = anno_file_name.split('.')[1]\n",
    "    _tmp_df['Updated_Protein_ID'] = protein_id_conversion(_tmp_df)\n",
    "    #write out filtered down tab file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P, anno_midfix+'_terms.tab'), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df[(_tmp_df.Updated_Protein_ID.isin(p_protein_list))].loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].\\\n",
    "    to_csv(os.path.join(OUT_PATH_P, anno_file_name ), sep = '\\t', header =None, index=None)\n",
    "     #write out not down tab file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_midfix+'_terms_all.tab' ), sep = '\\t', header =None, index=None)\n",
    "    #write out the filtered annotation file\n",
    "    _tmp_df.loc[:,['Updated_Protein_ID', 'Transfer_ID','DB_ID']].to_csv(os.path.join(OUT_PATH_P_ALL, anno_file_name.replace('.txt', '_all.txt') ), sep = '\\t', header =None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
