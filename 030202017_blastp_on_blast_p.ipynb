{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.h_on_p.blast.alloutfmt6', 'Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.p_on_h.blast.alloutfmt6']\n",
      "['Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.fa', 'Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.fa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "\n",
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p')\n",
    "\"\"\"\n",
    "Run on command line the following.\n",
    "blastp -query Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.fa -db Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.fa  -outfmt 6 -evalue 1e-5 -num_threads 6 > Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.p_on_h.blast.alloutfmt6 &\n",
    "blastp -query Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.fa  -db Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.protein.fa  -outfmt 6 -evalue 1e-5 -num_threads 6 > Pst_E104_v1_h_ctg.anno.RepaseTPSI_filtered.protein.h_on_p.blast.alloutfmt6&\n",
    "\"\"\"\n",
    "\n",
    "os.listdir()\n",
    "hit_df =''\n",
    "files = os.listdir()\n",
    "outfmt6 = [x for x in files if x.endswith('blast.alloutfmt6') and 'anno' in x]\n",
    "outfmt6.sort()\n",
    "print(outfmt6)\n",
    "fa_files = [x for x in files if x.endswith('RepaseTPSI_filtered.protein.fa')]\n",
    "fa_files.sort()\n",
    "print(fa_files)\n",
    "\n",
    "#The next block should pull in both the initial protein and the blast df.\n",
    "#The initial protein should become a dataframe that contains proteins sequence name and length.\n",
    "#This df should be merged with the blast df in a way that proteins without hit should get NA values. \n",
    "#Once this is done make two arrays with [p, h], sort this and compare, pull out everything that is identical, and lable it with a new column reverse blast Yes/No.\n",
    "#Pull out YES and see if they are enriched/depelted in something. NOs need to be checked for high coverage in ph vs h/p mapping and levels of heterozycosity + h on p mapping mappings. \n",
    "\n",
    "#read in protein ids for p and h contigs and store names in a list in a dict with unique key id [first part of\n",
    "#file name].\n",
    "fa_protein_dict = {}\n",
    "fa_protein_length_dict = {}\n",
    "for file in fa_files:\n",
    "    seq_list = []\n",
    "    length_list =[]\n",
    "    for seq in SeqIO.parse(open(file), 'fasta'):\n",
    "        seq_list.append(seq.id)\n",
    "        length_list.append(len(seq.seq))\n",
    "    key_name = file.split('.')[0]\n",
    "    fa_protein_dict[key_name] = seq_list\n",
    "    fa_protein_length_dict[key_name] = dict(zip(seq_list, length_list))\n",
    "\n",
    "#generate df dict of blast output and filter blast output\n",
    "header = ['Query', 'Target', 'PctID', 'AlnLgth', 'NumMis', 'NumGap', 'StartQuery', 'StopQuery', 'StartTarget',\\\n",
    "              'StopTarget', 'e-value','BitScore']\n",
    "outfmt6_dict ={} #contains the filtered values\n",
    "outfmt6_dict_all = {} #contains the unfiltered blast hits e.g. low % identity and low query coverage\n",
    "#match_dict = {} #get best hits in match_dict[p_protein] = h_protein\n",
    "hit_df = pd.DataFrame(columns=['p_protein', 'h_protein'])\n",
    "for outfile in outfmt6:\n",
    "    key_name =  outfile.split('.')[0]\n",
    "    df = ''\n",
    "    df = pd.read_csv(outfile, header = None, names = header, sep='\\t')\n",
    "    #add the query length using to the df using the length dict generated before\n",
    "    df[\"QLgth\"] = df[\"Query\"].apply(lambda x: fa_protein_length_dict[key_name][x]) \n",
    "    df[\"QCov\"] = df['AlnLgth']/df['QLgth']*100 #calculate the % coverage for each querry\n",
    "    outfmt6_dict_all[key_name] = df\n",
    "    df = df[(df['QCov'] > 30) & (df['PctID'] > 50) ] #define paralogous as Query coverage > 30% and PctID > 50\n",
    "    #this could be more dynamic and the outfmt of blast AlnLngthPct and they greater than 60%\n",
    "    groups = df.groupby(by='Query')\n",
    "    #now filter the dataframe by the smallest e-value for each group == Query\n",
    "    df_filtered = groups.apply(lambda g: g[g['e-value'] == g['e-value'].min()]) \n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    #in case there is a blast query that hits the same subject twice with the same minimal e-value\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['Query', 'Target'], keep ='last')\n",
    "    outfmt6_dict[key_name] = df_filtered\n",
    "    if 'p_ctg' in key_name:\n",
    "        df_filtered['h_protein'] = df_filtered['Target']\n",
    "        df_filtered['p_protein'] = df_filtered['Query']\n",
    "    if 'h_ctg' in key_name:\n",
    "        df_filtered['h_protein'] = df_filtered['Query']\n",
    "        df_filtered['p_protein'] = df_filtered['Target']\n",
    "    hit_df = pd.concat([hit_df, df_filtered.loc[:, ['p_protein', 'h_protein']]])\n",
    "\n",
    "#duplicates are besties as they are entered twice from both outfmt\n",
    "\n",
    "bestie_df = hit_df[hit_df.duplicated(keep='first')]\n",
    "\n",
    "bestie_df.to_csv(list(outfmt6_dict.keys())[0][:-6] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "bestie_df['p_protein'].to_csv(list(outfmt6_dict.keys())[0] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "bestie_df['h_protein'].to_csv(list(outfmt6_dict.keys())[1] + '.besties.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "\n",
    "#this is pulling out the no blast hits at all. Should be a subset of no_besties\n",
    "no_hits ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_hits[key] = set(fa_protein_dict[key]) - set(outfmt6_dict_all[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits[key])).to_csv(key + '.p_proteins.no_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_hits[key] = set(fa_protein_dict[key]) - set(outfmt6_dict_all[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits[key])).to_csv(key + '.h_proteins.no_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "no_hits_filtered ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_hits_filtered[key] = set(fa_protein_dict[key]) - set(outfmt6_dict[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits_filtered[key])).to_csv(key + '.p_proteins.no_filtered_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_hits_filtered[key] = set(fa_protein_dict[key]) - set(outfmt6_dict[key]['Query'].unique())\n",
    "        pd.DataFrame(list(no_hits_filtered[key])).to_csv(key + '.h_proteins.no_filtered_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "        \n",
    "\n",
    "#this is now pulling out the besties\n",
    "no_bestie ={}\n",
    "for key in fa_protein_dict.keys():\n",
    "    if 'p_' in key:\n",
    "        no_bestie[key] = set(fa_protein_dict[key]) - set(bestie_df['p_protein'])\n",
    "        pd.DataFrame(list(no_bestie[key])).to_csv(key + '.p_proteins.no_besties.txt', sep='\\t', header=None, index=None)\n",
    "    if 'h_' in key:\n",
    "        no_bestie[key] = set(fa_protein_dict[key]) - set(bestie_df['h_protein'])\n",
    "        pd.DataFrame(list(no_bestie[key])).to_csv(key + '.h_proteins.no_besties.txt', sep='\\t', header=None, index=None)        \n",
    "        \n",
    "_len_out = 0\n",
    "_len_pro = 0\n",
    "for x in fa_protein_dict.keys():\n",
    "    _len_pro += len(fa_protein_dict[x])\n",
    "    _len_out += len(no_bestie[x])\n",
    "_len_out += (len(bestie_df))*2 - bestie_df.duplicated(subset=\"p_protein\", keep='last').sum() \\\n",
    "- bestie_df.duplicated(subset=\"h_protein\", keep='last').sum()\n",
    "_len_out == _len_pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 14321 2496 have no reciprocal blast hit for Pst_E104_v1_h_ctg making it 17.43 percent.\n",
      "Out of 14321 333 have no blast hit at all for Pst_E104_v1_h_ctg making it 2.33 percent.\n",
      "Out of 14321 542 have no blast hit after filtering by AlnLght and QCov for Pst_E104_v1_h_ctg making it 3.78 percent.\n",
      "Out of 15930 4261 have no reciprocal blast hit for Pst_E104_v1_p_ctg making it 26.75 percent.\n",
      "Out of 15930 1236 have no blast hit at all for Pst_E104_v1_p_ctg making it 7.76 percent.\n",
      "Out of 15930 2134 have no blast hit after filtering by AlnLght and QCov for Pst_E104_v1_p_ctg making it 13.40 percent.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_len_out = 0\n",
    "_len_pro = 0\n",
    "for x in fa_protein_dict.keys():\n",
    "    _len_pro += len(fa_protein_dict[x])\n",
    "    _len_out += len(no_bestie[x])\n",
    "    print(\"Out of %i %i have no reciprocal blast hit for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_bestie[x]),x, (len(no_bestie[x])/len(fa_protein_dict[x])*100) ))\n",
    "    print(\"Out of %i %i have no blast hit at all for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_hits[x]),x, (len(no_hits[x])/len(fa_protein_dict[x])*100) ))\n",
    "    print(\"Out of %i %i have no blast hit after filtering by AlnLght and QCov for %s making it %.2f percent.\"%(len(fa_protein_dict[x]),len(no_hits_filtered[x]),x, (len(no_hits_filtered[x])/len(fa_protein_dict[x])*100) ))\n",
    "_len_out += (len(bestie_df))*2 - bestie_df.duplicated(subset=\"p_protein\", keep='last').sum() \\\n",
    "- bestie_df.duplicated(subset=\"h_protein\", keep='last').sum()\n",
    "_len_out == _len_pro"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#now pull gene sequences for no-besties and do blast on the corresponding other haplotype\n",
    "#gene files were generated by \n",
    "cat Pst_E104_v1_p_ctg.anno.RepaseTPSI_filtered.gff3 | awk '$3==\"gene\"' > Pst_E104_v1_p_ctg.gene.RepaseTPSI_filtered.gff3\n",
    "for gff in gene_gff:\n",
    "    gene = ''\n",
    "    gene_df = pd.read_csv(folder + gff, header = None, sep='\\t' )\n",
    "    gene_df[2] = gene_df[8].apply(col_8_id)\n",
    "    gene_df.to_csv(folder+gff, header=None, sep='\\t', index=None)\n",
    "bedtools getfasta -s -name -fi Pst_E104_v1_ph_ctg.fa -bed Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.gff3 -fo Pst_E104_v1_ph_ctg.gene.RepaseTPSI_filtered.fa\n",
    "bedtools getfasta -s -name -bed Pst_E104_v1_h_ctg.gene.RepaseTPSI_filtered.gff3 -fi Pst_E104_v1_h_ctg.fa -fo Pst_E104_v1_h_ctg.gene.RepaseTPSI_filtered.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_outfmt6_to_bed(x):\n",
    "    blast_fo = open(x, 'r')\n",
    "    blast_lines = blast_fo.readlines()\n",
    "    bed_file_name = x + '.bed'\n",
    "    bed_fo = open(bed_file_name, 'w+')\n",
    "    for l in blast_lines:\n",
    "        content = l.split('\\t')\n",
    "        if int(content[8]) - int(content[9]) < 1:\n",
    "            print(content[1], int(content[8]) -1, content[9], content[0], content[10], \"+\", sep=\"\\t\", file=bed_fo) \n",
    "        else:\n",
    "            print(content[1], int(content[9]) -1, content[8],  content[0], content[10], \"-\", sep = \"\\t\", file=bed_fo)\n",
    "    blast_fo.close()\n",
    "    bed_fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastn -db Pst_E104_v1_p_ctg.fa -query -Pst_E104_v1_h_ctg.h_genes.no_besties.fa > Pst_E104_v1_h_ctg.h_genes.no_besties.fa.outfmt6\n",
      "blastn -db Pst_E104_v1_h_ctg.fa -query -Pst_E104_v1_p_ctg.p_genes.no_besties.fa > Pst_E104_v1_p_ctg.p_genes.no_besties.fa.outfmt6\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "folder_p = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p/'\n",
    "\n",
    "no_besties = [x for x in os.listdir(folder_p) if x.endswith('no_besties.txt')]\n",
    "gene_files = [x for x in os.listdir(folder_p) if '.gene.' in x and '.fa' in x]\n",
    "no_besties.sort()\n",
    "gene_files.sort()\n",
    "no_bestie_dict = {}\n",
    "\n",
    "#simply pulls in the gene sequences of missing besties\n",
    "for no_b, gene_file in zip(no_besties, gene_files):\n",
    "    no_bestie_list = pd.read_csv(folder_p+no_b, header=None, sep='\\t')[0].tolist()\n",
    "    key = no_b.split('.')[0]\n",
    "    no_bestie_dict[key] = no_bestie_list\n",
    "    no_bestie_list = [x.replace('evm.model', 'evm.TU') for x in no_bestie_list]\n",
    "    no_bestie_seq = []\n",
    "    for seq in SeqIO.parse(open(folder_p + gene_file), 'fasta'):\n",
    "        if seq.id in no_bestie_list:\n",
    "            no_bestie_seq.append(seq)\n",
    "    out_f = folder_p + no_b[:-3].replace('protein', 'gene') + 'fa'\n",
    "    f_handle = open(out_f,'w') #need to generate handle for writing and\n",
    "    SeqIO.write(no_bestie_seq, f_handle, 'fasta')\n",
    "    f_handle.close() #closing file afterwards again\n",
    "\n",
    "gene_files_no_besties = [x for x in os.listdir(folder_p) if x.endswith('_genes.no_besties.fa')]\n",
    "blast_db_nt = [x for x in os.listdir(folder_p) if x.endswith('_ctg.fa')]\n",
    "gene_files_no_besties.sort()\n",
    "blast_db_nt.sort()\n",
    "\n",
    "os.chdir(folder_p)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[1], gene_files_no_besties[0],gene_files_no_besties[0]))\n",
    "!blastn -db {blast_db_nt[1]} -query {gene_files_no_besties[0]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_besties[0]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_besties[0]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[0], gene_files_no_besties[1],gene_files_no_besties[1]))\n",
    "!blastn -db {blast_db_nt[0]} -query {gene_files_no_besties[1]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_besties[1]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_besties[1]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pst_E104_v1_h_ctg.h_proteins.no_filtered_blast_hit.txt\n",
      "Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt\n",
      "blastn -db Pst_E104_v1_p_ctg.fa -query -Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa > Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa.outfmt6\n",
      "blastn -db Pst_E104_v1_h_ctg.fa -query -Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa > Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa.outfmt6\n"
     ]
    }
   ],
   "source": [
    "#blast no_filtered_blast_hits genes against opposite haplotyp at the gene level\n",
    "folder_p = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p/'\n",
    "\n",
    "no_filtered_blast = [x for x in os.listdir(folder_p) if x.endswith('no_filtered_blast_hit.txt')]\n",
    "gene_files = [x for x in os.listdir(folder_p) if '.gene.' in x and '.fa' in x]\n",
    "no_filtered_blast.sort()\n",
    "gene_files.sort()\n",
    "no_filtered_blast_dict = {}\n",
    "gene_files = gene_files[:2]\n",
    "\n",
    "#simply pulls in the gene sequences of missing besties\n",
    "for no_b, gene_file in zip(no_filtered_blast, gene_files):\n",
    "    print(no_b)\n",
    "    no_filtered_blast_list = pd.read_csv(folder_p+no_b, header=None, sep='\\t')[0].tolist()\n",
    "    key = no_b.split('.')[0]\n",
    "    no_filtered_blast_dict[key] = no_filtered_blast_list\n",
    "    no_filtered_blast_list = [x.replace('evm.model', 'evm.TU') for x in no_filtered_blast_list]\n",
    "    no_filtered_blast_seq = []\n",
    "    for seq in SeqIO.parse(open(folder_p + gene_file), 'fasta'):\n",
    "        if seq.id in no_filtered_blast_list:\n",
    "            no_filtered_blast_seq.append(seq)\n",
    "    out_f = ''\n",
    "    out_f = folder_p + no_b[:-3].replace('protein', 'gene') + 'fa'\n",
    "    f_handle = open(out_f,'w') #need to generate handle for writing and\n",
    "    SeqIO.write(no_filtered_blast_seq, f_handle, 'fasta')\n",
    "    f_handle.close() #closing file afterwards again\n",
    "\n",
    "gene_files_no_filtered_blast = [x for x in os.listdir(folder_p) if x.endswith('_genes.no_filtered_blast_hit.fa')]\n",
    "blast_db_nt = [x for x in os.listdir(folder_p) if x.endswith('_ctg.fa')]\n",
    "gene_files_no_filtered_blast.sort()\n",
    "blast_db_nt.sort()\n",
    "\n",
    "os.chdir(folder_p)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[1], gene_files_no_filtered_blast[0],gene_files_no_filtered_blast[0]))\n",
    "!blastn -db {blast_db_nt[1]} -query {gene_files_no_filtered_blast[0]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_filtered_blast[0]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_filtered_blast[0]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)\n",
    "\n",
    "print('blastn -db %s -query -%s > %s.outfmt6' %(blast_db_nt[0], gene_files_no_filtered_blast[1],gene_files_no_filtered_blast[1]))\n",
    "!blastn -db {blast_db_nt[0]} -query {gene_files_no_filtered_blast[1]}  -outfmt 6 -evalue 1e-10 -num_threads 1 \\\n",
    "> {gene_files_no_filtered_blast[1]}.outfmt6\n",
    "\n",
    "\n",
    "in_file =gene_files_no_filtered_blast[1]+'.outfmt6'\n",
    "blast_outfmt6_to_bed(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f4 Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa.outfmt6.bed | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f4 Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa.outfmt6.bed | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Out of the 2134 Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa 677 have a gene blast hit on the other haplome.\n",
    "Out of the 542 Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa 442 have a gene blast hit on the other haplome."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now read in the bed files as dataframe sort by e-value, pick the best e-value and the best hit on corresponding corresponding contig. Make two dictionaries with the same keys. One for the protein sequence and one for best blast hits. For the later make the value a list of file ids for the blast hits. Make a new folder for exonerate with subfolders for each no_filtered_blast hit. Save all the sequence files in this folders. Write a bash script that goes throught these folders and exectues exonerate for each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 2047 out of 2496 no_besties of Pst_E104_v1_h_ctg had a blast hit which was not RBH\n",
      "This 170 out of 2496 no_besties of Pst_E104_v1_h_ctg have no blast hit gene vs. other haplome\n",
      "No gene hits that have a protein hit 116 Pst_E104_v1_h_ctg\n",
      "This 2158 out of 4261 no_besties of Pst_E104_v1_p_ctg had a blast hit which was not RBH\n",
      "This 1693 out of 4261 no_besties of Pst_E104_v1_p_ctg have no blast hit gene vs. other haplome\n",
      "No gene hits that have a protein hit 867 Pst_E104_v1_p_ctg\n"
     ]
    }
   ],
   "source": [
    "#here track what happens with the no_besties hit. Do they not have protein blast hits? How many of the no protein \n",
    "#blast hits have not gene blast hit?\n",
    "#this needs to include some folder tracking of gene.no_besties.fa that hits nothing significant \n",
    "#no_bbb in - no_bbb out = no_hits at all\n",
    "no_gene_hits = {}\n",
    "no_besties_blast_nt_bed = [x for x in os.listdir() if x.endswith('no_besties.fa.outfmt6.bed')]\n",
    "no_besties_blast_nt_bed.sort()\n",
    "for no_bbb, protein_blast in zip(no_besties_blast_nt_bed,outfmt6):\n",
    "    no_bbb_no_protein_blast_df =''\n",
    "    no_bbb_df_header = ['Contig', 'start', 'end', 'blast_query', 'e-value', 'strand']\n",
    "    no_bbb_df = pd.read_csv(folder_p+no_bbb, header=None, names=no_bbb_df_header,  sep='\\t')\n",
    "    protein_blast_df = pd.read_csv(folder_p+protein_blast, header=None, sep='\\t')\n",
    "    no_bbb_df['protein_id'] = no_bbb_df['blast_query'].str.replace('evm.TU', 'evm.model')\n",
    "    #this below is most likely correct ignores the fact that some no_bbb genes might have hit nothing\n",
    "    #at all on the gene level\n",
    "    no_bbb_no_protein_blast_df = no_bbb_df[~no_bbb_df['protein_id'].isin(protein_blast_df[0])]\n",
    "    #these are the no_besties that didn't hit anything at the gene level\n",
    "    key =''\n",
    "    key = no_bbb.split('.')[0]\n",
    "    no_gene_hits[key] = set(no_bestie_dict[key]) - set(no_bbb_df['protein_id'].unique())\n",
    "    pd.DataFrame(list(no_gene_hits[key])).to_csv(key + '.gene.no_genome_blast_hit.txt', sep='\\t', header=None, index=None)\n",
    "    blast_p_no_bestie =''\n",
    "    blast_p_no_bestie = len(no_bbb_df[no_bbb_df['protein_id'].isin(protein_blast_df[0])]['blast_query'].unique())\n",
    "    print('This %i out of %i no_besties of %s had a blast hit which was not RBH' % \\\n",
    "          (blast_p_no_bestie, len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print('This %i out of %i no_besties of %s have no blast hit gene vs. other haplome' % \\\n",
    "         (len(no_gene_hits[key]),len(no_bestie_dict[key]),no_bbb.split('.')[0]))\n",
    "    print(\"No gene hits that have a protein hit\", len(set(no_gene_hits[key])- set(no_hits[key])), key)\n",
    "    groups = no_bbb_no_protein_blast_df.groupby(by='blast_query')\n",
    "    #now filter the dataframe by the smallest e-value for each group == blast_hit\n",
    "    df_filtered = groups.apply(lambda g: g[g['e-value'] == g['e-value'].min()])\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    df_filtered.iloc[:,0:6].to_csv(folder_p+no_bbb[:-4]+'.filteredbesthits.bed', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all primary proteins no hit need to be split up into pwh and pwoh\n",
    "p_contig_list = []\n",
    "h_contig_list = []\n",
    "for seq in SeqIO.parse('Pst_E104_v1_h_ctg.fa', 'fasta'):\n",
    "    h_contig_list.append(seq.id)\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    p_contig_list.append(seq.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_contigs with h_contig are 102 and without 74\n"
     ]
    }
   ],
   "source": [
    "pwh_set = set([x[0:11].replace('h','p') for x in h_contig_list])\n",
    "pwoh_set = set(p_contig_list) - pwh_set\n",
    "print(\"P_contigs with h_contig are %i and without %i\" % (len(pwh_set), len(pwoh_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pwh_filter (x):\n",
    "    p_contig = x.split('.')[2]\n",
    "    if p_contig in pwh_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15303 627 15930\n"
     ]
    }
   ],
   "source": [
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwh_set]\n",
    "fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']= [x for x in fa_protein_dict['Pst_E104_v1_p_ctg'] if x.split('.')[2] in pwoh_set]\n",
    "print(len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']), len (fa_protein_dict['Pst_E104_v1_p_ctg']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_txt = [x for x in os.listdir(folder_p) if x.split('.')[0] == 'Pst_E104_v1_p_ctg' and x.endswith('.txt')\\\n",
    "        and not 'pwh' in x and not 'pwoh' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.besties.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt',\n",
       " 'Pst_E104_v1_p_ctg.p_proteins.no_besties.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt 1443 proteins out of 15303 (9.43) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.gene.no_genome_blast_hit.txt 250 proteins out of 627 (39) are affected for pwoh\n",
      "Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt 1096 proteins out of 15303 (7.16) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_blast_hit.txt 140 proteins out of 627 (22) are affected for pwoh\n",
      "Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt\n",
      "For pwh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt 1866 proteins out of 15303 (12.19) are affected for pwh\n",
      "For pwoh:\n",
      "For this condition Pst_E104_v1_p_ctg.p_proteins.no_filtered_blast_hit.txt 268 proteins out of 627 (42) are affected for pwoh\n",
      "Lenght of pwoh 79847369, lenght of pwo 4178824, total length p 84026193\n"
     ]
    }
   ],
   "source": [
    "#filter and summarize the p results based on pwh and pwoh \n",
    "p_txt = [x for x in os.listdir(folder_p) if x.split('.')[0] == 'Pst_E104_v1_p_ctg' and x.endswith('.txt')\\\n",
    "        and not 'pwh' in x and not 'pwoh' in x and not x.endswith('besties.txt')]\n",
    "for x in p_txt:\n",
    "    #print(x)\n",
    "    df_p = pd.read_csv(x, header=None, sep='\\t')\n",
    "    #df_p.head()\n",
    "    df_p['pwh'] = df_p[0].apply(pwh_filter)\n",
    "    df_p[df_p['pwh'] == 1].to_csv(x[:-4]+'pwh.txt', sep ='\\t', header=None, index=None)\n",
    "    df_p[df_p['pwh'] == 0].to_csv(x[:-4]+'pwoh.txt', sep ='\\t', header=None, index=None)\n",
    "    print ('For pwh:')\n",
    "    print('For this condition %s %i proteins out of %i (%.2f) are affected for pwh'% \\\n",
    "          (x, sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh']), \\\n",
    "           sum(df_p['pwh'])/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwh'])*100 ))\n",
    "    print ('For pwoh:')\n",
    "    print('For this condition %s %i proteins out of %i (%i) are affected for pwoh'% \\\n",
    "         (x, len(df_p['pwh']) - sum(df_p['pwh']),len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh']),\\\n",
    "        (len(df_p['pwh']) - sum(df_p['pwh']))/len(fa_protein_dict['Pst_E104_v1_p_ctg_pwoh'])*100 ))\n",
    "     \n",
    "\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p')\n",
    "len_pwh = 0\n",
    "len_pwoh = 0\n",
    "for seq in SeqIO.parse('Pst_E104_v1_p_ctg.fa', 'fasta'):\n",
    "    if seq.id in pwh_set:\n",
    "        len_pwh = len_pwh + len(seq.seq)\n",
    "    if seq.id in pwoh_set:\n",
    "        len_pwoh = len_pwoh + len(seq.seq)\n",
    "print(\"Lenght of pwoh %i, lenght of pwo %i, total length p %i\" %(len_pwh,len_pwoh,len_pwh+len_pwoh ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_contig_blast(x,y):\n",
    "    '''Function that checks if the blast hit in columne y is on the same contig as the the query sequence in\n",
    "    column y.\n",
    "    '''\n",
    "    q_contig = x.split('.')[2].split('_')[1]\n",
    "    hit_contig = y.split('_')[1]\n",
    "    if q_contig == hit_contig:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Pst_E104_v1_h_ctg.h_genes.no_filtered_blast_hit.fa.outfmt6.bed is the current bed file being processed\n",
      "442\n",
      "This Pst_E104_v1_p_ctg.p_genes.no_filtered_blast_hit.fa.outfmt6.bed is the current bed file being processed\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "nfb_gene_blast_bed = [x for x in os.listdir(folder_p) if x.endswith('no_filtered_blast_hit.fa.outfmt6.bed')]\n",
    "nfb_gene_blast_bed.sort()\n",
    "protein_dict_nfb_bhits = {}\n",
    "protein_dict_nfb = {} #get a list of all proteins of nfb that don't have a hit when blasted at the gene level too\n",
    "#get the fasta genome files\n",
    "tmp_genome_files = ['Pst_E104_v1_p_ctg.fa', 'Pst_E104_v1_h_ctg.fa']\n",
    "protein_fa_files = [x for x in os.listdir(folder_p) if x.endswith('anno.RepaseTPSI_filtered.protein.fa')]\n",
    "for bed_file in nfb_gene_blast_bed:\n",
    "    print('This %s is the current bed file being processed' % (bed_file))\n",
    "    nfb_gene_blast_bed_df =''\n",
    "    nfb_gene_blast_bed_df = pd.read_csv(bed_file, header=None, sep='\\t' )\n",
    "    #now add another column to the dateframe that stats if the hit and query are on the same contig\n",
    "    nfb_gene_blast_bed_df['Same_contig'] = nfb_gene_blast_bed_df[3].combine(nfb_gene_blast_bed_df[0], func=same_contig_blast)\n",
    "    #initialize some temporary df for filtering\n",
    "    tmp_same_contig_df =''\n",
    "    tmp_best_hits_df =''\n",
    "    tmp_groups =''\n",
    "    tmp_best_hits_filtered =''\n",
    "    #get all blast hits that are on the same contig\n",
    "    tmp_same_contig_df = nfb_gene_blast_bed_df[nfb_gene_blast_bed_df['Same_contig'] == True]\n",
    "    #get the best remaining blast hit(s)\n",
    "    tmp_best_hits_df = nfb_gene_blast_bed_df[nfb_gene_blast_bed_df['Same_contig'] == False].sort_values(by=[3,4])\n",
    "    tmp_groups = tmp_best_hits_df.groupby(by=3)\n",
    "    #now filter the dataframe by the smallest e-value for each group == Query/3\n",
    "    tmp_best_hits_df_filtered = tmp_groups.apply(lambda g: g[g[4] == g[4].min()]) \n",
    "    tmp_best_hits_df_filtered = tmp_best_hits_df_filtered.reset_index(drop=True)\n",
    "    nfb_gene_blast_bed_df_filtered = ''\n",
    "    nfb_gene_blast_bed_df_filtered = pd.concat([tmp_best_hits_df_filtered, tmp_same_contig_df]).sort_values(by=[3,4]).reset_index(drop=True)\n",
    "    #now get the loop through the df. pull out the protein sequences and corresponding hits. save them to new folders.\n",
    "    #extend the script. \n",
    "    #get all the blasted sequences that had a hit == unique querries\n",
    "    tmp_queries = ''\n",
    "    tmp_queries = nfb_gene_blast_bed_df_filtered[3].unique()\n",
    "    #get all the protein sequences in a dictionary with protein ID being the key and the values being a SeqIO object\n",
    "    #get the fasta genome files\n",
    "    tmp_genome_file = [x for x in tmp_genome_files if not x.startswith(bed_file.split('.')[0])][0]\n",
    "    genome_fa = ''\n",
    "    genome_fa = pysam.FastaFile(tmp_genome_file)\n",
    "    tmp_queries_id = [x.replace('TU', 'model') for x in tmp_queries]\n",
    "    tmp_protein_fa_file = [x for x in protein_fa_files if x.startswith(bed_file.split('.')[0])][0]\n",
    "    for seq in SeqIO.parse(open(tmp_protein_fa_file), 'fasta'):\n",
    "            if seq.id in tmp_queries_id:\n",
    "                protein_dict_nfb[seq.id] = seq\n",
    "    #add this tmp_protein_dict_nfb to the full protein dict to keep track\n",
    "    #check why only one file gets processed.\n",
    "    \n",
    "    \n",
    "    #make a dict that gets the blast hit sequences in +30kb each side for alignments of protein sequences on top of them. \n",
    "    #The value of this dict will be a list of SeqIO objects\n",
    "    \n",
    "    tmp_list = [] #tmp_list to save the SeqIO objects for the blast hits in\n",
    "    print(len(tmp_queries))\n",
    "    for query in tmp_queries:\n",
    "        #print(query)\n",
    "        tmp_list = []\n",
    "        tmp_df = nfb_gene_blast_bed_df_filtered[nfb_gene_blast_bed_df_filtered[3] == query]\n",
    "        #do groupby instead here on columns one. Take min of column 1 and max of column 2 as start/stop +-\n",
    "        #this avoids to mess around with mutliple hits on the same contig\n",
    "        tmp_hit = tmp_df[0].unique()\n",
    "        for hit in tmp_hit:\n",
    "            tmp_df_2 = tmp_df[tmp_df[0] == hit]\n",
    "            start = tmp_df_2[1].min() - 30000\n",
    "            if start < 1:\n",
    "                start = 1\n",
    "            end = tmp_df_2[2].max() + 30000\n",
    "            seq = genome_fa.fetch(hit, start, end)\n",
    "            seq_r = '' #initialize empty SeqIO record\n",
    "            seq_id = hit + '_' + str(start) + '_' + str(end)\n",
    "            seq_ob = Seq(seq)\n",
    "            seq_ob.alphabet = 'fasta'\n",
    "            seq_r = SeqRecord(seq_ob)\n",
    "            seq_r.id = seq_id\n",
    "            tmp_list.append(seq_r)\n",
    "        protein_dict_nfb_bhits[query] = tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now loop over the dicts protein_dict_nfb_bhits and protein_dict_nfb with the keys and print out the sequences in a \n",
    "#new folder for each hit and write a script for this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make new folder for exonerate\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "exonerate_folder = os.path.join(working_dir, 'exonerate_2')\n",
    "if not os.path.exists(exonerate_folder):\n",
    "    os.mkdir(exonerate_folder)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.mkdir(new_folder)\n",
    "    os.chdir(new_folder)\n",
    "    out_p_f = open(key+'.fa', 'w')\n",
    "    SeqIO.write(protein_dict_nfb[key], out_p_f, 'fasta')\n",
    "    out_p_f.close()\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        out_t_f = open(seq.id + '.fa', 'w')\n",
    "        SeqIO.write(seq, out_t_f, 'fasta')\n",
    "        out_t_f.close()\n",
    "    os.chdir(working_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make write exonerate script\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "os.chdir(working_dir)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "out_exonerate = open('exonerate_alignments_vulgar2.sh', 'w')\n",
    "out_exonerate.write('#!/bin/bash\\n')\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    protein_file_name = key+'.fa'\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    out_exonerate.write('cd %s\\n'% (new_folder))\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        target_file_name = seq.id + '.fa'\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment False -S > %s.vulgar_exn\\n'\\\n",
    "                           %(protein_file_name, target_file_name,target_file_name ))\n",
    "out_exonerate.write('cd %s\\n' %(working_dir))\n",
    "out_exonerate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make write exonerate script\n",
    "working_dir = os.path.abspath(folder_p)\n",
    "os.chdir(working_dir)\n",
    "protein_keys = [x.replace('TU', 'model') for x in protein_dict_nfb_bhits.keys()]\n",
    "out_exonerate = open('exonerate_alignments2.sh', 'w')\n",
    "out_exonerate.write('#!/bin/bash\\n')\n",
    "for key in protein_keys:\n",
    "    new_folder = os.path.join(exonerate_folder, key)\n",
    "    protein_file_name = key+'.fa'\n",
    "    p_key = key.replace('model', 'TU')\n",
    "    out_exonerate.write('cd %s\\n'% (new_folder))\n",
    "    for seq in protein_dict_nfb_bhits[p_key]:\n",
    "        target_file_name = seq.id + '.fa'\n",
    "        out_exonerate.write('exonerate --model protein2genome --percent 20 -q %s -t %s --showalignment -S > %s.vulgar_exn\\n'\\\n",
    "                           %(protein_file_name, target_file_name,target_file_name ))\n",
    "out_exonerate.write('cd %s\\n' %(working_dir))\n",
    "out_exonerate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_E104_v1/blastp_on_p/exonerate/evm.model.pcontig_034.69')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exn_vulgar = [x for x in os.listdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evm.model.pcontig_034.69.fa\r\n",
      "hcontig_034_001_212361_212739.fa\r\n",
      "hcontig_034_001_212361_212739.fa.exonerate_out\r\n",
      "hcontig_034_001_212361_212739.fa.vulgar_exn\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_same_contig_df[3].unique())a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Same_contig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>489890</td>\n",
       "      <td>490460</td>\n",
       "      <td>evm.TU.pcontig_000.113</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hcontig_047_006</td>\n",
       "      <td>72870</td>\n",
       "      <td>73138</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>6.000000e-128</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hcontig_000_054</td>\n",
       "      <td>230833</td>\n",
       "      <td>231099</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>3.000000e-115</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1171960</td>\n",
       "      <td>1172227</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>1.000000e-95</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>577297</td>\n",
       "      <td>577570</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>8.000000e-87</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>744498</td>\n",
       "      <td>744763</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>3.000000e-86</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hcontig_000_039</td>\n",
       "      <td>4683</td>\n",
       "      <td>4947</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>3.000000e-86</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>129471</td>\n",
       "      <td>129638</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>2.000000e-58</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>129054</td>\n",
       "      <td>129131</td>\n",
       "      <td>evm.TU.pcontig_000.128</td>\n",
       "      <td>4.000000e-25</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>683263</td>\n",
       "      <td>683668</td>\n",
       "      <td>evm.TU.pcontig_000.152</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>456363</td>\n",
       "      <td>456569</td>\n",
       "      <td>evm.TU.pcontig_000.186</td>\n",
       "      <td>7.000000e-97</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hcontig_052_006</td>\n",
       "      <td>47057</td>\n",
       "      <td>47263</td>\n",
       "      <td>evm.TU.pcontig_000.186</td>\n",
       "      <td>7.000000e-92</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>681009</td>\n",
       "      <td>681111</td>\n",
       "      <td>evm.TU.pcontig_000.186</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hcontig_000_054</td>\n",
       "      <td>5866</td>\n",
       "      <td>5968</td>\n",
       "      <td>evm.TU.pcontig_000.186</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>21856</td>\n",
       "      <td>21972</td>\n",
       "      <td>evm.TU.pcontig_000.186</td>\n",
       "      <td>4.000000e-20</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>865171</td>\n",
       "      <td>865358</td>\n",
       "      <td>evm.TU.pcontig_000.200</td>\n",
       "      <td>2.000000e-81</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>865289</td>\n",
       "      <td>865423</td>\n",
       "      <td>evm.TU.pcontig_000.200</td>\n",
       "      <td>7.000000e-46</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hcontig_018_016</td>\n",
       "      <td>354144</td>\n",
       "      <td>354841</td>\n",
       "      <td>evm.TU.pcontig_000.237</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1029345</td>\n",
       "      <td>1033096</td>\n",
       "      <td>evm.TU.pcontig_000.237</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>134177</td>\n",
       "      <td>134617</td>\n",
       "      <td>evm.TU.pcontig_000.24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1308194</td>\n",
       "      <td>1308554</td>\n",
       "      <td>evm.TU.pcontig_000.304</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hcontig_006_013</td>\n",
       "      <td>109660</td>\n",
       "      <td>109705</td>\n",
       "      <td>evm.TU.pcontig_000.304</td>\n",
       "      <td>5.000000e-14</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hcontig_043_012</td>\n",
       "      <td>78196</td>\n",
       "      <td>79107</td>\n",
       "      <td>evm.TU.pcontig_000.355</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hcontig_026_018</td>\n",
       "      <td>110764</td>\n",
       "      <td>111676</td>\n",
       "      <td>evm.TU.pcontig_000.355</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1687480</td>\n",
       "      <td>1687892</td>\n",
       "      <td>evm.TU.pcontig_000.375</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1711669</td>\n",
       "      <td>1712348</td>\n",
       "      <td>evm.TU.pcontig_000.386</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1904282</td>\n",
       "      <td>1904552</td>\n",
       "      <td>evm.TU.pcontig_000.425</td>\n",
       "      <td>1.000000e-113</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1906076</td>\n",
       "      <td>1906839</td>\n",
       "      <td>evm.TU.pcontig_000.426</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hcontig_000_003</td>\n",
       "      <td>1954625</td>\n",
       "      <td>1954858</td>\n",
       "      <td>evm.TU.pcontig_000.426</td>\n",
       "      <td>8.000000e-55</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hcontig_000_050</td>\n",
       "      <td>13723</td>\n",
       "      <td>14181</td>\n",
       "      <td>evm.TU.pcontig_000.464</td>\n",
       "      <td>6.000000e-141</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>hcontig_238_001</td>\n",
       "      <td>17022</td>\n",
       "      <td>17244</td>\n",
       "      <td>evm.TU.pcontig_183.1</td>\n",
       "      <td>3.000000e-114</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>hcontig_060_001</td>\n",
       "      <td>42103</td>\n",
       "      <td>42679</td>\n",
       "      <td>evm.TU.pcontig_188.1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>hcontig_054_143</td>\n",
       "      <td>62794</td>\n",
       "      <td>63369</td>\n",
       "      <td>evm.TU.pcontig_188.1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>hcontig_241_001</td>\n",
       "      <td>6753</td>\n",
       "      <td>7053</td>\n",
       "      <td>evm.TU.pcontig_190.2</td>\n",
       "      <td>2.000000e-157</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>hcontig_238_002</td>\n",
       "      <td>2061</td>\n",
       "      <td>2349</td>\n",
       "      <td>evm.TU.pcontig_194.1</td>\n",
       "      <td>7.000000e-151</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>hcontig_238_001</td>\n",
       "      <td>17022</td>\n",
       "      <td>17244</td>\n",
       "      <td>evm.TU.pcontig_197.1</td>\n",
       "      <td>3.000000e-114</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>hcontig_241_001</td>\n",
       "      <td>8299</td>\n",
       "      <td>8527</td>\n",
       "      <td>evm.TU.pcontig_197.3</td>\n",
       "      <td>1.000000e-117</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>hcontig_238_002</td>\n",
       "      <td>2061</td>\n",
       "      <td>2349</td>\n",
       "      <td>evm.TU.pcontig_198.1</td>\n",
       "      <td>7.000000e-151</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>hcontig_019_012</td>\n",
       "      <td>17044</td>\n",
       "      <td>17963</td>\n",
       "      <td>evm.TU.pcontig_200.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>hcontig_081_005</td>\n",
       "      <td>117035</td>\n",
       "      <td>117933</td>\n",
       "      <td>evm.TU.pcontig_200.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>hcontig_039_005</td>\n",
       "      <td>372933</td>\n",
       "      <td>373728</td>\n",
       "      <td>evm.TU.pcontig_200.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>hcontig_241_001</td>\n",
       "      <td>8299</td>\n",
       "      <td>8527</td>\n",
       "      <td>evm.TU.pcontig_201.2</td>\n",
       "      <td>1.000000e-117</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>hcontig_033_007</td>\n",
       "      <td>41915</td>\n",
       "      <td>42752</td>\n",
       "      <td>evm.TU.pcontig_203.1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>hcontig_027_006</td>\n",
       "      <td>401001</td>\n",
       "      <td>401333</td>\n",
       "      <td>evm.TU.pcontig_203.5</td>\n",
       "      <td>5.000000e-82</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>hcontig_027_001</td>\n",
       "      <td>456</td>\n",
       "      <td>788</td>\n",
       "      <td>evm.TU.pcontig_203.5</td>\n",
       "      <td>5.000000e-82</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>hcontig_019_012</td>\n",
       "      <td>17044</td>\n",
       "      <td>18144</td>\n",
       "      <td>evm.TU.pcontig_204.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>hcontig_039_005</td>\n",
       "      <td>372596</td>\n",
       "      <td>373728</td>\n",
       "      <td>evm.TU.pcontig_204.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>hcontig_081_005</td>\n",
       "      <td>116824</td>\n",
       "      <td>117933</td>\n",
       "      <td>evm.TU.pcontig_204.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>hcontig_184_001</td>\n",
       "      <td>1094</td>\n",
       "      <td>1290</td>\n",
       "      <td>evm.TU.pcontig_205.2</td>\n",
       "      <td>6.000000e-100</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>hcontig_193_002</td>\n",
       "      <td>33279</td>\n",
       "      <td>33475</td>\n",
       "      <td>evm.TU.pcontig_205.2</td>\n",
       "      <td>6.000000e-100</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>hcontig_034_001</td>\n",
       "      <td>27614</td>\n",
       "      <td>27815</td>\n",
       "      <td>evm.TU.pcontig_207.5</td>\n",
       "      <td>7.000000e-72</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>hcontig_034_001</td>\n",
       "      <td>36583</td>\n",
       "      <td>37356</td>\n",
       "      <td>evm.TU.pcontig_207.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>hcontig_034_001</td>\n",
       "      <td>30027</td>\n",
       "      <td>30544</td>\n",
       "      <td>evm.TU.pcontig_207.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>hcontig_241_001</td>\n",
       "      <td>6753</td>\n",
       "      <td>7053</td>\n",
       "      <td>evm.TU.pcontig_209.2</td>\n",
       "      <td>2.000000e-157</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>hcontig_241_001</td>\n",
       "      <td>1079</td>\n",
       "      <td>1333</td>\n",
       "      <td>evm.TU.pcontig_211.1</td>\n",
       "      <td>4.000000e-128</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>hcontig_073_004</td>\n",
       "      <td>69384</td>\n",
       "      <td>69584</td>\n",
       "      <td>evm.TU.pcontig_218.1</td>\n",
       "      <td>4.000000e-97</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>hcontig_058_001</td>\n",
       "      <td>93337</td>\n",
       "      <td>93587</td>\n",
       "      <td>evm.TU.pcontig_223.2</td>\n",
       "      <td>9.000000e-95</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>hcontig_110_003</td>\n",
       "      <td>0</td>\n",
       "      <td>1239</td>\n",
       "      <td>evm.TU.pcontig_223.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>hcontig_047_006</td>\n",
       "      <td>56392</td>\n",
       "      <td>57157</td>\n",
       "      <td>evm.TU.pcontig_223.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>hcontig_016_024</td>\n",
       "      <td>672010</td>\n",
       "      <td>672134</td>\n",
       "      <td>evm.TU.pcontig_223.8</td>\n",
       "      <td>2.000000e-55</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2                       3  \\\n",
       "0     hcontig_000_003   489890   490460  evm.TU.pcontig_000.113   \n",
       "1     hcontig_047_006    72870    73138  evm.TU.pcontig_000.128   \n",
       "2     hcontig_000_054   230833   231099  evm.TU.pcontig_000.128   \n",
       "3     hcontig_000_003  1171960  1172227  evm.TU.pcontig_000.128   \n",
       "4     hcontig_000_050   577297   577570  evm.TU.pcontig_000.128   \n",
       "5     hcontig_000_003   744498   744763  evm.TU.pcontig_000.128   \n",
       "6     hcontig_000_039     4683     4947  evm.TU.pcontig_000.128   \n",
       "7     hcontig_000_050   129471   129638  evm.TU.pcontig_000.128   \n",
       "8     hcontig_000_050   129054   129131  evm.TU.pcontig_000.128   \n",
       "9     hcontig_000_003   683263   683668  evm.TU.pcontig_000.152   \n",
       "10    hcontig_000_050   456363   456569  evm.TU.pcontig_000.186   \n",
       "11    hcontig_052_006    47057    47263  evm.TU.pcontig_000.186   \n",
       "12    hcontig_000_050   681009   681111  evm.TU.pcontig_000.186   \n",
       "13    hcontig_000_054     5866     5968  evm.TU.pcontig_000.186   \n",
       "14    hcontig_000_003    21856    21972  evm.TU.pcontig_000.186   \n",
       "15    hcontig_000_003   865171   865358  evm.TU.pcontig_000.200   \n",
       "16    hcontig_000_003   865289   865423  evm.TU.pcontig_000.200   \n",
       "17    hcontig_018_016   354144   354841  evm.TU.pcontig_000.237   \n",
       "18    hcontig_000_003  1029345  1033096  evm.TU.pcontig_000.237   \n",
       "19    hcontig_000_003   134177   134617   evm.TU.pcontig_000.24   \n",
       "20    hcontig_000_003  1308194  1308554  evm.TU.pcontig_000.304   \n",
       "21    hcontig_006_013   109660   109705  evm.TU.pcontig_000.304   \n",
       "22    hcontig_043_012    78196    79107  evm.TU.pcontig_000.355   \n",
       "23    hcontig_026_018   110764   111676  evm.TU.pcontig_000.355   \n",
       "24    hcontig_000_003  1687480  1687892  evm.TU.pcontig_000.375   \n",
       "25    hcontig_000_003  1711669  1712348  evm.TU.pcontig_000.386   \n",
       "26    hcontig_000_003  1904282  1904552  evm.TU.pcontig_000.425   \n",
       "27    hcontig_000_003  1906076  1906839  evm.TU.pcontig_000.426   \n",
       "28    hcontig_000_003  1954625  1954858  evm.TU.pcontig_000.426   \n",
       "29    hcontig_000_050    13723    14181  evm.TU.pcontig_000.464   \n",
       "...               ...      ...      ...                     ...   \n",
       "1328  hcontig_238_001    17022    17244    evm.TU.pcontig_183.1   \n",
       "1329  hcontig_060_001    42103    42679    evm.TU.pcontig_188.1   \n",
       "1330  hcontig_054_143    62794    63369    evm.TU.pcontig_188.1   \n",
       "1331  hcontig_241_001     6753     7053    evm.TU.pcontig_190.2   \n",
       "1332  hcontig_238_002     2061     2349    evm.TU.pcontig_194.1   \n",
       "1333  hcontig_238_001    17022    17244    evm.TU.pcontig_197.1   \n",
       "1334  hcontig_241_001     8299     8527    evm.TU.pcontig_197.3   \n",
       "1335  hcontig_238_002     2061     2349    evm.TU.pcontig_198.1   \n",
       "1336  hcontig_019_012    17044    17963    evm.TU.pcontig_200.7   \n",
       "1337  hcontig_081_005   117035   117933    evm.TU.pcontig_200.7   \n",
       "1338  hcontig_039_005   372933   373728    evm.TU.pcontig_200.7   \n",
       "1339  hcontig_241_001     8299     8527    evm.TU.pcontig_201.2   \n",
       "1340  hcontig_033_007    41915    42752    evm.TU.pcontig_203.1   \n",
       "1341  hcontig_027_006   401001   401333    evm.TU.pcontig_203.5   \n",
       "1342  hcontig_027_001      456      788    evm.TU.pcontig_203.5   \n",
       "1343  hcontig_019_012    17044    18144    evm.TU.pcontig_204.6   \n",
       "1344  hcontig_039_005   372596   373728    evm.TU.pcontig_204.6   \n",
       "1345  hcontig_081_005   116824   117933    evm.TU.pcontig_204.6   \n",
       "1346  hcontig_184_001     1094     1290    evm.TU.pcontig_205.2   \n",
       "1347  hcontig_193_002    33279    33475    evm.TU.pcontig_205.2   \n",
       "1348  hcontig_034_001    27614    27815    evm.TU.pcontig_207.5   \n",
       "1349  hcontig_034_001    36583    37356    evm.TU.pcontig_207.6   \n",
       "1350  hcontig_034_001    30027    30544    evm.TU.pcontig_207.6   \n",
       "1351  hcontig_241_001     6753     7053    evm.TU.pcontig_209.2   \n",
       "1352  hcontig_241_001     1079     1333    evm.TU.pcontig_211.1   \n",
       "1353  hcontig_073_004    69384    69584    evm.TU.pcontig_218.1   \n",
       "1354  hcontig_058_001    93337    93587    evm.TU.pcontig_223.2   \n",
       "1355  hcontig_110_003        0     1239    evm.TU.pcontig_223.4   \n",
       "1356  hcontig_047_006    56392    57157    evm.TU.pcontig_223.4   \n",
       "1357  hcontig_016_024   672010   672134    evm.TU.pcontig_223.8   \n",
       "\n",
       "                  4  5 Same_contig  \n",
       "0      0.000000e+00  +        True  \n",
       "1     6.000000e-128  -       False  \n",
       "2     3.000000e-115  +        True  \n",
       "3      1.000000e-95  +        True  \n",
       "4      8.000000e-87  +        True  \n",
       "5      3.000000e-86  +        True  \n",
       "6      3.000000e-86  +        True  \n",
       "7      2.000000e-58  +        True  \n",
       "8      4.000000e-25  +        True  \n",
       "9      0.000000e+00  +        True  \n",
       "10     7.000000e-97  +        True  \n",
       "11     7.000000e-92  -       False  \n",
       "12     1.000000e-20  -        True  \n",
       "13     1.000000e-20  -        True  \n",
       "14     4.000000e-20  +        True  \n",
       "15     2.000000e-81  +        True  \n",
       "16     7.000000e-46  +        True  \n",
       "17     0.000000e+00  -       False  \n",
       "18     0.000000e+00  -        True  \n",
       "19     0.000000e+00  -        True  \n",
       "20     0.000000e+00  +        True  \n",
       "21     5.000000e-14  -       False  \n",
       "22     0.000000e+00  -       False  \n",
       "23     0.000000e+00  -       False  \n",
       "24     0.000000e+00  -        True  \n",
       "25     0.000000e+00  -        True  \n",
       "26    1.000000e-113  +        True  \n",
       "27     0.000000e+00  -        True  \n",
       "28     8.000000e-55  +        True  \n",
       "29    6.000000e-141  -        True  \n",
       "...             ... ..         ...  \n",
       "1328  3.000000e-114  -       False  \n",
       "1329   0.000000e+00  +       False  \n",
       "1330   0.000000e+00  +       False  \n",
       "1331  2.000000e-157  +       False  \n",
       "1332  7.000000e-151  +       False  \n",
       "1333  3.000000e-114  -       False  \n",
       "1334  1.000000e-117  +       False  \n",
       "1335  7.000000e-151  +       False  \n",
       "1336   0.000000e+00  +       False  \n",
       "1337   0.000000e+00  -       False  \n",
       "1338   0.000000e+00  -       False  \n",
       "1339  1.000000e-117  +       False  \n",
       "1340   0.000000e+00  -       False  \n",
       "1341   5.000000e-82  +       False  \n",
       "1342   5.000000e-82  +       False  \n",
       "1343   0.000000e+00  +       False  \n",
       "1344   0.000000e+00  -       False  \n",
       "1345   0.000000e+00  -       False  \n",
       "1346  6.000000e-100  +       False  \n",
       "1347  6.000000e-100  +       False  \n",
       "1348   7.000000e-72  -       False  \n",
       "1349   0.000000e+00  +       False  \n",
       "1350   0.000000e+00  +       False  \n",
       "1351  2.000000e-157  +       False  \n",
       "1352  4.000000e-128  +       False  \n",
       "1353   4.000000e-97  -       False  \n",
       "1354   9.000000e-95  +       False  \n",
       "1355   0.000000e+00  -       False  \n",
       "1356   0.000000e+00  -       False  \n",
       "1357   2.000000e-55  -       False  \n",
       "\n",
       "[1358 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfb_gene_blast_bed_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nfb_gene_blast_bed_df_filtered[3].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
